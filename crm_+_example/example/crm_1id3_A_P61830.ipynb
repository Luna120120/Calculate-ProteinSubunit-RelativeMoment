{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys, os \n",
    "import argparse\n",
    "from Bio import Align\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded relevant information of 1id3, chain A, from 1id3_A-AB.csv\n",
      "    NUM   AA   ABS\n",
      "0    38  PRO  0.00\n",
      "1    39  HIS  0.00\n",
      "2    40  ARG  0.00\n",
      "3    41  TYR  0.00\n",
      "4    42  LYS  0.00\n",
      "..  ...  ...   ...\n",
      "92  130  LEU  0.00\n",
      "93  131  ARG  2.55\n",
      "94  132  GLY  0.00\n",
      "95  133  GLU  0.00\n",
      "96  134  ARG  0.00\n",
      "\n",
      "[97 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part 1 Prepare data\n",
    "# 1.1\n",
    "def extract_pdb_name_and_generate_df(filepath):\n",
    "    # Read the table from the file, assuming comma separation\n",
    "    # Skip the first two rows which contain 'REM' and 'All-atoms'\n",
    "    df = pd.read_csv(filepath, delimiter=',', skiprows=1)\n",
    "    # print(f'df generated from file path: {filepath} \\n{df}')\n",
    "    # Extract the PDB name from the file name\n",
    "    basename = os.path.basename(filepath)\n",
    "    pdb_name = basename.split('_')[0]\n",
    "    rest_name = basename.split('_')[1]\n",
    "    chain_id = rest_name.split('-')[0]\n",
    "    \n",
    "    # Create a new DataFrame that only retains information from column index 1, 3, and 4\n",
    "    # which are the aa, index, ABS\n",
    "    selected_indices = [1, 3, 4]\n",
    "    data_df = df.iloc[: ,selected_indices]\n",
    "    # Swap the aa and the index columns\n",
    "    cols = list(data_df.columns)\n",
    "    cols[0], cols[1] = cols[1], cols[0]  # Swap the column names\n",
    "    data_df = data_df[cols]  # Reindex the DataFrame with the new column order\n",
    "    # Assign new column names to the DataFrame\n",
    "    data_df.columns = ['NUM', 'AA', 'ABS']\n",
    "    data_df = data_df[['NUM', 'AA', 'ABS']]\n",
    "    \n",
    "    return basename, pdb_name, chain_id, data_df\n",
    "\n",
    "filepath = '/Users/luna/Documents/RP1/2_do_cal_and_result/sample_candidates/1id3_A-AB.csv'\n",
    "basename, pdb_name, chain_id, data_df = extract_pdb_name_and_generate_df(filepath)\n",
    "print(f'Loaded relevant information of {pdb_name}, chain {chain_id}, from {basename}')\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "def convert_three_letter_code_to_one_letter_code(three_letter_list):\n",
    "    aa_dict = {\n",
    "        'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D',\n",
    "        'CYS': 'C', 'GLU': 'E', 'GLN': 'Q', 'GLY': 'G',\n",
    "        'HIS': 'H', 'ILE': 'I', 'LEU': 'L', 'LYS': 'K',\n",
    "        'MET': 'M', 'PHE': 'F', 'PRO': 'P', 'SER': 'S',\n",
    "        'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',\n",
    "        # Additional potential codes\n",
    "        'SEC': 'U', 'PYL': 'O', 'ASX': 'B', 'GLX': 'Z',\n",
    "        'XLE': 'J', 'XAA': 'X', 'TER': '*', 'UNK': 'X'}\n",
    "    one_letter_list = []\n",
    "    for aa in three_letter_list:\n",
    "        one_letter_code = aa_dict.get(aa, 'X')  # Default to 'X' if aa is not found\n",
    "        one_letter_list.append(one_letter_code)\n",
    "        \n",
    "    return one_letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NUM AA   ABS\n",
      "0    38  P  0.00\n",
      "1    39  H  0.00\n",
      "2    40  R  0.00\n",
      "3    41  Y  0.00\n",
      "4    42  K  0.00\n",
      "..  ... ..   ...\n",
      "92  130  L  0.00\n",
      "93  131  R  2.55\n",
      "94  132  G  0.00\n",
      "95  133  E  0.00\n",
      "96  134  R  0.00\n",
      "\n",
      "[97 rows x 3 columns]\n",
      "The PDB sequence of 1id3 is loaded, length: 97\n",
      "PHRYKPGTVALREIRRFQKSTELLIRKLPFQRLVREIAQDFKTDLRFQSSAIGALQESVEAYLVSLFEDTNLAAIHAKRVTIQKKEIKLARRLRGER\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "def process_df_and_generate_sequence_string(data_df):\n",
    "    # Convert the second column (amino acids) to a list of three-letter codes\n",
    "    three_letter_list = data_df.iloc[:, 1].tolist()\n",
    "    # Convert the three-letter codes to one-letter codes using the function\n",
    "    one_letter_list = convert_three_letter_code_to_one_letter_code(three_letter_list)\n",
    "    # Replace the second column with the one-letter codes\n",
    "    data_df.iloc[:, 1] = one_letter_list\n",
    "    \n",
    "    # Generate the PDB sequence \n",
    "    pdb_sequence = ''.join(one_letter_list)\n",
    "    \n",
    "    return pdb_sequence, data_df\n",
    "\n",
    "pdb_sequence, data_df = process_df_and_generate_sequence_string(data_df)\n",
    "print(data_df)\n",
    "print(f'The PDB sequence of {pdb_name} is loaded, length: {len(pdb_sequence)}')\n",
    "print(pdb_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the corresponding sequence in PDB model 1id3, the PDB aa range: \n",
      "min: 38, max: 134\n",
      "\n",
      "Identified PDB aa block:\n",
      "38(P)-134(R)\n",
      "\n",
      "Missing PDB aa:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1.4\n",
    "def identify_aa_blocks(pdb_name, data_df):\n",
    "    # Find the smallest and largest NUM values\n",
    "    min_num = data_df['NUM'].min()\n",
    "    max_num = data_df['NUM'].max()\n",
    "    \n",
    "    # Generate the full range of numbers from min_num to max_num\n",
    "    full_range = set(range(int(min_num), int(max_num) + 1))\n",
    "    print(f'For the corresponding sequence in PDB model {pdb_name}, the PDB aa range: \\nmin: {min_num}, max: {max_num}')\n",
    "    \n",
    "    # Get the set of NUM values that actually appear in the DataFrame\n",
    "    actual_nums = set(data_df['NUM'])\n",
    "    \n",
    "    # Find the set of numbers that are missing from the DataFrame\n",
    "    missing_nums = sorted(full_range - actual_nums)\n",
    "    \n",
    "    # Identify the existing PDB aa blocks\n",
    "    print('\\nIdentified PDB aa block:')\n",
    "    current_block_start = None\n",
    "    for num in sorted(actual_nums):\n",
    "        if current_block_start is None:\n",
    "            current_block_start = num\n",
    "        # If the next number is missing or it's the last number, end the current block\n",
    "        if num + 1 not in actual_nums or num == max_num:\n",
    "            # Get the AA for the start and end of the block\n",
    "            start_aa = data_df.loc[data_df['NUM'] == current_block_start, 'AA'].values[0]\n",
    "            end_aa = data_df.loc[data_df['NUM'] == num, 'AA'].values[0]\n",
    "            print(f'{current_block_start}({start_aa})-{num}({end_aa})')\n",
    "            current_block_start = None\n",
    "    \n",
    "    # Print missing PDB aa\n",
    "    print('\\nMissing PDB aa:')\n",
    "    if not missing_nums:\n",
    "        print('None')\n",
    "    else:\n",
    "        missing_block_start = None\n",
    "        for i, num in enumerate(missing_nums):\n",
    "            if missing_block_start is None:\n",
    "                missing_block_start = num\n",
    "            # If the next number is not consecutive or it's the last missing number, end the current block\n",
    "            if i + 1 == len(missing_nums) or missing_nums[i + 1] != num + 1:\n",
    "                if missing_block_start == num:\n",
    "                    print(missing_block_start)\n",
    "                else:\n",
    "                    print(f'{missing_block_start}-{num}')\n",
    "                missing_block_start = None\n",
    "\n",
    "identify_aa_blocks(pdb_name, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Uniprot sequence of P61830 is loaded, length: 136\n",
      "MARTKQTARKSTGGKAPRKQLASKAARKSAPSTGGVKKPHRYKPGTVALREIRRFQKSTELLIRKLPFQRLVREIAQDFKTDLRFQSSAIGALQESVEAYLVSLFEDTNLAAIHAKRVTIQKKDIKLARRLRGERS\n"
     ]
    }
   ],
   "source": [
    "# 1.5\n",
    "def extract_uniprot_data(uniprot_filepath):\n",
    "    # Initialize an empty string to hold the sequence\n",
    "    uniprot_sequence = ''\n",
    "    # Initialize a variable to hold the UniProt name\n",
    "    uniprot_name = ''\n",
    "    \n",
    "    # Compile the regular expressions for the header and sequence lines\n",
    "    header_pattern = re.compile(r'^>sp\\|(\\w+)\\|')\n",
    "    sequence_pattern = re.compile(r'^[A-Z]+$')\n",
    "    \n",
    "    # Open the file for reading\n",
    "    with open(uniprot_filepath, 'r') as file:\n",
    "        # Iterate over each line in the file\n",
    "        for line in file:\n",
    "            # Check if the line is a header (starts with '>')\n",
    "            if line.startswith('>'):\n",
    "                # Use the regular expression to extract the UniProt name\n",
    "                header_match = header_pattern.match(line)\n",
    "                if header_match:\n",
    "                    uniprot_name = header_match.group(1)\n",
    "                else:\n",
    "                    print('Invalid header format:', line)\n",
    "                    return None, None\n",
    "            else:\n",
    "                # Check if the line contains only uppercase letters (valid sequence line)\n",
    "                if sequence_pattern.match(line.strip()):\n",
    "                    # Remove any whitespace and concatenate to the sequence\n",
    "                    uniprot_sequence += line.strip()\n",
    "                else:\n",
    "                    print('Invalid sequence format:', line)\n",
    "                    return None, None\n",
    "    \n",
    "    return uniprot_name, uniprot_sequence\n",
    "\n",
    "uniprot_filepath = '/Users/luna/Documents/RP1/2_do_cal_and_result/uniprot_seq.txt'\n",
    "uniprot_name, uniprot_sequence = extract_uniprot_data(uniprot_filepath)\n",
    "print(f'The Uniprot sequence of {uniprot_name} is loaded, length: {len(uniprot_sequence)}')\n",
    "print(uniprot_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment: \n",
      "\n",
      "target            0 MARTKQTARKSTGGKAPRKQLASKAARKSAPSTGGVKKPHRYKPGTVALREIRRFQKSTE\n",
      "                  0 --------------------------------------||||||||||||||||||||||\n",
      "query             0 --------------------------------------PHRYKPGTVALREIRRFQKSTE\n",
      "\n",
      "target           60 LLIRKLPFQRLVREIAQDFKTDLRFQSSAIGALQESVEAYLVSLFEDTNLAAIHAKRVTI\n",
      "                 60 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query            22 LLIRKLPFQRLVREIAQDFKTDLRFQSSAIGALQESVEAYLVSLFEDTNLAAIHAKRVTI\n",
      "\n",
      "target          120 QKKDIKLARRLRGERS 136\n",
      "                120 |||.|||||||||||- 136\n",
      "query            82 QKKEIKLARRLRGER-  97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2 Perform Alignment\n",
    "# 2.1\n",
    "def perform_global_alignment(uniprot_sequence, pdb_sequence):\n",
    "    # Initialize the aligner\n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'global'  # Perform global alignment\n",
    "    aligner.match_score = 1  # Score for identical characters\n",
    "    aligner.mismatch_score = 0  # Score for non-identical characters\n",
    "    aligner.open_gap_score = 0  # Score to open a gap\n",
    "    aligner.extend_gap_score = 0  # Score to extend a gap# Define two protein sequences to be aligned\n",
    "    # Set sequence\n",
    "    target = uniprot_sequence\n",
    "    query = pdb_sequence\n",
    "    # Perform the alignment\n",
    "    alignments = aligner.align(target, query)\n",
    "    # Get the best alignment (usually the first one)\n",
    "    best_alignment = alignments[8]\n",
    "    \n",
    "    return best_alignment\n",
    "\n",
    "alignment = perform_global_alignment(uniprot_sequence, pdb_sequence)\n",
    "print(f'Alignment: \\n\\n{alignment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned_uniprot\n",
      "MARTKQTARKSTGGKAPRKQLASKAARKSAPSTGGVKKPHRYKPGTVALREIRRFQKSTELLIRKLPFQRLVREIAQDFKTDLRFQSSAIGALQESVEAYLVSLFEDTNLAAIHAKRVTIQKKDIKLARRLRGERS\n",
      "aligned_pdb\n",
      "--------------------------------------PHRYKPGTVALREIRRFQKSTELLIRKLPFQRLVREIAQDFKTDLRFQSSAIGALQESVEAYLVSLFEDTNLAAIHAKRVTIQKKEIKLARRLRGER-\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "def extract_aligned_sequences_from_alignment(alignment):\n",
    "    # Convert the alignment object to a string\n",
    "    alignment_str = str(alignment)\n",
    "    \n",
    "    # Split the alignment into lines\n",
    "    lines = alignment_str.strip().split(\"\\n\")\n",
    "    \n",
    "    # Initialize variables to hold the aligned sequences\n",
    "    aligned_uniprot = ''\n",
    "    aligned_pdb = ''\n",
    "\n",
    "    # Process the alignment block by block\n",
    "    for i in range(0, len(lines), 4):   # Each block has 4 lines\n",
    "        # Extract parts of the target and query sequences\n",
    "        # by removes any leading or trailing whitespace with strip()\n",
    "        # and then splits the line into parts based on whitespace with split()\n",
    "        target_line_parts = lines[i].strip().split() \n",
    "        query_line_parts = lines[i+2].strip().split()\n",
    "        \n",
    "        # Check if the line starts with 'target' or 'query' and has at least 3 parts\n",
    "        if target_line_parts[0].startswith('target') and len(target_line_parts) > 2:\n",
    "            aligned_uniprot += target_line_parts[2]  # The sequence part is the third element\n",
    "        if query_line_parts[0].startswith('query') and len(query_line_parts) > 2:\n",
    "            aligned_pdb += query_line_parts[2]  # The sequence part is the third element\n",
    "    \n",
    "    return aligned_uniprot, aligned_pdb\n",
    "\n",
    "aligned_uniprot, aligned_pdb = extract_aligned_sequences_from_alignment(alignment)\n",
    "print(f'aligned_uniprot\\n{aligned_uniprot}')\n",
    "print(f'aligned_pdb\\n{aligned_pdb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  UniProt_Index UniProt_AA\n",
      "0        1              1          M\n",
      "1        2              2          A\n",
      "2        3              3          R\n",
      "3        4              4          T\n",
      "4        5              5          K\n",
      "..     ...            ...        ...\n",
      "131    132            132          R\n",
      "132    133            133          G\n",
      "133    134            134          E\n",
      "134    135            135          R\n",
      "135    136            136          S\n",
      "\n",
      "[136 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Generate dfs and dictionaries from previous data\n",
    "# 3.1\n",
    "def create_df_from_aligned_target(aligned_uniprot):\n",
    "    # Initialize a list to store the data for each row\n",
    "    data_list = []\n",
    "    uniprot_index = 1  # Initialize the UniProt index counter\n",
    "    \n",
    "    # Iterate over each character in the aligned target sequence\n",
    "    for index, aa in enumerate(aligned_uniprot, start=1):\n",
    "        # Check if the character is an amino acid (not a gap '-')\n",
    "        if aa != '-':\n",
    "            # Add the index, UniProt index, and amino acid to the list\n",
    "            data_list.append({'Index': index, 'UniProt_Index': uniprot_index, 'UniProt_AA': aa})\n",
    "            uniprot_index += 1  # Increment the UniProt index counter\n",
    "        else:\n",
    "            # If the character is a gap, add it to the list with an empty UniProt index\n",
    "            data_list.append({'Index': index, 'UniProt_Index': ' ', 'UniProt_AA': aa})\n",
    "    \n",
    "    # Create a DataFrame from the list of data\n",
    "    uniprot_df = pd.DataFrame(data_list)\n",
    "    \n",
    "    return uniprot_df\n",
    "\n",
    "uniprot_df = create_df_from_aligned_target(aligned_uniprot)\n",
    "print(uniprot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PDB_Index PDB_AA\n",
      "0                  -\n",
      "1                  -\n",
      "2                  -\n",
      "3                  -\n",
      "4                  -\n",
      "..        ...    ...\n",
      "131       132      R\n",
      "132       133      G\n",
      "133       134      E\n",
      "134       135      R\n",
      "135                -\n",
      "\n",
      "[136 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.2 \n",
    "# For substitution and Addition\n",
    "# (1)\n",
    "def create_df_from_aligned_query(data_df, aligned_pdb):\n",
    "    # Initialize a list to store the index and amino acid data\n",
    "    aa_data = []\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # index = data_df['NUM'].iloc[0]  # Initialize the index counter\n",
    "    index = 39\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # Iterate over each character in the aligned query sequence\n",
    "    for aa in aligned_pdb:\n",
    "        # Check if the character is an amino acid (not a gap '-')\n",
    "        if aa != '-':\n",
    "            # Add the index and amino acid to the list\n",
    "            aa_data.append({'PDB_Index': index, 'PDB_AA': aa})\n",
    "            index += 1  # Increment the index counter\n",
    "        else:\n",
    "            # If the character is a gap, add it to the list with an empty index\n",
    "            aa_data.append({'PDB_Index': ' ', 'PDB_AA': aa})\n",
    "    \n",
    "    # Create a DataFrame from the list of data\n",
    "    pdb_df = pd.DataFrame(aa_data)\n",
    "    \n",
    "    return pdb_df\n",
    "\n",
    "pdb_df = create_df_from_aligned_query(data_df, aligned_pdb)\n",
    "print(pdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alignment_df \n",
      "     Index  UniProt_Index UniProt_AA PDB_Index PDB_AA\n",
      "0        1              1          M                -\n",
      "1        2              2          A                -\n",
      "2        3              3          R                -\n",
      "3        4              4          T                -\n",
      "4        5              5          K                -\n",
      "..     ...            ...        ...       ...    ...\n",
      "131    132            132          R       132      R\n",
      "132    133            133          G       133      G\n",
      "133    134            134          E       134      E\n",
      "134    135            135          R       135      R\n",
      "135    136            136          S                -\n",
      "\n",
      "[136 rows x 5 columns]\n",
      "Contents of alignment_dict:\n",
      "(1, 'M') (' ', '-')\n",
      "(2, 'A') (' ', '-')\n",
      "(3, 'R') (' ', '-')\n",
      "(4, 'T') (' ', '-')\n",
      "(5, 'K') (' ', '-')\n",
      "(6, 'Q') (' ', '-')\n",
      "(7, 'T') (' ', '-')\n",
      "(8, 'A') (' ', '-')\n",
      "(9, 'R') (' ', '-')\n",
      "(10, 'K') (' ', '-')\n",
      "(11, 'S') (' ', '-')\n",
      "(12, 'T') (' ', '-')\n",
      "(13, 'G') (' ', '-')\n",
      "(14, 'G') (' ', '-')\n",
      "(15, 'K') (' ', '-')\n",
      "(16, 'A') (' ', '-')\n",
      "(17, 'P') (' ', '-')\n",
      "(18, 'R') (' ', '-')\n",
      "(19, 'K') (' ', '-')\n",
      "(20, 'Q') (' ', '-')\n",
      "(21, 'L') (' ', '-')\n",
      "(22, 'A') (' ', '-')\n",
      "(23, 'S') (' ', '-')\n",
      "(24, 'K') (' ', '-')\n",
      "(25, 'A') (' ', '-')\n",
      "(26, 'A') (' ', '-')\n",
      "(27, 'R') (' ', '-')\n",
      "(28, 'K') (' ', '-')\n",
      "(29, 'S') (' ', '-')\n",
      "(30, 'A') (' ', '-')\n",
      "(31, 'P') (' ', '-')\n",
      "(32, 'S') (' ', '-')\n",
      "(33, 'T') (' ', '-')\n",
      "(34, 'G') (' ', '-')\n",
      "(35, 'G') (' ', '-')\n",
      "(36, 'V') (' ', '-')\n",
      "(37, 'K') (' ', '-')\n",
      "(38, 'K') (' ', '-')\n",
      "(39, 'P') (39, 'P')\n",
      "(40, 'H') (40, 'H')\n",
      "(41, 'R') (41, 'R')\n",
      "(42, 'Y') (42, 'Y')\n",
      "(43, 'K') (43, 'K')\n",
      "(44, 'P') (44, 'P')\n",
      "(45, 'G') (45, 'G')\n",
      "(46, 'T') (46, 'T')\n",
      "(47, 'V') (47, 'V')\n",
      "(48, 'A') (48, 'A')\n",
      "(49, 'L') (49, 'L')\n",
      "(50, 'R') (50, 'R')\n",
      "(51, 'E') (51, 'E')\n",
      "(52, 'I') (52, 'I')\n",
      "(53, 'R') (53, 'R')\n",
      "(54, 'R') (54, 'R')\n",
      "(55, 'F') (55, 'F')\n",
      "(56, 'Q') (56, 'Q')\n",
      "(57, 'K') (57, 'K')\n",
      "(58, 'S') (58, 'S')\n",
      "(59, 'T') (59, 'T')\n",
      "(60, 'E') (60, 'E')\n",
      "(61, 'L') (61, 'L')\n",
      "(62, 'L') (62, 'L')\n",
      "(63, 'I') (63, 'I')\n",
      "(64, 'R') (64, 'R')\n",
      "(65, 'K') (65, 'K')\n",
      "(66, 'L') (66, 'L')\n",
      "(67, 'P') (67, 'P')\n",
      "(68, 'F') (68, 'F')\n",
      "(69, 'Q') (69, 'Q')\n",
      "(70, 'R') (70, 'R')\n",
      "(71, 'L') (71, 'L')\n",
      "(72, 'V') (72, 'V')\n",
      "(73, 'R') (73, 'R')\n",
      "(74, 'E') (74, 'E')\n",
      "(75, 'I') (75, 'I')\n",
      "(76, 'A') (76, 'A')\n",
      "(77, 'Q') (77, 'Q')\n",
      "(78, 'D') (78, 'D')\n",
      "(79, 'F') (79, 'F')\n",
      "(80, 'K') (80, 'K')\n",
      "(81, 'T') (81, 'T')\n",
      "(82, 'D') (82, 'D')\n",
      "(83, 'L') (83, 'L')\n",
      "(84, 'R') (84, 'R')\n",
      "(85, 'F') (85, 'F')\n",
      "(86, 'Q') (86, 'Q')\n",
      "(87, 'S') (87, 'S')\n",
      "(88, 'S') (88, 'S')\n",
      "(89, 'A') (89, 'A')\n",
      "(90, 'I') (90, 'I')\n",
      "(91, 'G') (91, 'G')\n",
      "(92, 'A') (92, 'A')\n",
      "(93, 'L') (93, 'L')\n",
      "(94, 'Q') (94, 'Q')\n",
      "(95, 'E') (95, 'E')\n",
      "(96, 'S') (96, 'S')\n",
      "(97, 'V') (97, 'V')\n",
      "(98, 'E') (98, 'E')\n",
      "(99, 'A') (99, 'A')\n",
      "(100, 'Y') (100, 'Y')\n",
      "(101, 'L') (101, 'L')\n",
      "(102, 'V') (102, 'V')\n",
      "(103, 'S') (103, 'S')\n",
      "(104, 'L') (104, 'L')\n",
      "(105, 'F') (105, 'F')\n",
      "(106, 'E') (106, 'E')\n",
      "(107, 'D') (107, 'D')\n",
      "(108, 'T') (108, 'T')\n",
      "(109, 'N') (109, 'N')\n",
      "(110, 'L') (110, 'L')\n",
      "(111, 'A') (111, 'A')\n",
      "(112, 'A') (112, 'A')\n",
      "(113, 'I') (113, 'I')\n",
      "(114, 'H') (114, 'H')\n",
      "(115, 'A') (115, 'A')\n",
      "(116, 'K') (116, 'K')\n",
      "(117, 'R') (117, 'R')\n",
      "(118, 'V') (118, 'V')\n",
      "(119, 'T') (119, 'T')\n",
      "(120, 'I') (120, 'I')\n",
      "(121, 'Q') (121, 'Q')\n",
      "(122, 'K') (122, 'K')\n",
      "(123, 'K') (123, 'K')\n",
      "(124, 'D') (124, 'E')\n",
      "(125, 'I') (125, 'I')\n",
      "(126, 'K') (126, 'K')\n",
      "(127, 'L') (127, 'L')\n",
      "(128, 'A') (128, 'A')\n",
      "(129, 'R') (129, 'R')\n",
      "(130, 'R') (130, 'R')\n",
      "(131, 'L') (131, 'L')\n",
      "(132, 'R') (132, 'R')\n",
      "(133, 'G') (133, 'G')\n",
      "(134, 'E') (134, 'E')\n",
      "(135, 'R') (135, 'R')\n",
      "(136, 'S') (' ', '-')\n"
     ]
    }
   ],
   "source": [
    "(2)\n",
    "def create_alignment_df_and_dict(uniprot_df, pdb_df):\n",
    "    # Merge the two DataFrames on their index\n",
    "    alignment_df = pd.merge(uniprot_df, pdb_df, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    # Initialize an empty dictionary to store the data\n",
    "    alignment_dict = {}\n",
    "    # Iterate over each row in the combined DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Create a key-value pair with the desired columns\n",
    "        key = (row['Index'], row['UniProt_AA'])\n",
    "        value = (row['PDB_Index'], row['PDB_AA'])\n",
    "        \n",
    "        # Add the key-value pair to the dictionary\n",
    "        alignment_dict[key] = value\n",
    "    \n",
    "    return alignment_df, alignment_dict\n",
    "\n",
    "alignment_df, alignment_dict = create_alignment_df_and_dict(uniprot_df, pdb_df)\n",
    "print(f'alignment_df \\n{alignment_df}')\n",
    "\n",
    "print(\"Contents of alignment_dict:\")\n",
    "for key, value in alignment_dict.items():\n",
    "    print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3.2\n",
    "# # For deletion\n",
    "# def create_alignment_df_and_dict(uniprot_df, aligned_pdb):\n",
    "#     # Initialize the 'PDB_Index' column with empty strings\n",
    "#     uniprot_df['PDB_Index'] = ''\n",
    "#     # Add the 'PDB_AA' column to uniprot_df with the characters from aligned_pdb\n",
    "#     uniprot_df['PDB_AA'] = list(aligned_pdb)\n",
    "#     # Create the alignment DataFrame with the correct column order\n",
    "#     alignment_df =uniprot_df\n",
    "    \n",
    "#     # Iterate over the DataFrame and update 'PDB_Index' based on the condition\n",
    "#     for i, aa in enumerate(uniprot_df['PDB_AA']):\n",
    "#         if aa != '-':\n",
    "#             uniprot_df.at[i, 'PDB_Index'] = uniprot_df.at[i, 'UniProt_Index']\n",
    "    \n",
    "#     alignment_df = alignment_df[['Index', 'UniProt_Index', 'UniProt_AA', 'PDB_Index', 'PDB_AA']]\n",
    "    \n",
    "#     # Initialize an empty dictionary to store the data\n",
    "#     alignment_dict = {}\n",
    "#     # Iterate over each row in the combined DataFrame\n",
    "#     for index, row in alignment_df.iterrows():\n",
    "#         # Create a key-value pair with the desired columns\n",
    "#         key = (row['Index'], row['UniProt_AA'])\n",
    "#         value = (row['PDB_Index'], row['PDB_AA'])\n",
    "        \n",
    "#         # Add the key-value pair to the dictionary\n",
    "#         alignment_dict[key] = value\n",
    "    \n",
    "#     return alignment_df, alignment_dict\n",
    "\n",
    "# # Deletion\n",
    "# print('\\nDeletion')\n",
    "# alignment_df, alignment_dict = create_alignment_df_and_dict(uniprot_df, aligned_pdb)\n",
    "# print('alignment_df')\n",
    "# print(alignment_df)\n",
    "\n",
    "# print('\\nalignment_dict')\n",
    "# for key, value in alignment_dict.items():\n",
    "#     print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of mapping_dict:\n",
      "(39, 'P') 0.0\n",
      "(40, 'H') 0.0\n",
      "(41, 'R') 0.0\n",
      "(42, 'Y') 0.0\n",
      "(43, 'K') 0.0\n",
      "(44, 'P') 0.0\n",
      "(45, 'G') 14.18\n",
      "(46, 'T') 0.0\n",
      "(47, 'V') 0.0\n",
      "(48, 'A') 40.34\n",
      "(49, 'L') 21.08\n",
      "(50, 'R') 0.0\n",
      "(51, 'E') 37.98\n",
      "(52, 'I') 66.48\n",
      "(53, 'R') 0.0\n",
      "(54, 'R') 0.0\n",
      "(55, 'F') 64.02\n",
      "(56, 'Q') 41.94\n",
      "(57, 'K') 0.0\n",
      "(58, 'S') 7.08\n",
      "(59, 'T') 11.32\n",
      "(60, 'E') 6.06\n",
      "(61, 'L') 0.51\n",
      "(62, 'L') 84.96\n",
      "(63, 'I') 59.59\n",
      "(64, 'R') 26.76\n",
      "(65, 'K') 0.0\n",
      "(66, 'L') 0.0\n",
      "(67, 'P') 33.76\n",
      "(68, 'F') 21.93\n",
      "(69, 'Q') 0.0\n",
      "(70, 'R') 49.23\n",
      "(71, 'L') 84.22\n",
      "(72, 'V') 15.86\n",
      "(73, 'R') 0.0\n",
      "(74, 'E') 43.46\n",
      "(75, 'I') 85.99\n",
      "(76, 'A') 12.56\n",
      "(77, 'Q') 0.0\n",
      "(78, 'D') 0.0\n",
      "(79, 'F') 105.56\n",
      "(80, 'K') 67.43\n",
      "(81, 'T') 0.0\n",
      "(82, 'D') 12.2\n",
      "(83, 'L') 52.3\n",
      "(84, 'R') 55.21\n",
      "(85, 'F') 35.82\n",
      "(86, 'Q') 71.64\n",
      "(87, 'S') 0.0\n",
      "(88, 'S') 30.91\n",
      "(89, 'A') 38.99\n",
      "(90, 'I') 0.0\n",
      "(91, 'G') 8.16\n",
      "(92, 'A') 64.4\n",
      "(93, 'L') 73.75\n",
      "(94, 'Q') 0.0\n",
      "(95, 'E') 31.21\n",
      "(96, 'S') 58.85\n",
      "(97, 'V') 48.13\n",
      "(98, 'E') 8.58\n",
      "(99, 'A') 3.92\n",
      "(100, 'Y') 75.1\n",
      "(101, 'L') 67.37\n",
      "(102, 'V') 56.86\n",
      "(103, 'S') 2.91\n",
      "(104, 'L') 6.68\n",
      "(105, 'F') 93.91\n",
      "(106, 'E') 23.24\n",
      "(107, 'D') 0.0\n",
      "(108, 'T') 0.0\n",
      "(109, 'N') 39.28\n",
      "(110, 'L') 0.0\n",
      "(111, 'A') 0.0\n",
      "(112, 'A') 0.0\n",
      "(113, 'I') 0.0\n",
      "(114, 'H') 0.0\n",
      "(115, 'A') 0.0\n",
      "(116, 'K') 0.0\n",
      "(117, 'R') 0.0\n",
      "(118, 'V') 45.66\n",
      "(119, 'T') 70.98\n",
      "(120, 'I') 68.82\n",
      "(121, 'Q') 20.37\n",
      "(122, 'K') 74.88\n",
      "(123, 'K') 0.0\n",
      "(124, 'E') 0.0\n",
      "(125, 'I') 58.03\n",
      "(126, 'K') 14.38\n",
      "(127, 'L') 0.0\n",
      "(128, 'A') 0.0\n",
      "(129, 'R') 33.29\n",
      "(130, 'R') 0.0\n",
      "(131, 'L') 0.0\n",
      "(132, 'R') 2.55\n",
      "(133, 'G') 0.0\n",
      "(134, 'E') 0.0\n",
      "(135, 'R') 0.0\n"
     ]
    }
   ],
   "source": [
    "# 3.3\n",
    "def create_aa_rel_dict(data_df):\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Reset the 'NUM' column of the DataFrame starting from a designated number \n",
    "    # --- which is the index of matching aa in the UniProt sequence\n",
    "    # Find the difference between the current minimum and 25\n",
    "    diff = 39 - data_df['NUM'].min()\n",
    "    # Add this difference to each value in the ['NUM'] column\n",
    "    data_df['NUM'] += diff\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # Initialize an empty dictionary\n",
    "    aa_rel_dict = {}\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for pdb_index, row in data_df.iterrows():\n",
    "        # Add the key-value pair to the dictionary\n",
    "        aa_rel_dict[(row['NUM'], row['AA'])] = row['ABS']\n",
    "        \n",
    "    return aa_rel_dict\n",
    "\n",
    "aa_rel_dict = create_aa_rel_dict(data_df)\n",
    "# Debugging: Print the contents of aa_rel_dict\n",
    "print(\"Contents of mapping_dict:\")\n",
    "for key, value in aa_rel_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported result in file 1id3_A_P61830_cal.csv \n",
      "     Index  UniProt_Index UniProt_AA PDB_Index PDB_AA   ABS\n",
      "0        1              1          M                -      \n",
      "1        2              2          A                -      \n",
      "2        3              3          R                -      \n",
      "3        4              4          T                -      \n",
      "4        5              5          K                -      \n",
      "..     ...            ...        ...       ...    ...   ...\n",
      "131    132            132          R       132      R  2.55\n",
      "132    133            133          G       133      G   0.0\n",
      "133    134            134          E       134      E   0.0\n",
      "134    135            135          R       135      R   0.0\n",
      "135    136            136          S                -      \n",
      "\n",
      "[136 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.4\n",
    "def update_alignment_df_with_REL_values(uniprot_name, pdb_name, chain_id, alignment_df, alignment_dict, aa_rel_dict):\n",
    "    \n",
    "    def lookup_value(row, alignment_dict, aa_rel_dict):\n",
    "        # Construct the key from the current row's 'Index' and 'UniProt_AA'\n",
    "        key = (row['Index'], row['UniProt_AA'])\n",
    "        # Get the corresponding PDB key from the alignment_dict using the constructed key\n",
    "        pdb_key = alignment_dict.get(key)\n",
    "        # Get the REL value from aa_rel_dict using the PDB key, if it exists\n",
    "        rel_value = aa_rel_dict.get(pdb_key) if pdb_key else None\n",
    "        \n",
    "        return rel_value\n",
    "\n",
    "    # Use the apply() function to apply the lookup_value function to each row of alignment_df\n",
    "    # Pass additional arguments alignment_dict and aa_rel_dict using args parameter\n",
    "    # The result is a new 'Value' column in alignment_df\n",
    "    alignment_df['ABS'] = alignment_df.apply(lookup_value, axis=1, args=(alignment_dict, aa_rel_dict))\n",
    "    # Replace NaN values with an empty string in the 'Value' column\n",
    "    alignment_df['ABS'] = alignment_df['ABS'].fillna('')\n",
    "    \n",
    "    # Write the updated DataFrame to a CSV file\n",
    "    filename = f'{pdb_name}_{chain_id}_{uniprot_name}_cal.csv'\n",
    "    alignment_df.to_csv(filename, index=False)\n",
    "    \n",
    "    return alignment_df\n",
    "\n",
    "alignment_df = update_alignment_df_with_REL_values(uniprot_name, pdb_name, chain_id, alignment_df, alignment_dict, aa_rel_dict)\n",
    "print(f'\\nExported result in file {pdb_name}_{chain_id}_{uniprot_name}_cal.csv ')\n",
    "print(alignment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Calculate the moment(M) of proteins (The truncated protein in the elute)\n",
    "def calculate_moment(r,n,m):\n",
    "    # Initialize the sum\n",
    "    total_sum = 0   \n",
    "    # Calculate the sum of r * (i - m) from i=0 to n\n",
    "    for i in range(n + 1):  # range(n+1) because the upper limit is inclusive\n",
    "        total_sum += r * (i - m)\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PDB model 1id3, chain A encoded protein, with respect to the UniProt sequence P61830\n",
      "n = 136\n",
      "m = 68.5\n",
      "Absolute Moment(M_abs) = 43248.07\n"
     ]
    }
   ],
   "source": [
    "# Part 4 Calculate the moment(M) of proteins (The truncated protein in the elute)\n",
    "'''\n",
    "- n is the total length of UniProt sequence (n = max(UniProt_Index)).\n",
    "- m is the middle value that can separate the UniProt sequence into equivalent upper and lower two sections.\n",
    "  This is to make sure the REl value for aa counting form both ends has the same weight\n",
    "  (so they can counter each other).\n",
    "- i is the UniProt_Index of each PDB aa.\n",
    "- r is the REL value of each PDB aa, when the REL is not 0.0 and there is a corresponding UniProt aa for the PDB aa.\n",
    "  This is to make sure the calculation is based on the UniProt sequence\n",
    "  (So any addition from the PDB sequence would not affect the calculation).\n",
    "'''\n",
    "\n",
    "# The absolute moment\n",
    "def calculate_absolute_moment(alignment_df):\n",
    "    # Determine the middle position 'm' of the sequence\n",
    "    alignment_df['UniPort_Index'] = pd.to_numeric(alignment_df['UniProt_Index'], errors='coerce')\n",
    "    n = alignment_df['UniPort_Index'].max()\n",
    "    print(f'n = {n}')\n",
    "    m = (n / 2) + 0.5 \n",
    "    print(f'm = {m}')\n",
    "\n",
    "    # Initialize the sum\n",
    "    total_sum = 0\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Check if 'ABS' is numeric, not blank, greater than 0.0, and 'UniProt_AA' is not '-'\n",
    "        if pd.notnull(row['ABS']) and row['ABS'] != '' and row['ABS'] > 0.0 and row['UniProt_AA'] != '-':\n",
    "            r = float(row['ABS'])\n",
    "            i = row['UniPort_Index']\n",
    "            sum = r * (i - m)\n",
    "            # print(i)\n",
    "            # print(f'sum = {r} * ({i} - {m}) = {sum}')\n",
    "            \n",
    "            total_sum += sum\n",
    "    \n",
    "    # Round the total sum to 2 decimal places after the loop\n",
    "    total_sum = round(total_sum, 2)\n",
    "\n",
    "    print(f'Absolute Moment(M_abs) = {total_sum}')\n",
    "    return total_sum\n",
    "\n",
    "print(f'For PDB model {pdb_name}, chain {chain_id} encoded protein, with respect to the UniProt sequence {uniprot_name}')\n",
    "M_abs = calculate_absolute_moment(alignment_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PDB model 1id3, chain A encoded protein, with respect to the UniPort sequence P61830\n",
      "n = 136\n",
      "m = 68.5\n",
      "sum = 0.006032297037452991 * -0.17647058823529413 = -0.0010645230066093515\n",
      "sum = 0.017160991713036228 * -0.15441176470588236 = -0.002649859014512947\n",
      "sum = 0.008967617880783431 * -0.14705882352941177 = -0.0013187673354093281\n",
      "sum = 0.01615702690285364 * -0.1323529411764706 = -0.0021384300312600408\n",
      "sum = 0.028281178212261983 * -0.125 = -0.003535147276532748\n",
      "sum = 0.027234672520291995 * -0.10294117647058823 = -0.002803569230030058\n",
      "sum = 0.017841645821634586 * -0.09558823529411764 = -0.0017054514388327177\n",
      "sum = 0.003011894430547756 * -0.08088235294117647 = -0.00024360910835312735\n",
      "sum = 0.004815627818333418 * -0.07352941176470588 = -0.00035409028075981014\n",
      "sum = 0.0025779774363162995 * -0.0661764705882353 = -0.00017060144799151982\n",
      "sum = 0.0002169584971157282 * -0.058823529411764705 = -1.2762264536219306e-05\n",
      "sum = 0.03614273316657307 * -0.051470588235294115 = -0.0018602877365147903\n",
      "sum = 0.025350111457110282 * -0.04411764705882353 = -0.0011183872701666302\n",
      "sum = 0.011383939966307622 * -0.03676470588235294 = -0.00041852720464366256\n",
      "sum = 0.014361801691425457 * -0.014705882352941176 = -0.00021120296605037437\n",
      "sum = 0.009329215375976313 * -0.007352941176470588 = -6.859717188217877e-05\n",
      "sum = 0.02094287610393588 * 0.014705882352941176 = 0.00030798347211670414\n",
      "sum = 0.03582793064134633 * 0.022058823529411766 = 0.0007903219994414633\n",
      "sum = 0.0067469838514812724 * 0.029411764705882353 = 0.00019844070151415507\n",
      "sum = 0.018488267224803033 * 0.04411764705882353 = 0.000815658848153075\n",
      "sum = 0.03658090424898327 * 0.051470588235294115 = 0.0018828406598741388\n",
      "sum = 0.005343134752497149 * 0.058823529411764705 = 0.0003143020442645382\n",
      "sum = 0.044906154814777 * 0.08088235294117647 = 0.0036321154629599043\n",
      "sum = 0.02868531658924226 * 0.08823529411764706 = 0.0025310573461096116\n",
      "sum = 0.005189987578062517 * 0.10294117647058823 = 0.0005342634271534944\n",
      "sum = 0.02224888117480899 * 0.11029411764705882 = 0.0024539207178098147\n",
      "sum = 0.023486820834822262 * 0.11764705882352941 = 0.002763155392332031\n",
      "sum = 0.015238143856245851 * 0.125 = 0.0019047679820307314\n",
      "sum = 0.030476287712491702 * 0.1323529411764706 = 0.004033626314888608\n",
      "sum = 0.013149386560484625 * 0.14705882352941177 = 0.0019337333177183273\n",
      "sum = 0.016586689808906357 * 0.15441176470588236 = 0.002561180044022305\n",
      "sum = 0.003471335953851651 * 0.16911764705882354 = 0.0005870641686660881\n",
      "sum = 0.02739632787108411 * 0.17647058823529413 = 0.004834646094897196\n",
      "sum = 0.03137390031820579 * 0.18382352941176472 = 0.005767261087905476\n",
      "sum = 0.013277009205846818 * 0.19852941176470587 = 0.0026358768276313533\n",
      "sum = 0.025035308931883538 * 0.20588235294117646 = 0.005154328309505434\n",
      "sum = 0.020474926404274507 * 0.21323529411764705 = 0.004365976953852652\n",
      "sum = 0.003650007657358721 * 0.22058823529411764 = 0.0008051487479467767\n",
      "sum = 0.0016676025660659892 * 0.22794117647058823 = 0.00038011529079445345\n",
      "sum = 0.03194820222233566 * 0.23529411764705882 = 0.007517224052314272\n",
      "sum = 0.02865979206016982 * 0.2426470588235294 = 0.006954214249894147\n",
      "sum = 0.024188745384314324 * 0.25 = 0.006047186346078581\n",
      "sum = 0.0012379396600132727 * 0.25735294117647056 = 0.00031858741250341576\n",
      "sum = 0.002841730903398165 * 0.2647058823529412 = 0.0007522228861936319\n",
      "sum = 0.03995014208654516 * 0.27205882352941174 = 0.010868788655898316\n",
      "sum = 0.00988650092739122 * 0.27941176470588236 = 0.0027624046708887235\n",
      "sum = 0.01671005836608981 * 0.3014705882352941 = 0.005037591125071193\n",
      "sum = 0.019424166624125782 * 0.36764705882352944 = 0.007141237729458009\n",
      "sum = 0.030195517892694878 * 0.375 = 0.011323319209760579\n",
      "sum = 0.02927663484608708 * 0.38235294117647056 = 0.011194007441150943\n",
      "sum = 0.008665577620092908 * 0.3897058823529412 = 0.003377026572536207\n",
      "sum = 0.03185461228240338 * 0.39705882352941174 = 0.012648154876836636\n",
      "sum = 0.024686473701226876 * 0.41911764705882354 = 0.010346536771837734\n",
      "sum = 0.006117378801027787 * 0.4264705882352941 = 0.0026088821357324386\n",
      "sum = 0.014161859547024688 * 0.4485294117647059 = 0.006352010532121368\n",
      "sum = 0.0010847924855786409 * 0.47058823529411764 = 0.0005104905814487722\n",
      "Relative Moment(M_rel) = 0.14\n"
     ]
    }
   ],
   "source": [
    "# The relative moment\n",
    "def calculate_relative_moment(alignment_df):\n",
    "    # Convert 'UniProt_Index' to numeric and handle errors\n",
    "    alignment_df['UniProt_Index'] = pd.to_numeric(alignment_df['UniProt_Index'], errors='coerce')\n",
    "    n = alignment_df['UniProt_Index'].max()\n",
    "    print(f'n = {n}')\n",
    "    m = (n / 2) + 0.5 \n",
    "    print(f'm = {m}')\n",
    "    \n",
    "    # Initialize values\n",
    "    total_sum = 0\n",
    "    # Handle non-numeric values in 'ABS' column\n",
    "    alignment_df['ABS'] = pd.to_numeric(alignment_df['ABS'], errors='coerce')\n",
    "    # Drop rows with NaN values in 'ABS' column\n",
    "    alignment_df = alignment_df.dropna(subset=['ABS'])\n",
    "    total_r = alignment_df['ABS'].sum()\n",
    "    \n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Check if 'ABS' is numeric, not blank, greater than 0.0, and 'UniProt_AA' is not '-'\n",
    "        if pd.notnull(row['ABS']) and row['ABS'] != '' and row['ABS'] > 0.0 and row['UniProt_AA'] != '-':\n",
    "            r = float(row['ABS'])\n",
    "            i = row['UniProt_Index']\n",
    "            # Calculate the relative position with respect to 'm' for for odd residue number\n",
    "            if n % 2 == 1:\n",
    "                if i == m:\n",
    "                    relative_i = 0\n",
    "                else:\n",
    "                    relative_i = (i - m) / n\n",
    "            # Calculate the relative position with respect to 'm' for for odd residue number\n",
    "            if n % 2 == 0:\n",
    "                if i < m:\n",
    "                    relative_i = ((i - m) - 0.5) / n\n",
    "                elif i > m:\n",
    "                    relative_i = ((i - m) + 0.5) / n\n",
    "            \n",
    "            relative_r = r / total_r\n",
    "            \n",
    "            line_sum = relative_r * relative_i\n",
    "            print(f'sum = {relative_r} * {relative_i} = {line_sum}')\n",
    "            \n",
    "            total_sum += line_sum\n",
    "    \n",
    "    # Round the total sum to 2 decimal places after the loop\n",
    "    total_sum = round(total_sum, 2)\n",
    "\n",
    "    print(f'Relative Moment(M_rel) = {total_sum}')\n",
    "    return total_sum\n",
    "\n",
    "print(f'For PDB model {pdb_name}, chain {chain_id} encoded protein, with respect to the UniPort sequence {uniprot_name}')\n",
    "M_rel = calculate_relative_moment(alignment_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
