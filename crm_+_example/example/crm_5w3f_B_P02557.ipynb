{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys, os \n",
    "import argparse\n",
    "from Bio import Align\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded relevant information of 5w3f, chain B, from 5w3f_B-AB.csv\n",
      "     NUM   AA    ABS\n",
      "0      1  MET  65.54\n",
      "1      2  ARG  13.07\n",
      "2      3  GLU   0.00\n",
      "3      4  ILE   0.00\n",
      "4      5  ILE   0.00\n",
      "..   ...  ...    ...\n",
      "422  423  GLN   0.00\n",
      "423  424  GLN   4.76\n",
      "424  425  TYR  42.50\n",
      "425  426  GLN   0.00\n",
      "426  427  GLU   0.00\n",
      "\n",
      "[427 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part 1 Prepare data\n",
    "# 1.1\n",
    "def extract_pdb_name_and_generate_df(filepath):\n",
    "    # Read the table from the file, assuming comma separation\n",
    "    # Skip the first two rows which contain 'REM' and 'All-atoms'\n",
    "    df = pd.read_csv(filepath, delimiter=',', skiprows=1)\n",
    "    # print(f'df generated from file path: {filepath} \\n{df}')\n",
    "    # Extract the PDB name from the file name\n",
    "    basename = os.path.basename(filepath)\n",
    "    pdb_name = basename.split('_')[0]\n",
    "    rest_name = basename.split('_')[1]\n",
    "    chain_id = rest_name.split('-')[0]\n",
    "    \n",
    "    # Create a new DataFrame that only retains information from column index 1, 3, and 4\n",
    "    # which are the aa, index, ABS\n",
    "    selected_indices = [1, 3, 4]\n",
    "    data_df = df.iloc[: ,selected_indices]\n",
    "    # Swap the aa and the index columns\n",
    "    cols = list(data_df.columns)\n",
    "    cols[0], cols[1] = cols[1], cols[0]  # Swap the column names\n",
    "    data_df = data_df[cols]  # Reindex the DataFrame with the new column order\n",
    "    # Assign new column names to the DataFrame\n",
    "    data_df.columns = ['NUM', 'AA', 'ABS']\n",
    "    data_df = data_df[['NUM', 'AA', 'ABS']]\n",
    "    \n",
    "    return basename, pdb_name, chain_id, data_df\n",
    "\n",
    "filepath = '/Users/luna/Documents/RP1/2_do_cal_and_result/5w3f_B-AB.csv'\n",
    "basename, pdb_name, chain_id, data_df = extract_pdb_name_and_generate_df(filepath)\n",
    "print(f'Loaded relevant information of {pdb_name}, chain {chain_id}, from {basename}')\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "def convert_three_letter_code_to_one_letter_code(three_letter_list):\n",
    "    aa_dict = {\n",
    "        'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D',\n",
    "        'CYS': 'C', 'GLU': 'E', 'GLN': 'Q', 'GLY': 'G',\n",
    "        'HIS': 'H', 'ILE': 'I', 'LEU': 'L', 'LYS': 'K',\n",
    "        'MET': 'M', 'PHE': 'F', 'PRO': 'P', 'SER': 'S',\n",
    "        'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',\n",
    "        # Additional potential codes\n",
    "        'SEC': 'U', 'PYL': 'O', 'ASX': 'B', 'GLX': 'Z',\n",
    "        'XLE': 'J', 'XAA': 'X', 'TER': '*', 'UNK': 'X'}\n",
    "    one_letter_list = []\n",
    "    for aa in three_letter_list:\n",
    "        one_letter_code = aa_dict.get(aa, 'X')  # Default to 'X' if aa is not found\n",
    "        one_letter_list.append(one_letter_code)\n",
    "        \n",
    "    return one_letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NUM AA    ABS\n",
      "0      1  M  65.54\n",
      "1      2  R  13.07\n",
      "2      3  E   0.00\n",
      "3      4  I   0.00\n",
      "4      5  I   0.00\n",
      "..   ... ..    ...\n",
      "422  423  Q   0.00\n",
      "423  424  Q   4.76\n",
      "424  425  Y  42.50\n",
      "425  426  Q   0.00\n",
      "426  427  E   0.00\n",
      "\n",
      "[427 rows x 3 columns]\n",
      "The PDB sequence of 5w3f is loaded, length: 427\n",
      "MREIIHISTGQCGNQIGAAFWETICGEHGLDFNGTYHGHDDIQKERLNVYFNEASSGKWVPRSINVDLEPGTIDAVRNSAIGNLFRPDNYIFGQSSAGNVWAKGHYTEGAELVDSVMDVIRREAEGCDSLQGFQITHSLGGGTGSGMGTLLISKIREEFPDRMMATFSVLPSPKTSDTVVEPYNATLSVHQLVEHSDETFCIDNEALYDICQRTLKLNQPSYGDLNNLVSSVMSGVTTSLRYPGQLNSDLRKLAVNLVPFPRLHFFMVGYAPLTAIGSQSFRSLTVPELTQQMFDAKNMMAAADPRNGRYLTVAAFFRGKVSVKEVEDEMHKVQSKNSDYFVEWIPNNVQTAVCSVAPQGLDMAATFIANSTSIQELFKRVGDQFSAMFKRKAFLHWYTSEGMDELEFSEAESNMNDLVSEYQQYQE\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "def process_df_and_generate_sequence_string(data_df):\n",
    "    # Convert the second column (amino acids) to a list of three-letter codes\n",
    "    three_letter_list = data_df.iloc[:, 1].tolist()\n",
    "    # Convert the three-letter codes to one-letter codes using the function\n",
    "    one_letter_list = convert_three_letter_code_to_one_letter_code(three_letter_list)\n",
    "    # Replace the second column with the one-letter codes\n",
    "    data_df.iloc[:, 1] = one_letter_list\n",
    "    \n",
    "    # Generate the PDB sequence \n",
    "    pdb_sequence = ''.join(one_letter_list)\n",
    "    \n",
    "    return pdb_sequence, data_df\n",
    "\n",
    "pdb_sequence, data_df = process_df_and_generate_sequence_string(data_df)\n",
    "print(data_df)\n",
    "print(f'The PDB sequence of {pdb_name} is loaded, length: {len(pdb_sequence)}')\n",
    "print(pdb_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the corresponding sequence in PDB model 5w3f, the PDB aa range: \n",
      "min: 1, max: 427\n",
      "\n",
      "Identified PDB aa block:\n",
      "1(M)-427(E)\n",
      "\n",
      "Missing PDB aa:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1.4\n",
    "def identify_aa_blocks(pdb_name, data_df):\n",
    "    # Find the smallest and largest NUM values\n",
    "    min_num = data_df['NUM'].min()\n",
    "    max_num = data_df['NUM'].max()\n",
    "    \n",
    "    # Generate the full range of numbers from min_num to max_num\n",
    "    full_range = set(range(int(min_num), int(max_num) + 1))\n",
    "    print(f'For the corresponding sequence in PDB model {pdb_name}, the PDB aa range: \\nmin: {min_num}, max: {max_num}')\n",
    "    \n",
    "    # Get the set of NUM values that actually appear in the DataFrame\n",
    "    actual_nums = set(data_df['NUM'])\n",
    "    \n",
    "    # Find the set of numbers that are missing from the DataFrame\n",
    "    missing_nums = sorted(full_range - actual_nums)\n",
    "    \n",
    "    # Identify the existing PDB aa blocks\n",
    "    print('\\nIdentified PDB aa block:')\n",
    "    current_block_start = None\n",
    "    for num in sorted(actual_nums):\n",
    "        if current_block_start is None:\n",
    "            current_block_start = num\n",
    "        # If the next number is missing or it's the last number, end the current block\n",
    "        if num + 1 not in actual_nums or num == max_num:\n",
    "            # Get the AA for the start and end of the block\n",
    "            start_aa = data_df.loc[data_df['NUM'] == current_block_start, 'AA'].values[0]\n",
    "            end_aa = data_df.loc[data_df['NUM'] == num, 'AA'].values[0]\n",
    "            print(f'{current_block_start}({start_aa})-{num}({end_aa})')\n",
    "            current_block_start = None\n",
    "    \n",
    "    # Print missing PDB aa\n",
    "    print('\\nMissing PDB aa:')\n",
    "    if not missing_nums:\n",
    "        print('None')\n",
    "    else:\n",
    "        missing_block_start = None\n",
    "        for i, num in enumerate(missing_nums):\n",
    "            if missing_block_start is None:\n",
    "                missing_block_start = num\n",
    "            # If the next number is not consecutive or it's the last missing number, end the current block\n",
    "            if i + 1 == len(missing_nums) or missing_nums[i + 1] != num + 1:\n",
    "                if missing_block_start == num:\n",
    "                    print(missing_block_start)\n",
    "                else:\n",
    "                    print(f'{missing_block_start}-{num}')\n",
    "                missing_block_start = None\n",
    "\n",
    "identify_aa_blocks(pdb_name, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Uniprot sequence of P02557 is loaded, length: 457\n",
      "MREIIHISTGQCGNQIGAAFWETICGEHGLDFNGTYHGHDDIQKERLNVYFNEASSGKWVPRSINVDLEPGTIDAVRNSAIGNLFRPDNYIFGQSSAGNVWAKGHYTEGAELVDSVMDVIRREAEGCDSLQGFQITHSLGGGTGSGMGTLLISKIREEFPDRMMATFSVLPSPKTSDTVVEPYNATLSVHQLVEHSDETFCIDNEALYDICQRTLKLNQPSYGDLNNLVSSVMSGVTTSLRYPGQLNSDLRKLAVNLVPFPRLHFFMVGYAPLTAIGSQSFRSLTVPELTQQMFDAKNMMAAADPRNGRYLTVAAFFRGKVSVKEVEDEMHKVQSKNSDYFVEWIPNNVQTAVCSVAPQGLDMAATFIANSTSIQELFKRVGDQFSAMFKRKAFLHWYTSEGMDELEFSEAESNMNDLVSEYQQYQEATVEDDEEVDENGDFGAPQNQDEPITENFE\n"
     ]
    }
   ],
   "source": [
    "# 1.5\n",
    "def extract_uniprot_data(uniprot_filepath):\n",
    "    # Initialize an empty string to hold the sequence\n",
    "    uniprot_sequence = ''\n",
    "    # Initialize a variable to hold the UniProt name\n",
    "    uniprot_name = ''\n",
    "    \n",
    "    # Compile the regular expressions for the header and sequence lines\n",
    "    header_pattern = re.compile(r'^>sp\\|(\\w+)\\|')\n",
    "    sequence_pattern = re.compile(r'^[A-Z]+$')\n",
    "    \n",
    "    # Open the file for reading\n",
    "    with open(uniprot_filepath, 'r') as file:\n",
    "        # Iterate over each line in the file\n",
    "        for line in file:\n",
    "            # Check if the line is a header (starts with '>')\n",
    "            if line.startswith('>'):\n",
    "                # Use the regular expression to extract the UniProt name\n",
    "                header_match = header_pattern.match(line)\n",
    "                if header_match:\n",
    "                    uniprot_name = header_match.group(1)\n",
    "                else:\n",
    "                    print('Invalid header format:', line)\n",
    "                    return None, None\n",
    "            else:\n",
    "                # Check if the line contains only uppercase letters (valid sequence line)\n",
    "                if sequence_pattern.match(line.strip()):\n",
    "                    # Remove any whitespace and concatenate to the sequence\n",
    "                    uniprot_sequence += line.strip()\n",
    "                else:\n",
    "                    print('Invalid sequence format:', line)\n",
    "                    return None, None\n",
    "    \n",
    "    return uniprot_name, uniprot_sequence\n",
    "\n",
    "uniprot_filepath = '/Users/luna/Documents/RP1/2_do_cal_and_result/uniprot_seq.txt'\n",
    "uniprot_name, uniprot_sequence = extract_uniprot_data(uniprot_filepath)\n",
    "print(f'The Uniprot sequence of {uniprot_name} is loaded, length: {len(uniprot_sequence)}')\n",
    "print(uniprot_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment: \n",
      "\n",
      "target            0 MREIIHISTGQCGNQIGAAFWETICGEHGLDFNGTYHGHDDIQKERLNVYFNEASSGKWV\n",
      "                  0 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query             0 MREIIHISTGQCGNQIGAAFWETICGEHGLDFNGTYHGHDDIQKERLNVYFNEASSGKWV\n",
      "\n",
      "target           60 PRSINVDLEPGTIDAVRNSAIGNLFRPDNYIFGQSSAGNVWAKGHYTEGAELVDSVMDVI\n",
      "                 60 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query            60 PRSINVDLEPGTIDAVRNSAIGNLFRPDNYIFGQSSAGNVWAKGHYTEGAELVDSVMDVI\n",
      "\n",
      "target          120 RREAEGCDSLQGFQITHSLGGGTGSGMGTLLISKIREEFPDRMMATFSVLPSPKTSDTVV\n",
      "                120 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           120 RREAEGCDSLQGFQITHSLGGGTGSGMGTLLISKIREEFPDRMMATFSVLPSPKTSDTVV\n",
      "\n",
      "target          180 EPYNATLSVHQLVEHSDETFCIDNEALYDICQRTLKLNQPSYGDLNNLVSSVMSGVTTSL\n",
      "                180 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           180 EPYNATLSVHQLVEHSDETFCIDNEALYDICQRTLKLNQPSYGDLNNLVSSVMSGVTTSL\n",
      "\n",
      "target          240 RYPGQLNSDLRKLAVNLVPFPRLHFFMVGYAPLTAIGSQSFRSLTVPELTQQMFDAKNMM\n",
      "                240 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           240 RYPGQLNSDLRKLAVNLVPFPRLHFFMVGYAPLTAIGSQSFRSLTVPELTQQMFDAKNMM\n",
      "\n",
      "target          300 AAADPRNGRYLTVAAFFRGKVSVKEVEDEMHKVQSKNSDYFVEWIPNNVQTAVCSVAPQG\n",
      "                300 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           300 AAADPRNGRYLTVAAFFRGKVSVKEVEDEMHKVQSKNSDYFVEWIPNNVQTAVCSVAPQG\n",
      "\n",
      "target          360 LDMAATFIANSTSIQELFKRVGDQFSAMFKRKAFLHWYTSEGMDELEFSEAESNMNDLVS\n",
      "                360 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           360 LDMAATFIANSTSIQELFKRVGDQFSAMFKRKAFLHWYTSEGMDELEFSEAESNMNDLVS\n",
      "\n",
      "target          420 EYQQYQEATVEDDEEVDENGDFGAPQNQDEPITENFE 457\n",
      "                420 |||||||------------------------------ 457\n",
      "query           420 EYQQYQE------------------------------ 427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2 Perform Alignment\n",
    "# 2.1\n",
    "def perform_global_alignment(uniprot_sequence, pdb_sequence):\n",
    "    # Initialize the aligner\n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'global'  # Perform global alignment\n",
    "    aligner.match_score = 1  # Score for identical characters\n",
    "    aligner.mismatch_score = 0  # Score for non-identical characters\n",
    "    aligner.open_gap_score = 0  # Score to open a gap\n",
    "    aligner.extend_gap_score = 0  # Score to extend a gap# Define two protein sequences to be aligned\n",
    "    # Set sequence\n",
    "    target = uniprot_sequence\n",
    "    query = pdb_sequence\n",
    "    # Perform the alignment\n",
    "    alignments = aligner.align(target, query)\n",
    "    # Get the best alignment (usually the first one)\n",
    "    best_alignment = alignments[0]\n",
    "    \n",
    "    return best_alignment\n",
    "\n",
    "alignment = perform_global_alignment(uniprot_sequence, pdb_sequence)\n",
    "print(f'Alignment: \\n\\n{alignment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned_uniprot\n",
      "MREIIHISTGQCGNQIGAAFWETICGEHGLDFNGTYHGHDDIQKERLNVYFNEASSGKWVPRSINVDLEPGTIDAVRNSAIGNLFRPDNYIFGQSSAGNVWAKGHYTEGAELVDSVMDVIRREAEGCDSLQGFQITHSLGGGTGSGMGTLLISKIREEFPDRMMATFSVLPSPKTSDTVVEPYNATLSVHQLVEHSDETFCIDNEALYDICQRTLKLNQPSYGDLNNLVSSVMSGVTTSLRYPGQLNSDLRKLAVNLVPFPRLHFFMVGYAPLTAIGSQSFRSLTVPELTQQMFDAKNMMAAADPRNGRYLTVAAFFRGKVSVKEVEDEMHKVQSKNSDYFVEWIPNNVQTAVCSVAPQGLDMAATFIANSTSIQELFKRVGDQFSAMFKRKAFLHWYTSEGMDELEFSEAESNMNDLVSEYQQYQEATVEDDEEVDENGDFGAPQNQDEPITENFE\n",
      "aligned_pdb\n",
      "MREIIHISTGQCGNQIGAAFWETICGEHGLDFNGTYHGHDDIQKERLNVYFNEASSGKWVPRSINVDLEPGTIDAVRNSAIGNLFRPDNYIFGQSSAGNVWAKGHYTEGAELVDSVMDVIRREAEGCDSLQGFQITHSLGGGTGSGMGTLLISKIREEFPDRMMATFSVLPSPKTSDTVVEPYNATLSVHQLVEHSDETFCIDNEALYDICQRTLKLNQPSYGDLNNLVSSVMSGVTTSLRYPGQLNSDLRKLAVNLVPFPRLHFFMVGYAPLTAIGSQSFRSLTVPELTQQMFDAKNMMAAADPRNGRYLTVAAFFRGKVSVKEVEDEMHKVQSKNSDYFVEWIPNNVQTAVCSVAPQGLDMAATFIANSTSIQELFKRVGDQFSAMFKRKAFLHWYTSEGMDELEFSEAESNMNDLVSEYQQYQE------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "def extract_aligned_sequences_from_alignment(alignment):\n",
    "    # Convert the alignment object to a string\n",
    "    alignment_str = str(alignment)\n",
    "    \n",
    "    # Split the alignment into lines\n",
    "    lines = alignment_str.strip().split(\"\\n\")\n",
    "    \n",
    "    # Initialize variables to hold the aligned sequences\n",
    "    aligned_uniprot = ''\n",
    "    aligned_pdb = ''\n",
    "\n",
    "    # Process the alignment block by block\n",
    "    for i in range(0, len(lines), 4):   # Each block has 4 lines\n",
    "        # Extract parts of the target and query sequences\n",
    "        # by removes any leading or trailing whitespace with strip()\n",
    "        # and then splits the line into parts based on whitespace with split()\n",
    "        target_line_parts = lines[i].strip().split() \n",
    "        query_line_parts = lines[i+2].strip().split()\n",
    "        \n",
    "        # Check if the line starts with 'target' or 'query' and has at least 3 parts\n",
    "        if target_line_parts[0].startswith('target') and len(target_line_parts) > 2:\n",
    "            aligned_uniprot += target_line_parts[2]  # The sequence part is the third element\n",
    "        if query_line_parts[0].startswith('query') and len(query_line_parts) > 2:\n",
    "            aligned_pdb += query_line_parts[2]  # The sequence part is the third element\n",
    "    \n",
    "    return aligned_uniprot, aligned_pdb\n",
    "\n",
    "aligned_uniprot, aligned_pdb = extract_aligned_sequences_from_alignment(alignment)\n",
    "print(f'aligned_uniprot\\n{aligned_uniprot}')\n",
    "print(f'aligned_pdb\\n{aligned_pdb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  UniProt_Index UniProt_AA\n",
      "0        1              1          M\n",
      "1        2              2          R\n",
      "2        3              3          E\n",
      "3        4              4          I\n",
      "4        5              5          I\n",
      "..     ...            ...        ...\n",
      "452    453            453          T\n",
      "453    454            454          E\n",
      "454    455            455          N\n",
      "455    456            456          F\n",
      "456    457            457          E\n",
      "\n",
      "[457 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Generate dfs and dictionaries from previous data\n",
    "# 3.1\n",
    "def create_df_from_aligned_target(aligned_uniprot):\n",
    "    # Initialize a list to store the data for each row\n",
    "    data_list = []\n",
    "    uniprot_index = 1  # Initialize the UniProt index counter\n",
    "    \n",
    "    # Iterate over each character in the aligned target sequence\n",
    "    for index, aa in enumerate(aligned_uniprot, start=1):\n",
    "        # Check if the character is an amino acid (not a gap '-')\n",
    "        if aa != '-':\n",
    "            # Add the index, UniProt index, and amino acid to the list\n",
    "            data_list.append({'Index': index, 'UniProt_Index': uniprot_index, 'UniProt_AA': aa})\n",
    "            uniprot_index += 1  # Increment the UniProt index counter\n",
    "        else:\n",
    "            # If the character is a gap, add it to the list with an empty UniProt index\n",
    "            data_list.append({'Index': index, 'UniProt_Index': ' ', 'UniProt_AA': aa})\n",
    "    \n",
    "    # Create a DataFrame from the list of data\n",
    "    uniprot_df = pd.DataFrame(data_list)\n",
    "    \n",
    "    return uniprot_df\n",
    "\n",
    "uniprot_df = create_df_from_aligned_target(aligned_uniprot)\n",
    "print(uniprot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3.2 \n",
    "# # For substitution and Addition\n",
    "# # (1)\n",
    "# def create_df_from_aligned_query(data_df, aligned_pdb):\n",
    "#     # Initialize a list to store the index and amino acid data\n",
    "#     aa_data = []\n",
    "#     index = data_df['NUM'].iloc[0]  # Initialize the index counter\n",
    "    \n",
    "#     # Iterate over each character in the aligned query sequence\n",
    "#     for aa in aligned_pdb:\n",
    "#         # Check if the character is an amino acid (not a gap '-')\n",
    "#         if aa != '-':\n",
    "#             # Add the index and amino acid to the list\n",
    "#             aa_data.append({'PDB_Index': index, 'PDB_AA': aa})\n",
    "#             index += 1  # Increment the index counter\n",
    "#         else:\n",
    "#             # If the character is a gap, add it to the list with an empty index\n",
    "#             aa_data.append({'PDB_Index': ' ', 'PDB_AA': aa})\n",
    "    \n",
    "#     # Create a DataFrame from the list of data\n",
    "#     pdb_df = pd.DataFrame(aa_data)\n",
    "    \n",
    "#     return pdb_df\n",
    "\n",
    "# pdb_df = create_df_from_aligned_query(data_df, aligned_pdb)\n",
    "# print(pdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "# def create_alignment_df_and_dict(uniprot_df, pdb_df):\n",
    "#     # Merge the two DataFrames on their index\n",
    "#     alignment_df = pd.merge(uniprot_df, pdb_df, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "#     # Initialize an empty dictionary to store the data\n",
    "#     alignment_dict = {}\n",
    "#     # Iterate over each row in the combined DataFrame\n",
    "#     for index, row in alignment_df.iterrows():\n",
    "#         # Create a key-value pair with the desired columns\n",
    "#         key = (row['Index'], row['UniProt_AA'])\n",
    "#         value = (row['PDB_Index'], row['PDB_AA'])\n",
    "        \n",
    "#         # Add the key-value pair to the dictionary\n",
    "#         alignment_dict[key] = value\n",
    "    \n",
    "#     return alignment_df, alignment_dict\n",
    "\n",
    "# alignment_df, alignment_dict = create_alignment_df_and_dict(uniprot_df, pdb_df)\n",
    "# print(f'alignment_df \\n{alignment_df}')\n",
    "\n",
    "# print(\"Contents of alignment_dict:\")\n",
    "# for key, value in alignment_dict.items():\n",
    "#     print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deletion\n",
      "alignment_df\n",
      "     Index  UniProt_Index UniProt_AA PDB_Index PDB_AA\n",
      "0        1              1          M         1      M\n",
      "1        2              2          R         2      R\n",
      "2        3              3          E         3      E\n",
      "3        4              4          I         4      I\n",
      "4        5              5          I         5      I\n",
      "..     ...            ...        ...       ...    ...\n",
      "452    453            453          T                -\n",
      "453    454            454          E                -\n",
      "454    455            455          N                -\n",
      "455    456            456          F                -\n",
      "456    457            457          E                -\n",
      "\n",
      "[457 rows x 5 columns]\n",
      "\n",
      "alignment_dict\n",
      "(1, 'M') (1, 'M')\n",
      "(2, 'R') (2, 'R')\n",
      "(3, 'E') (3, 'E')\n",
      "(4, 'I') (4, 'I')\n",
      "(5, 'I') (5, 'I')\n",
      "(6, 'H') (6, 'H')\n",
      "(7, 'I') (7, 'I')\n",
      "(8, 'S') (8, 'S')\n",
      "(9, 'T') (9, 'T')\n",
      "(10, 'G') (10, 'G')\n",
      "(11, 'Q') (11, 'Q')\n",
      "(12, 'C') (12, 'C')\n",
      "(13, 'G') (13, 'G')\n",
      "(14, 'N') (14, 'N')\n",
      "(15, 'Q') (15, 'Q')\n",
      "(16, 'I') (16, 'I')\n",
      "(17, 'G') (17, 'G')\n",
      "(18, 'A') (18, 'A')\n",
      "(19, 'A') (19, 'A')\n",
      "(20, 'F') (20, 'F')\n",
      "(21, 'W') (21, 'W')\n",
      "(22, 'E') (22, 'E')\n",
      "(23, 'T') (23, 'T')\n",
      "(24, 'I') (24, 'I')\n",
      "(25, 'C') (25, 'C')\n",
      "(26, 'G') (26, 'G')\n",
      "(27, 'E') (27, 'E')\n",
      "(28, 'H') (28, 'H')\n",
      "(29, 'G') (29, 'G')\n",
      "(30, 'L') (30, 'L')\n",
      "(31, 'D') (31, 'D')\n",
      "(32, 'F') (32, 'F')\n",
      "(33, 'N') (33, 'N')\n",
      "(34, 'G') (34, 'G')\n",
      "(35, 'T') (35, 'T')\n",
      "(36, 'Y') (36, 'Y')\n",
      "(37, 'H') (37, 'H')\n",
      "(38, 'G') (38, 'G')\n",
      "(39, 'H') (39, 'H')\n",
      "(40, 'D') (40, 'D')\n",
      "(41, 'D') (41, 'D')\n",
      "(42, 'I') (42, 'I')\n",
      "(43, 'Q') (43, 'Q')\n",
      "(44, 'K') (44, 'K')\n",
      "(45, 'E') (45, 'E')\n",
      "(46, 'R') (46, 'R')\n",
      "(47, 'L') (47, 'L')\n",
      "(48, 'N') (48, 'N')\n",
      "(49, 'V') (49, 'V')\n",
      "(50, 'Y') (50, 'Y')\n",
      "(51, 'F') (51, 'F')\n",
      "(52, 'N') (52, 'N')\n",
      "(53, 'E') (53, 'E')\n",
      "(54, 'A') (54, 'A')\n",
      "(55, 'S') (55, 'S')\n",
      "(56, 'S') (56, 'S')\n",
      "(57, 'G') (57, 'G')\n",
      "(58, 'K') (58, 'K')\n",
      "(59, 'W') (59, 'W')\n",
      "(60, 'V') (60, 'V')\n",
      "(61, 'P') (61, 'P')\n",
      "(62, 'R') (62, 'R')\n",
      "(63, 'S') (63, 'S')\n",
      "(64, 'I') (64, 'I')\n",
      "(65, 'N') (65, 'N')\n",
      "(66, 'V') (66, 'V')\n",
      "(67, 'D') (67, 'D')\n",
      "(68, 'L') (68, 'L')\n",
      "(69, 'E') (69, 'E')\n",
      "(70, 'P') (70, 'P')\n",
      "(71, 'G') (71, 'G')\n",
      "(72, 'T') (72, 'T')\n",
      "(73, 'I') (73, 'I')\n",
      "(74, 'D') (74, 'D')\n",
      "(75, 'A') (75, 'A')\n",
      "(76, 'V') (76, 'V')\n",
      "(77, 'R') (77, 'R')\n",
      "(78, 'N') (78, 'N')\n",
      "(79, 'S') (79, 'S')\n",
      "(80, 'A') (80, 'A')\n",
      "(81, 'I') (81, 'I')\n",
      "(82, 'G') (82, 'G')\n",
      "(83, 'N') (83, 'N')\n",
      "(84, 'L') (84, 'L')\n",
      "(85, 'F') (85, 'F')\n",
      "(86, 'R') (86, 'R')\n",
      "(87, 'P') (87, 'P')\n",
      "(88, 'D') (88, 'D')\n",
      "(89, 'N') (89, 'N')\n",
      "(90, 'Y') (90, 'Y')\n",
      "(91, 'I') (91, 'I')\n",
      "(92, 'F') (92, 'F')\n",
      "(93, 'G') (93, 'G')\n",
      "(94, 'Q') (94, 'Q')\n",
      "(95, 'S') (95, 'S')\n",
      "(96, 'S') (96, 'S')\n",
      "(97, 'A') (97, 'A')\n",
      "(98, 'G') (98, 'G')\n",
      "(99, 'N') (99, 'N')\n",
      "(100, 'V') (100, 'V')\n",
      "(101, 'W') (101, 'W')\n",
      "(102, 'A') (102, 'A')\n",
      "(103, 'K') (103, 'K')\n",
      "(104, 'G') (104, 'G')\n",
      "(105, 'H') (105, 'H')\n",
      "(106, 'Y') (106, 'Y')\n",
      "(107, 'T') (107, 'T')\n",
      "(108, 'E') (108, 'E')\n",
      "(109, 'G') (109, 'G')\n",
      "(110, 'A') (110, 'A')\n",
      "(111, 'E') (111, 'E')\n",
      "(112, 'L') (112, 'L')\n",
      "(113, 'V') (113, 'V')\n",
      "(114, 'D') (114, 'D')\n",
      "(115, 'S') (115, 'S')\n",
      "(116, 'V') (116, 'V')\n",
      "(117, 'M') (117, 'M')\n",
      "(118, 'D') (118, 'D')\n",
      "(119, 'V') (119, 'V')\n",
      "(120, 'I') (120, 'I')\n",
      "(121, 'R') (121, 'R')\n",
      "(122, 'R') (122, 'R')\n",
      "(123, 'E') (123, 'E')\n",
      "(124, 'A') (124, 'A')\n",
      "(125, 'E') (125, 'E')\n",
      "(126, 'G') (126, 'G')\n",
      "(127, 'C') (127, 'C')\n",
      "(128, 'D') (128, 'D')\n",
      "(129, 'S') (129, 'S')\n",
      "(130, 'L') (130, 'L')\n",
      "(131, 'Q') (131, 'Q')\n",
      "(132, 'G') (132, 'G')\n",
      "(133, 'F') (133, 'F')\n",
      "(134, 'Q') (134, 'Q')\n",
      "(135, 'I') (135, 'I')\n",
      "(136, 'T') (136, 'T')\n",
      "(137, 'H') (137, 'H')\n",
      "(138, 'S') (138, 'S')\n",
      "(139, 'L') (139, 'L')\n",
      "(140, 'G') (140, 'G')\n",
      "(141, 'G') (141, 'G')\n",
      "(142, 'G') (142, 'G')\n",
      "(143, 'T') (143, 'T')\n",
      "(144, 'G') (144, 'G')\n",
      "(145, 'S') (145, 'S')\n",
      "(146, 'G') (146, 'G')\n",
      "(147, 'M') (147, 'M')\n",
      "(148, 'G') (148, 'G')\n",
      "(149, 'T') (149, 'T')\n",
      "(150, 'L') (150, 'L')\n",
      "(151, 'L') (151, 'L')\n",
      "(152, 'I') (152, 'I')\n",
      "(153, 'S') (153, 'S')\n",
      "(154, 'K') (154, 'K')\n",
      "(155, 'I') (155, 'I')\n",
      "(156, 'R') (156, 'R')\n",
      "(157, 'E') (157, 'E')\n",
      "(158, 'E') (158, 'E')\n",
      "(159, 'F') (159, 'F')\n",
      "(160, 'P') (160, 'P')\n",
      "(161, 'D') (161, 'D')\n",
      "(162, 'R') (162, 'R')\n",
      "(163, 'M') (163, 'M')\n",
      "(164, 'M') (164, 'M')\n",
      "(165, 'A') (165, 'A')\n",
      "(166, 'T') (166, 'T')\n",
      "(167, 'F') (167, 'F')\n",
      "(168, 'S') (168, 'S')\n",
      "(169, 'V') (169, 'V')\n",
      "(170, 'L') (170, 'L')\n",
      "(171, 'P') (171, 'P')\n",
      "(172, 'S') (172, 'S')\n",
      "(173, 'P') (173, 'P')\n",
      "(174, 'K') (174, 'K')\n",
      "(175, 'T') (175, 'T')\n",
      "(176, 'S') (176, 'S')\n",
      "(177, 'D') (177, 'D')\n",
      "(178, 'T') (178, 'T')\n",
      "(179, 'V') (179, 'V')\n",
      "(180, 'V') (180, 'V')\n",
      "(181, 'E') (181, 'E')\n",
      "(182, 'P') (182, 'P')\n",
      "(183, 'Y') (183, 'Y')\n",
      "(184, 'N') (184, 'N')\n",
      "(185, 'A') (185, 'A')\n",
      "(186, 'T') (186, 'T')\n",
      "(187, 'L') (187, 'L')\n",
      "(188, 'S') (188, 'S')\n",
      "(189, 'V') (189, 'V')\n",
      "(190, 'H') (190, 'H')\n",
      "(191, 'Q') (191, 'Q')\n",
      "(192, 'L') (192, 'L')\n",
      "(193, 'V') (193, 'V')\n",
      "(194, 'E') (194, 'E')\n",
      "(195, 'H') (195, 'H')\n",
      "(196, 'S') (196, 'S')\n",
      "(197, 'D') (197, 'D')\n",
      "(198, 'E') (198, 'E')\n",
      "(199, 'T') (199, 'T')\n",
      "(200, 'F') (200, 'F')\n",
      "(201, 'C') (201, 'C')\n",
      "(202, 'I') (202, 'I')\n",
      "(203, 'D') (203, 'D')\n",
      "(204, 'N') (204, 'N')\n",
      "(205, 'E') (205, 'E')\n",
      "(206, 'A') (206, 'A')\n",
      "(207, 'L') (207, 'L')\n",
      "(208, 'Y') (208, 'Y')\n",
      "(209, 'D') (209, 'D')\n",
      "(210, 'I') (210, 'I')\n",
      "(211, 'C') (211, 'C')\n",
      "(212, 'Q') (212, 'Q')\n",
      "(213, 'R') (213, 'R')\n",
      "(214, 'T') (214, 'T')\n",
      "(215, 'L') (215, 'L')\n",
      "(216, 'K') (216, 'K')\n",
      "(217, 'L') (217, 'L')\n",
      "(218, 'N') (218, 'N')\n",
      "(219, 'Q') (219, 'Q')\n",
      "(220, 'P') (220, 'P')\n",
      "(221, 'S') (221, 'S')\n",
      "(222, 'Y') (222, 'Y')\n",
      "(223, 'G') (223, 'G')\n",
      "(224, 'D') (224, 'D')\n",
      "(225, 'L') (225, 'L')\n",
      "(226, 'N') (226, 'N')\n",
      "(227, 'N') (227, 'N')\n",
      "(228, 'L') (228, 'L')\n",
      "(229, 'V') (229, 'V')\n",
      "(230, 'S') (230, 'S')\n",
      "(231, 'S') (231, 'S')\n",
      "(232, 'V') (232, 'V')\n",
      "(233, 'M') (233, 'M')\n",
      "(234, 'S') (234, 'S')\n",
      "(235, 'G') (235, 'G')\n",
      "(236, 'V') (236, 'V')\n",
      "(237, 'T') (237, 'T')\n",
      "(238, 'T') (238, 'T')\n",
      "(239, 'S') (239, 'S')\n",
      "(240, 'L') (240, 'L')\n",
      "(241, 'R') (241, 'R')\n",
      "(242, 'Y') (242, 'Y')\n",
      "(243, 'P') (243, 'P')\n",
      "(244, 'G') (244, 'G')\n",
      "(245, 'Q') (245, 'Q')\n",
      "(246, 'L') (246, 'L')\n",
      "(247, 'N') (247, 'N')\n",
      "(248, 'S') (248, 'S')\n",
      "(249, 'D') (249, 'D')\n",
      "(250, 'L') (250, 'L')\n",
      "(251, 'R') (251, 'R')\n",
      "(252, 'K') (252, 'K')\n",
      "(253, 'L') (253, 'L')\n",
      "(254, 'A') (254, 'A')\n",
      "(255, 'V') (255, 'V')\n",
      "(256, 'N') (256, 'N')\n",
      "(257, 'L') (257, 'L')\n",
      "(258, 'V') (258, 'V')\n",
      "(259, 'P') (259, 'P')\n",
      "(260, 'F') (260, 'F')\n",
      "(261, 'P') (261, 'P')\n",
      "(262, 'R') (262, 'R')\n",
      "(263, 'L') (263, 'L')\n",
      "(264, 'H') (264, 'H')\n",
      "(265, 'F') (265, 'F')\n",
      "(266, 'F') (266, 'F')\n",
      "(267, 'M') (267, 'M')\n",
      "(268, 'V') (268, 'V')\n",
      "(269, 'G') (269, 'G')\n",
      "(270, 'Y') (270, 'Y')\n",
      "(271, 'A') (271, 'A')\n",
      "(272, 'P') (272, 'P')\n",
      "(273, 'L') (273, 'L')\n",
      "(274, 'T') (274, 'T')\n",
      "(275, 'A') (275, 'A')\n",
      "(276, 'I') (276, 'I')\n",
      "(277, 'G') (277, 'G')\n",
      "(278, 'S') (278, 'S')\n",
      "(279, 'Q') (279, 'Q')\n",
      "(280, 'S') (280, 'S')\n",
      "(281, 'F') (281, 'F')\n",
      "(282, 'R') (282, 'R')\n",
      "(283, 'S') (283, 'S')\n",
      "(284, 'L') (284, 'L')\n",
      "(285, 'T') (285, 'T')\n",
      "(286, 'V') (286, 'V')\n",
      "(287, 'P') (287, 'P')\n",
      "(288, 'E') (288, 'E')\n",
      "(289, 'L') (289, 'L')\n",
      "(290, 'T') (290, 'T')\n",
      "(291, 'Q') (291, 'Q')\n",
      "(292, 'Q') (292, 'Q')\n",
      "(293, 'M') (293, 'M')\n",
      "(294, 'F') (294, 'F')\n",
      "(295, 'D') (295, 'D')\n",
      "(296, 'A') (296, 'A')\n",
      "(297, 'K') (297, 'K')\n",
      "(298, 'N') (298, 'N')\n",
      "(299, 'M') (299, 'M')\n",
      "(300, 'M') (300, 'M')\n",
      "(301, 'A') (301, 'A')\n",
      "(302, 'A') (302, 'A')\n",
      "(303, 'A') (303, 'A')\n",
      "(304, 'D') (304, 'D')\n",
      "(305, 'P') (305, 'P')\n",
      "(306, 'R') (306, 'R')\n",
      "(307, 'N') (307, 'N')\n",
      "(308, 'G') (308, 'G')\n",
      "(309, 'R') (309, 'R')\n",
      "(310, 'Y') (310, 'Y')\n",
      "(311, 'L') (311, 'L')\n",
      "(312, 'T') (312, 'T')\n",
      "(313, 'V') (313, 'V')\n",
      "(314, 'A') (314, 'A')\n",
      "(315, 'A') (315, 'A')\n",
      "(316, 'F') (316, 'F')\n",
      "(317, 'F') (317, 'F')\n",
      "(318, 'R') (318, 'R')\n",
      "(319, 'G') (319, 'G')\n",
      "(320, 'K') (320, 'K')\n",
      "(321, 'V') (321, 'V')\n",
      "(322, 'S') (322, 'S')\n",
      "(323, 'V') (323, 'V')\n",
      "(324, 'K') (324, 'K')\n",
      "(325, 'E') (325, 'E')\n",
      "(326, 'V') (326, 'V')\n",
      "(327, 'E') (327, 'E')\n",
      "(328, 'D') (328, 'D')\n",
      "(329, 'E') (329, 'E')\n",
      "(330, 'M') (330, 'M')\n",
      "(331, 'H') (331, 'H')\n",
      "(332, 'K') (332, 'K')\n",
      "(333, 'V') (333, 'V')\n",
      "(334, 'Q') (334, 'Q')\n",
      "(335, 'S') (335, 'S')\n",
      "(336, 'K') (336, 'K')\n",
      "(337, 'N') (337, 'N')\n",
      "(338, 'S') (338, 'S')\n",
      "(339, 'D') (339, 'D')\n",
      "(340, 'Y') (340, 'Y')\n",
      "(341, 'F') (341, 'F')\n",
      "(342, 'V') (342, 'V')\n",
      "(343, 'E') (343, 'E')\n",
      "(344, 'W') (344, 'W')\n",
      "(345, 'I') (345, 'I')\n",
      "(346, 'P') (346, 'P')\n",
      "(347, 'N') (347, 'N')\n",
      "(348, 'N') (348, 'N')\n",
      "(349, 'V') (349, 'V')\n",
      "(350, 'Q') (350, 'Q')\n",
      "(351, 'T') (351, 'T')\n",
      "(352, 'A') (352, 'A')\n",
      "(353, 'V') (353, 'V')\n",
      "(354, 'C') (354, 'C')\n",
      "(355, 'S') (355, 'S')\n",
      "(356, 'V') (356, 'V')\n",
      "(357, 'A') (357, 'A')\n",
      "(358, 'P') (358, 'P')\n",
      "(359, 'Q') (359, 'Q')\n",
      "(360, 'G') (360, 'G')\n",
      "(361, 'L') (361, 'L')\n",
      "(362, 'D') (362, 'D')\n",
      "(363, 'M') (363, 'M')\n",
      "(364, 'A') (364, 'A')\n",
      "(365, 'A') (365, 'A')\n",
      "(366, 'T') (366, 'T')\n",
      "(367, 'F') (367, 'F')\n",
      "(368, 'I') (368, 'I')\n",
      "(369, 'A') (369, 'A')\n",
      "(370, 'N') (370, 'N')\n",
      "(371, 'S') (371, 'S')\n",
      "(372, 'T') (372, 'T')\n",
      "(373, 'S') (373, 'S')\n",
      "(374, 'I') (374, 'I')\n",
      "(375, 'Q') (375, 'Q')\n",
      "(376, 'E') (376, 'E')\n",
      "(377, 'L') (377, 'L')\n",
      "(378, 'F') (378, 'F')\n",
      "(379, 'K') (379, 'K')\n",
      "(380, 'R') (380, 'R')\n",
      "(381, 'V') (381, 'V')\n",
      "(382, 'G') (382, 'G')\n",
      "(383, 'D') (383, 'D')\n",
      "(384, 'Q') (384, 'Q')\n",
      "(385, 'F') (385, 'F')\n",
      "(386, 'S') (386, 'S')\n",
      "(387, 'A') (387, 'A')\n",
      "(388, 'M') (388, 'M')\n",
      "(389, 'F') (389, 'F')\n",
      "(390, 'K') (390, 'K')\n",
      "(391, 'R') (391, 'R')\n",
      "(392, 'K') (392, 'K')\n",
      "(393, 'A') (393, 'A')\n",
      "(394, 'F') (394, 'F')\n",
      "(395, 'L') (395, 'L')\n",
      "(396, 'H') (396, 'H')\n",
      "(397, 'W') (397, 'W')\n",
      "(398, 'Y') (398, 'Y')\n",
      "(399, 'T') (399, 'T')\n",
      "(400, 'S') (400, 'S')\n",
      "(401, 'E') (401, 'E')\n",
      "(402, 'G') (402, 'G')\n",
      "(403, 'M') (403, 'M')\n",
      "(404, 'D') (404, 'D')\n",
      "(405, 'E') (405, 'E')\n",
      "(406, 'L') (406, 'L')\n",
      "(407, 'E') (407, 'E')\n",
      "(408, 'F') (408, 'F')\n",
      "(409, 'S') (409, 'S')\n",
      "(410, 'E') (410, 'E')\n",
      "(411, 'A') (411, 'A')\n",
      "(412, 'E') (412, 'E')\n",
      "(413, 'S') (413, 'S')\n",
      "(414, 'N') (414, 'N')\n",
      "(415, 'M') (415, 'M')\n",
      "(416, 'N') (416, 'N')\n",
      "(417, 'D') (417, 'D')\n",
      "(418, 'L') (418, 'L')\n",
      "(419, 'V') (419, 'V')\n",
      "(420, 'S') (420, 'S')\n",
      "(421, 'E') (421, 'E')\n",
      "(422, 'Y') (422, 'Y')\n",
      "(423, 'Q') (423, 'Q')\n",
      "(424, 'Q') (424, 'Q')\n",
      "(425, 'Y') (425, 'Y')\n",
      "(426, 'Q') (426, 'Q')\n",
      "(427, 'E') (427, 'E')\n",
      "(428, 'A') ('', '-')\n",
      "(429, 'T') ('', '-')\n",
      "(430, 'V') ('', '-')\n",
      "(431, 'E') ('', '-')\n",
      "(432, 'D') ('', '-')\n",
      "(433, 'D') ('', '-')\n",
      "(434, 'E') ('', '-')\n",
      "(435, 'E') ('', '-')\n",
      "(436, 'V') ('', '-')\n",
      "(437, 'D') ('', '-')\n",
      "(438, 'E') ('', '-')\n",
      "(439, 'N') ('', '-')\n",
      "(440, 'G') ('', '-')\n",
      "(441, 'D') ('', '-')\n",
      "(442, 'F') ('', '-')\n",
      "(443, 'G') ('', '-')\n",
      "(444, 'A') ('', '-')\n",
      "(445, 'P') ('', '-')\n",
      "(446, 'Q') ('', '-')\n",
      "(447, 'N') ('', '-')\n",
      "(448, 'Q') ('', '-')\n",
      "(449, 'D') ('', '-')\n",
      "(450, 'E') ('', '-')\n",
      "(451, 'P') ('', '-')\n",
      "(452, 'I') ('', '-')\n",
      "(453, 'T') ('', '-')\n",
      "(454, 'E') ('', '-')\n",
      "(455, 'N') ('', '-')\n",
      "(456, 'F') ('', '-')\n",
      "(457, 'E') ('', '-')\n"
     ]
    }
   ],
   "source": [
    "# 3.2\n",
    "# For deletion\n",
    "def create_alignment_df_and_dict(uniprot_df, aligned_pdb):\n",
    "    # Initialize the 'PDB_Index' column with empty strings\n",
    "    uniprot_df['PDB_Index'] = ''\n",
    "    # Add the 'PDB_AA' column to uniprot_df with the characters from aligned_pdb\n",
    "    uniprot_df['PDB_AA'] = list(aligned_pdb)\n",
    "    # Create the alignment DataFrame with the correct column order\n",
    "    alignment_df =uniprot_df\n",
    "    \n",
    "    # Iterate over the DataFrame and update 'PDB_Index' based on the condition\n",
    "    for i, aa in enumerate(uniprot_df['PDB_AA']):\n",
    "        if aa != '-':\n",
    "            uniprot_df.at[i, 'PDB_Index'] = uniprot_df.at[i, 'UniProt_Index']\n",
    "    \n",
    "    alignment_df = alignment_df[['Index', 'UniProt_Index', 'UniProt_AA', 'PDB_Index', 'PDB_AA']]\n",
    "    \n",
    "    # Initialize an empty dictionary to store the data\n",
    "    alignment_dict = {}\n",
    "    # Iterate over each row in the combined DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Create a key-value pair with the desired columns\n",
    "        key = (row['Index'], row['UniProt_AA'])\n",
    "        value = (row['PDB_Index'], row['PDB_AA'])\n",
    "        \n",
    "        # Add the key-value pair to the dictionary\n",
    "        alignment_dict[key] = value\n",
    "    \n",
    "    return alignment_df, alignment_dict\n",
    "\n",
    "# Deletion\n",
    "print('\\nDeletion')\n",
    "alignment_df, alignment_dict = create_alignment_df_and_dict(uniprot_df, aligned_pdb)\n",
    "print('alignment_df')\n",
    "print(alignment_df)\n",
    "\n",
    "print('\\nalignment_dict')\n",
    "for key, value in alignment_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of mapping_dict:\n",
      "(1, 'M') 65.54\n",
      "(2, 'R') 13.07\n",
      "(3, 'E') 0.0\n",
      "(4, 'I') 0.0\n",
      "(5, 'I') 0.0\n",
      "(6, 'H') 0.0\n",
      "(7, 'I') 0.0\n",
      "(8, 'S') 0.0\n",
      "(9, 'T') 0.0\n",
      "(10, 'G') 0.0\n",
      "(11, 'Q') 0.0\n",
      "(12, 'C') 0.0\n",
      "(13, 'G') 0.0\n",
      "(14, 'N') 0.0\n",
      "(15, 'Q') 0.0\n",
      "(16, 'I') 0.0\n",
      "(17, 'G') 0.0\n",
      "(18, 'A') 0.0\n",
      "(19, 'A') 0.0\n",
      "(20, 'F') 0.0\n",
      "(21, 'W') 0.0\n",
      "(22, 'E') 0.0\n",
      "(23, 'T') 0.0\n",
      "(24, 'I') 0.0\n",
      "(25, 'C') 0.0\n",
      "(26, 'G') 0.0\n",
      "(27, 'E') 0.0\n",
      "(28, 'H') 0.0\n",
      "(29, 'G') 0.0\n",
      "(30, 'L') 0.0\n",
      "(31, 'D') 0.0\n",
      "(32, 'F') 0.0\n",
      "(33, 'N') 0.0\n",
      "(34, 'G') 0.0\n",
      "(35, 'T') 0.0\n",
      "(36, 'Y') 0.0\n",
      "(37, 'H') 0.0\n",
      "(38, 'G') 0.0\n",
      "(39, 'H') 0.0\n",
      "(40, 'D') 0.0\n",
      "(41, 'D') 0.33\n",
      "(42, 'I') 0.0\n",
      "(43, 'Q') 0.0\n",
      "(44, 'K') 0.0\n",
      "(45, 'E') 6.64\n",
      "(46, 'R') 64.26\n",
      "(47, 'L') 0.0\n",
      "(48, 'N') 0.0\n",
      "(49, 'V') 0.0\n",
      "(50, 'Y') 0.0\n",
      "(51, 'F') 0.0\n",
      "(52, 'N') 0.0\n",
      "(53, 'E') 0.0\n",
      "(54, 'A') 0.0\n",
      "(55, 'S') 0.0\n",
      "(56, 'S') 0.0\n",
      "(57, 'G') 0.0\n",
      "(58, 'K') 0.0\n",
      "(59, 'W') 0.0\n",
      "(60, 'V') 0.0\n",
      "(61, 'P') 0.0\n",
      "(62, 'R') 0.0\n",
      "(63, 'S') 0.0\n",
      "(64, 'I') 0.0\n",
      "(65, 'N') 0.0\n",
      "(66, 'V') 0.0\n",
      "(67, 'D') 0.0\n",
      "(68, 'L') 0.0\n",
      "(69, 'E') 0.0\n",
      "(70, 'P') 0.0\n",
      "(71, 'G') 0.0\n",
      "(72, 'T') 0.0\n",
      "(73, 'I') 0.0\n",
      "(74, 'D') 0.0\n",
      "(75, 'A') 0.0\n",
      "(76, 'V') 0.0\n",
      "(77, 'R') 0.0\n",
      "(78, 'N') 0.0\n",
      "(79, 'S') 0.0\n",
      "(80, 'A') 0.0\n",
      "(81, 'I') 0.0\n",
      "(82, 'G') 0.0\n",
      "(83, 'N') 0.0\n",
      "(84, 'L') 0.0\n",
      "(85, 'F') 0.0\n",
      "(86, 'R') 0.0\n",
      "(87, 'P') 0.0\n",
      "(88, 'D') 0.0\n",
      "(89, 'N') 0.0\n",
      "(90, 'Y') 0.0\n",
      "(91, 'I') 0.0\n",
      "(92, 'F') 0.0\n",
      "(93, 'G') 0.0\n",
      "(94, 'Q') 0.0\n",
      "(95, 'S') 0.0\n",
      "(96, 'S') 0.0\n",
      "(97, 'A') 0.0\n",
      "(98, 'G') 0.0\n",
      "(99, 'N') 0.0\n",
      "(100, 'V') 0.0\n",
      "(101, 'W') 0.0\n",
      "(102, 'A') 0.0\n",
      "(103, 'K') 0.0\n",
      "(104, 'G') 0.0\n",
      "(105, 'H') 0.0\n",
      "(106, 'Y') 0.0\n",
      "(107, 'T') 0.0\n",
      "(108, 'E') 0.0\n",
      "(109, 'G') 0.0\n",
      "(110, 'A') 0.0\n",
      "(111, 'E') 0.0\n",
      "(112, 'L') 0.0\n",
      "(113, 'V') 0.0\n",
      "(114, 'D') 0.0\n",
      "(115, 'S') 0.0\n",
      "(116, 'V') 0.0\n",
      "(117, 'M') 0.0\n",
      "(118, 'D') 0.0\n",
      "(119, 'V') 0.0\n",
      "(120, 'I') 0.0\n",
      "(121, 'R') 0.0\n",
      "(122, 'R') 0.0\n",
      "(123, 'E') 0.0\n",
      "(124, 'A') 0.0\n",
      "(125, 'E') 0.0\n",
      "(126, 'G') 0.0\n",
      "(127, 'C') 0.0\n",
      "(128, 'D') 19.86\n",
      "(129, 'S') 0.74\n",
      "(130, 'L') 0.0\n",
      "(131, 'Q') 0.0\n",
      "(132, 'G') 0.0\n",
      "(133, 'F') 0.0\n",
      "(134, 'Q') 0.0\n",
      "(135, 'I') 0.0\n",
      "(136, 'T') 0.0\n",
      "(137, 'H') 0.0\n",
      "(138, 'S') 0.0\n",
      "(139, 'L') 0.0\n",
      "(140, 'G') 0.0\n",
      "(141, 'G') 0.0\n",
      "(142, 'G') 0.0\n",
      "(143, 'T') 0.0\n",
      "(144, 'G') 0.0\n",
      "(145, 'S') 0.0\n",
      "(146, 'G') 0.0\n",
      "(147, 'M') 0.0\n",
      "(148, 'G') 0.0\n",
      "(149, 'T') 0.0\n",
      "(150, 'L') 0.0\n",
      "(151, 'L') 0.0\n",
      "(152, 'I') 0.0\n",
      "(153, 'S') 0.0\n",
      "(154, 'K') 0.0\n",
      "(155, 'I') 0.0\n",
      "(156, 'R') 0.0\n",
      "(157, 'E') 0.0\n",
      "(158, 'E') 0.0\n",
      "(159, 'F') 0.0\n",
      "(160, 'P') 0.0\n",
      "(161, 'D') 0.0\n",
      "(162, 'R') 29.11\n",
      "(163, 'M') 1.56\n",
      "(164, 'M') 0.0\n",
      "(165, 'A') 0.0\n",
      "(166, 'T') 0.0\n",
      "(167, 'F') 0.0\n",
      "(168, 'S') 0.0\n",
      "(169, 'V') 0.0\n",
      "(170, 'L') 0.0\n",
      "(171, 'P') 0.0\n",
      "(172, 'S') 0.0\n",
      "(173, 'P') 0.0\n",
      "(174, 'K') 0.0\n",
      "(175, 'T') 0.0\n",
      "(176, 'S') 0.0\n",
      "(177, 'D') 0.0\n",
      "(178, 'T') 0.0\n",
      "(179, 'V') 0.0\n",
      "(180, 'V') 0.0\n",
      "(181, 'E') 0.0\n",
      "(182, 'P') 0.0\n",
      "(183, 'Y') 0.0\n",
      "(184, 'N') 0.0\n",
      "(185, 'A') 0.0\n",
      "(186, 'T') 0.0\n",
      "(187, 'L') 0.0\n",
      "(188, 'S') 0.0\n",
      "(189, 'V') 0.0\n",
      "(190, 'H') 0.0\n",
      "(191, 'Q') 0.0\n",
      "(192, 'L') 0.0\n",
      "(193, 'V') 0.0\n",
      "(194, 'E') 0.0\n",
      "(195, 'H') 0.0\n",
      "(196, 'S') 0.0\n",
      "(197, 'D') 1.04\n",
      "(198, 'E') 0.0\n",
      "(199, 'T') 0.0\n",
      "(200, 'F') 0.0\n",
      "(201, 'C') 0.0\n",
      "(202, 'I') 0.0\n",
      "(203, 'D') 0.0\n",
      "(204, 'N') 0.0\n",
      "(205, 'E') 0.0\n",
      "(206, 'A') 0.0\n",
      "(207, 'L') 0.0\n",
      "(208, 'Y') 0.0\n",
      "(209, 'D') 0.0\n",
      "(210, 'I') 0.0\n",
      "(211, 'C') 0.0\n",
      "(212, 'Q') 0.0\n",
      "(213, 'R') 0.0\n",
      "(214, 'T') 0.0\n",
      "(215, 'L') 0.0\n",
      "(216, 'K') 0.0\n",
      "(217, 'L') 0.0\n",
      "(218, 'N') 0.0\n",
      "(219, 'Q') 0.0\n",
      "(220, 'P') 0.0\n",
      "(221, 'S') 0.0\n",
      "(222, 'Y') 0.0\n",
      "(223, 'G') 0.0\n",
      "(224, 'D') 0.0\n",
      "(225, 'L') 0.0\n",
      "(226, 'N') 0.0\n",
      "(227, 'N') 0.0\n",
      "(228, 'L') 0.0\n",
      "(229, 'V') 0.0\n",
      "(230, 'S') 0.0\n",
      "(231, 'S') 0.0\n",
      "(232, 'V') 0.0\n",
      "(233, 'M') 0.0\n",
      "(234, 'S') 0.0\n",
      "(235, 'G') 0.0\n",
      "(236, 'V') 0.0\n",
      "(237, 'T') 0.0\n",
      "(238, 'T') 0.0\n",
      "(239, 'S') 6.42\n",
      "(240, 'L') 14.3\n",
      "(241, 'R') 0.0\n",
      "(242, 'Y') 0.18\n",
      "(243, 'P') 18.69\n",
      "(244, 'G') 4.73\n",
      "(245, 'Q') 64.24\n",
      "(246, 'L') 32.48\n",
      "(247, 'N') 51.58\n",
      "(248, 'S') 0.23\n",
      "(249, 'D') 6.91\n",
      "(250, 'L') 0.0\n",
      "(251, 'R') 91.35\n",
      "(252, 'K') 43.6\n",
      "(253, 'L') 0.0\n",
      "(254, 'A') 26.36\n",
      "(255, 'V') 104.96\n",
      "(256, 'N') 65.35\n",
      "(257, 'L') 0.0\n",
      "(258, 'V') 14.55\n",
      "(259, 'P') 46.75\n",
      "(260, 'F') 5.88\n",
      "(261, 'P') 41.45\n",
      "(262, 'R') 0.0\n",
      "(263, 'L') 0.0\n",
      "(264, 'H') 0.0\n",
      "(265, 'F') 0.0\n",
      "(266, 'F') 0.0\n",
      "(267, 'M') 0.0\n",
      "(268, 'V') 0.0\n",
      "(269, 'G') 0.0\n",
      "(270, 'Y') 0.0\n",
      "(271, 'A') 0.0\n",
      "(272, 'P') 0.0\n",
      "(273, 'L') 0.0\n",
      "(274, 'T') 0.0\n",
      "(275, 'A') 0.0\n",
      "(276, 'I') 0.0\n",
      "(277, 'G') 0.0\n",
      "(278, 'S') 0.0\n",
      "(279, 'Q') 0.0\n",
      "(280, 'S') 0.0\n",
      "(281, 'F') 0.0\n",
      "(282, 'R') 0.0\n",
      "(283, 'S') 0.0\n",
      "(284, 'L') 0.0\n",
      "(285, 'T') 0.0\n",
      "(286, 'V') 0.0\n",
      "(287, 'P') 7.34\n",
      "(288, 'E') 0.0\n",
      "(289, 'L') 0.0\n",
      "(290, 'T') 0.0\n",
      "(291, 'Q') 0.0\n",
      "(292, 'Q') 0.0\n",
      "(293, 'M') 0.0\n",
      "(294, 'F') 0.0\n",
      "(295, 'D') 0.0\n",
      "(296, 'A') 0.0\n",
      "(297, 'K') 0.0\n",
      "(298, 'N') 0.0\n",
      "(299, 'M') 0.0\n",
      "(300, 'M') 0.0\n",
      "(301, 'A') 0.0\n",
      "(302, 'A') 0.0\n",
      "(303, 'A') 0.0\n",
      "(304, 'D') 0.0\n",
      "(305, 'P') 0.0\n",
      "(306, 'R') 0.0\n",
      "(307, 'N') 0.0\n",
      "(308, 'G') 0.0\n",
      "(309, 'R') 0.0\n",
      "(310, 'Y') 0.0\n",
      "(311, 'L') 0.0\n",
      "(312, 'T') 17.93\n",
      "(313, 'V') 1.35\n",
      "(314, 'A') 0.0\n",
      "(315, 'A') 0.0\n",
      "(316, 'F') 0.0\n",
      "(317, 'F') 0.0\n",
      "(318, 'R') 0.0\n",
      "(319, 'G') 0.0\n",
      "(320, 'K') 0.0\n",
      "(321, 'V') 0.0\n",
      "(322, 'S') 38.2\n",
      "(323, 'V') 58.23\n",
      "(324, 'K') 109.07\n",
      "(325, 'E') 41.43\n",
      "(326, 'V') 0.0\n",
      "(327, 'E') 56.97\n",
      "(328, 'D') 14.23\n",
      "(329, 'E') 0.0\n",
      "(330, 'M') 0.0\n",
      "(331, 'H') 44.27\n",
      "(332, 'K') 0.0\n",
      "(333, 'V') 0.0\n",
      "(334, 'Q') 3.88\n",
      "(335, 'S') 0.0\n",
      "(336, 'K') 0.0\n",
      "(337, 'N') 0.0\n",
      "(338, 'S') 0.0\n",
      "(339, 'D') 0.0\n",
      "(340, 'Y') 0.0\n",
      "(341, 'F') 0.0\n",
      "(342, 'V') 0.0\n",
      "(343, 'E') 15.61\n",
      "(344, 'W') 98.54\n",
      "(345, 'I') 45.41\n",
      "(346, 'P') 57.49\n",
      "(347, 'N') 86.58\n",
      "(348, 'N') 0.06\n",
      "(349, 'V') 46.45\n",
      "(350, 'Q') 22.18\n",
      "(351, 'T') 18.81\n",
      "(352, 'A') 0.0\n",
      "(353, 'V') 0.0\n",
      "(354, 'C') 0.0\n",
      "(355, 'S') 0.0\n",
      "(356, 'V') 0.0\n",
      "(357, 'A') 0.0\n",
      "(358, 'P') 0.0\n",
      "(359, 'Q') 0.0\n",
      "(360, 'G') 0.0\n",
      "(361, 'L') 0.0\n",
      "(362, 'D') 0.0\n",
      "(363, 'M') 0.0\n",
      "(364, 'A') 0.0\n",
      "(365, 'A') 0.0\n",
      "(366, 'T') 0.0\n",
      "(367, 'F') 0.0\n",
      "(368, 'I') 0.0\n",
      "(369, 'A') 0.0\n",
      "(370, 'N') 0.0\n",
      "(371, 'S') 0.0\n",
      "(372, 'T') 0.0\n",
      "(373, 'S') 0.0\n",
      "(374, 'I') 0.0\n",
      "(375, 'Q') 0.0\n",
      "(376, 'E') 0.0\n",
      "(377, 'L') 0.0\n",
      "(378, 'F') 0.0\n",
      "(379, 'K') 0.0\n",
      "(380, 'R') 0.0\n",
      "(381, 'V') 0.0\n",
      "(382, 'G') 0.0\n",
      "(383, 'D') 0.0\n",
      "(384, 'Q') 0.0\n",
      "(385, 'F') 0.0\n",
      "(386, 'S') 0.0\n",
      "(387, 'A') 0.0\n",
      "(388, 'M') 0.0\n",
      "(389, 'F') 0.0\n",
      "(390, 'K') 0.0\n",
      "(391, 'R') 0.0\n",
      "(392, 'K') 0.0\n",
      "(393, 'A') 0.0\n",
      "(394, 'F') 0.0\n",
      "(395, 'L') 0.0\n",
      "(396, 'H') 0.0\n",
      "(397, 'W') 0.0\n",
      "(398, 'Y') 0.0\n",
      "(399, 'T') 0.0\n",
      "(400, 'S') 0.0\n",
      "(401, 'E') 0.0\n",
      "(402, 'G') 0.0\n",
      "(403, 'M') 0.0\n",
      "(404, 'D') 0.0\n",
      "(405, 'E') 0.0\n",
      "(406, 'L') 0.0\n",
      "(407, 'E') 0.0\n",
      "(408, 'F') 0.0\n",
      "(409, 'S') 0.0\n",
      "(410, 'E') 0.0\n",
      "(411, 'A') 0.0\n",
      "(412, 'E') 0.0\n",
      "(413, 'S') 0.0\n",
      "(414, 'N') 0.0\n",
      "(415, 'M') 0.0\n",
      "(416, 'N') 0.0\n",
      "(417, 'D') 0.0\n",
      "(418, 'L') 0.0\n",
      "(419, 'V') 0.0\n",
      "(420, 'S') 0.0\n",
      "(421, 'E') 0.0\n",
      "(422, 'Y') 0.0\n",
      "(423, 'Q') 0.0\n",
      "(424, 'Q') 4.76\n",
      "(425, 'Y') 42.5\n",
      "(426, 'Q') 0.0\n",
      "(427, 'E') 0.0\n"
     ]
    }
   ],
   "source": [
    "# 3.3\n",
    "def create_aa_rel_dict(data_df):\n",
    "    # Initialize an empty dictionary\n",
    "    aa_rel_dict = {}\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for pdb_index, row in data_df.iterrows():\n",
    "        # Add the key-value pair to the dictionary\n",
    "        aa_rel_dict[(row['NUM'], row['AA'])] = row['ABS']\n",
    "        \n",
    "    return aa_rel_dict\n",
    "\n",
    "aa_rel_dict = create_aa_rel_dict(data_df)\n",
    "# Debugging: Print the contents of aa_rel_dict\n",
    "print(\"Contents of mapping_dict:\")\n",
    "for key, value in aa_rel_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported result in file 5w3f_B_P02557_cal.csv \n",
      "     Index  UniProt_Index UniProt_AA PDB_Index PDB_AA    ABS\n",
      "0        1              1          M         1      M  65.54\n",
      "1        2              2          R         2      R  13.07\n",
      "2        3              3          E         3      E    0.0\n",
      "3        4              4          I         4      I    0.0\n",
      "4        5              5          I         5      I    0.0\n",
      "..     ...            ...        ...       ...    ...    ...\n",
      "452    453            453          T                -       \n",
      "453    454            454          E                -       \n",
      "454    455            455          N                -       \n",
      "455    456            456          F                -       \n",
      "456    457            457          E                -       \n",
      "\n",
      "[457 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.4\n",
    "def update_alignment_df_with_REL_values(uniprot_name, pdb_name, chain_id, alignment_df, alignment_dict, aa_rel_dict):\n",
    "    \n",
    "    def lookup_value(row, alignment_dict, aa_rel_dict):\n",
    "        # Construct the key from the current row's 'Index' and 'UniProt_AA'\n",
    "        key = (row['Index'], row['UniProt_AA'])\n",
    "        # Get the corresponding PDB key from the alignment_dict using the constructed key\n",
    "        pdb_key = alignment_dict.get(key)\n",
    "        # Get the REL value from aa_rel_dict using the PDB key, if it exists\n",
    "        rel_value = aa_rel_dict.get(pdb_key) if pdb_key else None\n",
    "        \n",
    "        return rel_value\n",
    "\n",
    "    # Use the apply() function to apply the lookup_value function to each row of alignment_df\n",
    "    # Pass additional arguments alignment_dict and aa_rel_dict using args parameter\n",
    "    # The result is a new 'Value' column in alignment_df\n",
    "    alignment_df['ABS'] = alignment_df.apply(lookup_value, axis=1, args=(alignment_dict, aa_rel_dict))\n",
    "    # Replace NaN values with an empty string in the 'Value' column\n",
    "    alignment_df['ABS'] = alignment_df['ABS'].fillna('')\n",
    "    \n",
    "    # Write the updated DataFrame to a CSV file\n",
    "    filename = f'{pdb_name}_{chain_id}_{uniprot_name}_cal.csv'\n",
    "    alignment_df.to_csv(filename, index=False)\n",
    "    \n",
    "    return alignment_df\n",
    "\n",
    "alignment_df = update_alignment_df_with_REL_values(uniprot_name, pdb_name, chain_id, alignment_df, alignment_dict, aa_rel_dict)\n",
    "print(f'\\nExported result in file {pdb_name}_{chain_id}_{uniprot_name}_cal.csv ')\n",
    "print(alignment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Calculate the moment(M) of proteins (The truncated protein in the elute)\n",
    "def calculate_moment(r,n,m):\n",
    "    # Initialize the sum\n",
    "    total_sum = 0   \n",
    "    # Calculate the sum of r * (i - m) from i=0 to n\n",
    "    for i in range(n + 1):  # range(n+1) because the upper limit is inclusive\n",
    "        total_sum += r * (i - m)\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PDB model 5w3f, chain B encoded protein, with respect to the UniProt sequence P02557\n",
      "n = 457\n",
      "m = 229.0\n",
      "Absolute Moment(M_abs) = 72032.78\n"
     ]
    }
   ],
   "source": [
    "# Part 4 Calculate the moment(M) of proteins (The truncated protein in the elute)\n",
    "'''\n",
    "- n is the total length of UniProt sequence (n = max(UniProt_Index)).\n",
    "- m is the middle value that can separate the UniProt sequence into equivalent upper and lower two sections.\n",
    "  This is to make sure the REl value for aa counting form both ends has the same weight\n",
    "  (so they can counter each other).\n",
    "- i is the UniProt_Index of each PDB aa.\n",
    "- r is the REL value of each PDB aa, when the REL is not 0.0 and there is a corresponding UniProt aa for the PDB aa.\n",
    "  This is to make sure the calculation is based on the UniProt sequence\n",
    "  (So any addition from the PDB sequence would not affect the calculation).\n",
    "'''\n",
    "\n",
    "# The absolute moment\n",
    "def calculate_absolute_moment(alignment_df):\n",
    "    # Determine the middle position 'm' of the sequence\n",
    "    alignment_df['UniPort_Index'] = pd.to_numeric(alignment_df['UniProt_Index'], errors='coerce')\n",
    "    n = alignment_df['UniPort_Index'].max()\n",
    "    print(f'n = {n}')\n",
    "    m = (n / 2) + 0.5 \n",
    "    print(f'm = {m}')\n",
    "\n",
    "    # Initialize the sum\n",
    "    total_sum = 0\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Check if 'ABS' is numeric, not blank, greater than 0.0, and 'UniProt_AA' is not '-'\n",
    "        if pd.notnull(row['ABS']) and row['ABS'] != '' and row['ABS'] > 0.0 and row['UniProt_AA'] != '-':\n",
    "            r = float(row['ABS'])\n",
    "            i = row['UniPort_Index']\n",
    "            sum = r * (i - m)\n",
    "            # print(i)\n",
    "            # print(f'sum = {r} * ({i} - {m}) = {sum}')\n",
    "            \n",
    "            total_sum += sum\n",
    "    \n",
    "    # Round the total sum to 2 decimal places after the loop\n",
    "    total_sum = round(total_sum, 2)\n",
    "\n",
    "    print(f'Absolute Moment(M_abs) = {total_sum}')\n",
    "    return total_sum\n",
    "\n",
    "print(f'For PDB model {pdb_name}, chain {chain_id} encoded protein, with respect to the UniProt sequence {uniprot_name}')\n",
    "M_abs = calculate_absolute_moment(alignment_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PDB model 5w3f, chain B encoded protein, with respect to the UniPort sequence P02557\n",
      "n = 457\n",
      "m = 229.0\n",
      "sum = 0.03916460007768383 * -0.4989059080962801 = -0.019539450366984495\n",
      "sum = 0.007810212435387971 * -0.49671772428884026 = -0.0038794709471183138\n",
      "sum = 0.00019719740655531985 * -0.4113785557986871 = -8.112278431597402e-05\n",
      "sum = 0.003967850847052496 * -0.4026258205689278 = -0.0015975592031896265\n",
      "sum = 0.03839971316740865 * -0.40043763676148797 = -0.015376690393076112\n",
      "sum = 0.01186769846723834 * -0.2210065645514223 = -0.0026228392673765255\n",
      "sum = 0.00044220024500283845 * -0.2188183807439825 = -9.676154157611344e-05\n",
      "sum = 0.01739520152977382 * -0.14660831509846828 = -0.002550281187078438\n",
      "sum = 0.0009322059218978756 * -0.14442013129102846 = -0.0001346293016307654\n",
      "sum = 0.0006214706145985838 * -0.0700218818380744 = -4.3516541941257504e-05\n",
      "sum = 0.0038363859093489498 * 0.02188183807439825 = 8.394717525927679e-05\n",
      "sum = 0.008545220950730526 * 0.024070021881838075 = 0.00020568365526922494\n",
      "sum = 0.00010756222175744719 * 0.028446389496717725 = 3.0597568552446686e-06\n",
      "sum = 0.011168544025814934 * 0.030634573304157548 = 0.00034214358065953846\n",
      "sum = 0.0028264961606262514 * 0.03282275711159737 = 9.277339695709796e-05\n",
      "sum = 0.038387761809435594 * 0.0350109409190372 = 0.001343991660724222\n",
      "sum = 0.01940900534823269 * 0.037199124726477024 = 0.0007219980107657675\n",
      "sum = 0.030822552212495143 * 0.03938730853391685 = 0.0012140173737963077\n",
      "sum = 0.00013744061669007142 * 0.04157549234135667 = 5.714161306589402e-06\n",
      "sum = 0.004129194179688667 * 0.0437636761487965 = 0.00018070871683539022\n",
      "sum = 0.05458782754190444 * 0.04814004376367615 = 0.002627860406831286\n",
      "sum = 0.02605396038124832 * 0.05032822757111598 = 0.001311249647196305\n",
      "sum = 0.015751889808479486 * 0.05470459518599562 = 0.0008617007553872805\n",
      "sum = 0.06272072664256476 * 0.05689277899343545 = 0.003568356439183115\n",
      "sum = 0.03905106217693985 * 0.05908096280087528 = 0.002307174351810451\n",
      "sum = 0.008694612925393648 * 0.06345733041575492 = 0.0005517369252437982\n",
      "sum = 0.027936299262003646 * 0.06564551422319474 = 0.0018338927305472852\n",
      "sum = 0.0035136992440766082 * 0.06783369803063458 = 0.00023834721349316163\n",
      "sum = 0.024769189399145478 * 0.0700218818380744 = 0.0017343852533318496\n",
      "sum = 0.004386148376109235 * 0.12691466083150985 = 0.0005566665335105812\n",
      "sum = 0.010714392422839045 * 0.18161925601750548 = 0.0019459399805156253\n",
      "sum = 0.000806716663180854 * 0.1838074398249453 = 0.00014828052452339549\n",
      "sum = 0.022827093728524903 * 0.20350109409190373 = 0.004645338548693252\n",
      "sum = 0.03479637873853416 * 0.20568927789934355 = 0.007157242016241162\n",
      "sum = 0.06517673070602646 * 0.20787746170678337 = 0.013548773341515347\n",
      "sum = 0.024757238041172427 * 0.2100656455142232 = 0.005200645190268169\n",
      "sum = 0.034043443186232036 * 0.21444201312910285 = 0.007300344490701837\n",
      "sum = 0.008503391197824853 * 0.21663019693654267 = 0.0018420913098132613\n",
      "sum = 0.026454330873345484 * 0.22319474835886213 = 0.005904467722278423\n",
      "sum = 0.0023185634467716393 * 0.22975929978118162 = 0.0005327115140284948\n",
      "sum = 0.009328034897965281 * 0.24945295404814005 = 0.00232690586076158\n",
      "sum = 0.058884340733215815 * 0.25164113785557984 = 0.014817722503982096\n",
      "sum = 0.027135558277809314 * 0.2538293216630197 = 0.0068878003506036775\n",
      "sum = 0.034354178493531326 * 0.25601750547045954 = 0.0087952710804008\n",
      "sum = 0.0517374286653321 * 0.25820568927789933 = 0.013358898429998222\n",
      "sum = 3.585407391914906e-05 * 0.2603938730853392 = 9.33618117369527e-06\n",
      "sum = 0.0277570288924079 * 0.26258205689277897 = 0.007288497739800761\n",
      "sum = 0.013254055992112103 * 0.2647702407002188 = 0.003509279595285699\n",
      "sum = 0.01124025217365323 * 0.26695842450765866 = 0.003000680011347252\n",
      "sum = 0.0028444231975858253 * 0.42669584245076586 = 0.0012137035525803849\n",
      "sum = 0.025396635692730585 * 0.4288840262582057 = 0.010892211369311148\n",
      "Relative Moment(M_rel) = 0.09\n"
     ]
    }
   ],
   "source": [
    "# The relative moment\n",
    "def calculate_relative_moment(alignment_df):\n",
    "    # Convert 'UniProt_Index' to numeric and handle errors\n",
    "    alignment_df['UniProt_Index'] = pd.to_numeric(alignment_df['UniProt_Index'], errors='coerce')\n",
    "    n = alignment_df['UniProt_Index'].max()\n",
    "    print(f'n = {n}')\n",
    "    m = (n / 2) + 0.5 \n",
    "    print(f'm = {m}')\n",
    "    \n",
    "    # Initialize values\n",
    "    total_sum = 0\n",
    "    # Handle non-numeric values in 'ABS' column\n",
    "    alignment_df['ABS'] = pd.to_numeric(alignment_df['ABS'], errors='coerce')\n",
    "    # Drop rows with NaN values in 'ABS' column\n",
    "    alignment_df = alignment_df.dropna(subset=['ABS'])\n",
    "    total_r = alignment_df['ABS'].sum()\n",
    "    \n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Check if 'ABS' is numeric, not blank, greater than 0.0, and 'UniProt_AA' is not '-'\n",
    "        if pd.notnull(row['ABS']) and row['ABS'] != '' and row['ABS'] > 0.0 and row['UniProt_AA'] != '-':\n",
    "            r = float(row['ABS'])\n",
    "            i = row['UniProt_Index']\n",
    "            # Calculate the relative position with respect to 'm' for for odd residue number\n",
    "            if n % 2 == 1:\n",
    "                if i == m:\n",
    "                    relative_i = 0\n",
    "                else:\n",
    "                    relative_i = (i - m) / n\n",
    "            # Calculate the relative position with respect to 'm' for for odd residue number\n",
    "            if n % 2 == 0:\n",
    "                if i < m:\n",
    "                    relative_i = ((i - m) - 0.5) / n\n",
    "                elif i > m:\n",
    "                    relative_i = ((i - m) + 0.5) / n\n",
    "            \n",
    "            relative_r = r / total_r\n",
    "            \n",
    "            line_sum = relative_r * relative_i\n",
    "            print(f'sum = {relative_r} * {relative_i} = {line_sum}')\n",
    "            \n",
    "            total_sum += line_sum\n",
    "    \n",
    "    # Round the total sum to 2 decimal places after the loop\n",
    "    total_sum = round(total_sum, 2)\n",
    "\n",
    "    print(f'Relative Moment(M_rel) = {total_sum}')\n",
    "    return total_sum\n",
    "\n",
    "print(f'For PDB model {pdb_name}, chain {chain_id} encoded protein, with respect to the UniPort sequence {uniprot_name}')\n",
    "M_rel = calculate_relative_moment(alignment_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
