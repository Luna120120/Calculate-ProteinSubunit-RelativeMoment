{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys, os \n",
    "import argparse\n",
    "from Bio import Align\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded relevant information of 5w3f, chain A, from 5w3f_A-AB.csv\n",
      "     NUM   AA  ABS\n",
      "0      1  MET  0.0\n",
      "1      2  ARG  0.0\n",
      "2      3  GLU  0.0\n",
      "3      4  VAL  0.0\n",
      "4      5  ILE  0.0\n",
      "..   ...  ...  ...\n",
      "435  436  VAL  0.0\n",
      "436  437  GLY  0.0\n",
      "437  438  ALA  0.0\n",
      "438  439  ASP  0.0\n",
      "439  440  SER  0.0\n",
      "\n",
      "[440 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part 1 Prepare data\n",
    "# 1.1\n",
    "def extract_pdb_name_and_generate_df(filepath):\n",
    "    # Read the table from the file, assuming comma separation\n",
    "    # Skip the first two rows which contain 'REM' and 'All-atoms'\n",
    "    df = pd.read_csv(filepath, delimiter=',', skiprows=1)\n",
    "    # print(f'df generated from file path: {filepath} \\n{df}')\n",
    "    # Extract the PDB name from the file name\n",
    "    basename = os.path.basename(filepath)\n",
    "    pdb_name = basename.split('_')[0]\n",
    "    rest_name = basename.split('_')[1]\n",
    "    chain_id = rest_name.split('-')[0]\n",
    "    \n",
    "    # Create a new DataFrame that only retains information from column index 1, 3, and 4\n",
    "    # which are the aa, index, ABS\n",
    "    selected_indices = [1, 3, 4]\n",
    "    data_df = df.iloc[: ,selected_indices]\n",
    "    # Swap the aa and the index columns\n",
    "    cols = list(data_df.columns)\n",
    "    cols[0], cols[1] = cols[1], cols[0]  # Swap the column names\n",
    "    data_df = data_df[cols]  # Reindex the DataFrame with the new column order\n",
    "    # Assign new column names to the DataFrame\n",
    "    data_df.columns = ['NUM', 'AA', 'ABS']\n",
    "    data_df = data_df[['NUM', 'AA', 'ABS']]\n",
    "    \n",
    "    return basename, pdb_name, chain_id, data_df\n",
    "\n",
    "filepath = '/Users/luna/Documents/RP1/2_do_cal_and_result/5w3f_A-AB.csv'\n",
    "basename, pdb_name, chain_id, data_df = extract_pdb_name_and_generate_df(filepath)\n",
    "print(f'Loaded relevant information of {pdb_name}, chain {chain_id}, from {basename}')\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "def convert_three_letter_code_to_one_letter_code(three_letter_list):\n",
    "    aa_dict = {\n",
    "        'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D',\n",
    "        'CYS': 'C', 'GLU': 'E', 'GLN': 'Q', 'GLY': 'G',\n",
    "        'HIS': 'H', 'ILE': 'I', 'LEU': 'L', 'LYS': 'K',\n",
    "        'MET': 'M', 'PHE': 'F', 'PRO': 'P', 'SER': 'S',\n",
    "        'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',\n",
    "        # Additional potential codes\n",
    "        'SEC': 'U', 'PYL': 'O', 'ASX': 'B', 'GLX': 'Z',\n",
    "        'XLE': 'J', 'XAA': 'X', 'TER': '*', 'UNK': 'X'}\n",
    "    one_letter_list = []\n",
    "    for aa in three_letter_list:\n",
    "        one_letter_code = aa_dict.get(aa, 'X')  # Default to 'X' if aa is not found\n",
    "        one_letter_list.append(one_letter_code)\n",
    "        \n",
    "    return one_letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NUM AA  ABS\n",
      "0      1  M  0.0\n",
      "1      2  R  0.0\n",
      "2      3  E  0.0\n",
      "3      4  V  0.0\n",
      "4      5  I  0.0\n",
      "..   ... ..  ...\n",
      "435  436  V  0.0\n",
      "436  437  G  0.0\n",
      "437  438  A  0.0\n",
      "438  439  D  0.0\n",
      "439  440  S  0.0\n",
      "\n",
      "[440 rows x 3 columns]\n",
      "The PDB sequence of 5w3f is loaded, length: 440\n",
      "MREVISINVGQAGCQIGNACWELYSLEHGIKPDGHLEDGLSKPKGGEEGFSTFFHETGYGKFVPRAIYVDLEPNVIDEVRNGPYKDLFHPEQLISGKEDAANNYARGHYTVGREILGDVLDRIRKLADQCDGLQGFLFTHSLGGGTGSGLGSLLLEELSAEYGKKSKLEFAVYPAPQVSTSVVEPYNTVLTTHTTLEHADCTFMVDNEAIYDMCKRNLDIPRPSFANLNNLIAQVVSSVTASLRFDGSLNVDLNEFQTNLVPYPRIHFPLVSYSPVLSKSKAFHESNSVSEITNACFEPGNQMVKCDPRDGKYMATCLLYRGDVVTRDVQRAVEQVKNKKTVQLVDWCPTGFKIGICYEPPTATPNSQLATVDRAVCMLSNTTSIAEAWKRIDRKFDLMYAKRAFVHWYVGEGMEEGEFTEAREDLAALERDYIEVGADS\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "def process_df_and_generate_sequence_string(data_df):\n",
    "    # Convert the second column (amino acids) to a list of three-letter codes\n",
    "    three_letter_list = data_df.iloc[:, 1].tolist()\n",
    "    # Convert the three-letter codes to one-letter codes using the function\n",
    "    one_letter_list = convert_three_letter_code_to_one_letter_code(three_letter_list)\n",
    "    # Replace the second column with the one-letter codes\n",
    "    data_df.iloc[:, 1] = one_letter_list\n",
    "    \n",
    "    # Generate the PDB sequence \n",
    "    pdb_sequence = ''.join(one_letter_list)\n",
    "    \n",
    "    return pdb_sequence, data_df\n",
    "\n",
    "pdb_sequence, data_df = process_df_and_generate_sequence_string(data_df)\n",
    "print(data_df)\n",
    "print(f'The PDB sequence of {pdb_name} is loaded, length: {len(pdb_sequence)}')\n",
    "print(pdb_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the corresponding sequence in PDB model 5w3f, the PDB aa range: \n",
      "min: 1, max: 440\n",
      "\n",
      "Identified PDB aa block:\n",
      "1(M)-440(S)\n",
      "\n",
      "Missing PDB aa:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1.4\n",
    "def identify_aa_blocks(pdb_name, data_df):\n",
    "    # Find the smallest and largest NUM values\n",
    "    min_num = data_df['NUM'].min()\n",
    "    max_num = data_df['NUM'].max()\n",
    "    \n",
    "    # Generate the full range of numbers from min_num to max_num\n",
    "    full_range = set(range(int(min_num), int(max_num) + 1))\n",
    "    print(f'For the corresponding sequence in PDB model {pdb_name}, the PDB aa range: \\nmin: {min_num}, max: {max_num}')\n",
    "    \n",
    "    # Get the set of NUM values that actually appear in the DataFrame\n",
    "    actual_nums = set(data_df['NUM'])\n",
    "    \n",
    "    # Find the set of numbers that are missing from the DataFrame\n",
    "    missing_nums = sorted(full_range - actual_nums)\n",
    "    \n",
    "    # Identify the existing PDB aa blocks\n",
    "    print('\\nIdentified PDB aa block:')\n",
    "    current_block_start = None\n",
    "    for num in sorted(actual_nums):\n",
    "        if current_block_start is None:\n",
    "            current_block_start = num\n",
    "        # If the next number is missing or it's the last number, end the current block\n",
    "        if num + 1 not in actual_nums or num == max_num:\n",
    "            # Get the AA for the start and end of the block\n",
    "            start_aa = data_df.loc[data_df['NUM'] == current_block_start, 'AA'].values[0]\n",
    "            end_aa = data_df.loc[data_df['NUM'] == num, 'AA'].values[0]\n",
    "            print(f'{current_block_start}({start_aa})-{num}({end_aa})')\n",
    "            current_block_start = None\n",
    "    \n",
    "    # Print missing PDB aa\n",
    "    print('\\nMissing PDB aa:')\n",
    "    if not missing_nums:\n",
    "        print('None')\n",
    "    else:\n",
    "        missing_block_start = None\n",
    "        for i, num in enumerate(missing_nums):\n",
    "            if missing_block_start is None:\n",
    "                missing_block_start = num\n",
    "            # If the next number is not consecutive or it's the last missing number, end the current block\n",
    "            if i + 1 == len(missing_nums) or missing_nums[i + 1] != num + 1:\n",
    "                if missing_block_start == num:\n",
    "                    print(missing_block_start)\n",
    "                else:\n",
    "                    print(f'{missing_block_start}-{num}')\n",
    "                missing_block_start = None\n",
    "\n",
    "identify_aa_blocks(pdb_name, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Uniprot sequence of P09733 is loaded, length: 447\n",
      "MREVISINVGQAGCQIGNACWELYSLEHGIKPDGHLEDGLSKPKGGEEGFSTFFHETGYGKFVPRAIYVDLEPNVIDEVRNGPYKDLFHPEQLISGKEDAANNYARGHYTVGREILGDVLDRIRKLADQCDGLQGFLFTHSLGGGTGSGLGSLLLEELSAEYGKKSKLEFAVYPAPQVSTSVVEPYNTVLTTHTTLEHADCTFMVDNEAIYDMCKRNLDIPRPSFANLNNLIAQVVSSVTASLRFDGSLNVDLNEFQTNLVPYPRIHFPLVSYSPVLSKSKAFHESNSVSEITNACFEPGNQMVKCDPRDGKYMATCLLYRGDVVTRDVQRAVEQVKNKKTVQLVDWCPTGFKIGICYEPPTATPNSQLATVDRAVCMLSNTTSIAEAWKRIDRKFDLMYAKRAFVHWYVGEGMEEGEFTEAREDLAALERDYIEVGADSYAEEEEF\n"
     ]
    }
   ],
   "source": [
    "# 1.5\n",
    "def extract_uniprot_data(uniprot_filepath):\n",
    "    # Initialize an empty string to hold the sequence\n",
    "    uniprot_sequence = ''\n",
    "    # Initialize a variable to hold the UniProt name\n",
    "    uniprot_name = ''\n",
    "    \n",
    "    # Compile the regular expressions for the header and sequence lines\n",
    "    header_pattern = re.compile(r'^>sp\\|(\\w+)\\|')\n",
    "    sequence_pattern = re.compile(r'^[A-Z]+$')\n",
    "    \n",
    "    # Open the file for reading\n",
    "    with open(uniprot_filepath, 'r') as file:\n",
    "        # Iterate over each line in the file\n",
    "        for line in file:\n",
    "            # Check if the line is a header (starts with '>')\n",
    "            if line.startswith('>'):\n",
    "                # Use the regular expression to extract the UniProt name\n",
    "                header_match = header_pattern.match(line)\n",
    "                if header_match:\n",
    "                    uniprot_name = header_match.group(1)\n",
    "                else:\n",
    "                    print('Invalid header format:', line)\n",
    "                    return None, None\n",
    "            else:\n",
    "                # Check if the line contains only uppercase letters (valid sequence line)\n",
    "                if sequence_pattern.match(line.strip()):\n",
    "                    # Remove any whitespace and concatenate to the sequence\n",
    "                    uniprot_sequence += line.strip()\n",
    "                else:\n",
    "                    print('Invalid sequence format:', line)\n",
    "                    return None, None\n",
    "    \n",
    "    return uniprot_name, uniprot_sequence\n",
    "\n",
    "uniprot_filepath = '/Users/luna/Documents/RP1/2_do_cal_and_result/uniprot_seq.txt'\n",
    "uniprot_name, uniprot_sequence = extract_uniprot_data(uniprot_filepath)\n",
    "print(f'The Uniprot sequence of {uniprot_name} is loaded, length: {len(uniprot_sequence)}')\n",
    "print(uniprot_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment: \n",
      "\n",
      "target            0 MREVISINVGQAGCQIGNACWELYSLEHGIKPDGHLEDGLSKPKGGEEGFSTFFHETGYG\n",
      "                  0 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query             0 MREVISINVGQAGCQIGNACWELYSLEHGIKPDGHLEDGLSKPKGGEEGFSTFFHETGYG\n",
      "\n",
      "target           60 KFVPRAIYVDLEPNVIDEVRNGPYKDLFHPEQLISGKEDAANNYARGHYTVGREILGDVL\n",
      "                 60 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query            60 KFVPRAIYVDLEPNVIDEVRNGPYKDLFHPEQLISGKEDAANNYARGHYTVGREILGDVL\n",
      "\n",
      "target          120 DRIRKLADQCDGLQGFLFTHSLGGGTGSGLGSLLLEELSAEYGKKSKLEFAVYPAPQVST\n",
      "                120 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           120 DRIRKLADQCDGLQGFLFTHSLGGGTGSGLGSLLLEELSAEYGKKSKLEFAVYPAPQVST\n",
      "\n",
      "target          180 SVVEPYNTVLTTHTTLEHADCTFMVDNEAIYDMCKRNLDIPRPSFANLNNLIAQVVSSVT\n",
      "                180 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           180 SVVEPYNTVLTTHTTLEHADCTFMVDNEAIYDMCKRNLDIPRPSFANLNNLIAQVVSSVT\n",
      "\n",
      "target          240 ASLRFDGSLNVDLNEFQTNLVPYPRIHFPLVSYSPVLSKSKAFHESNSVSEITNACFEPG\n",
      "                240 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           240 ASLRFDGSLNVDLNEFQTNLVPYPRIHFPLVSYSPVLSKSKAFHESNSVSEITNACFEPG\n",
      "\n",
      "target          300 NQMVKCDPRDGKYMATCLLYRGDVVTRDVQRAVEQVKNKKTVQLVDWCPTGFKIGICYEP\n",
      "                300 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           300 NQMVKCDPRDGKYMATCLLYRGDVVTRDVQRAVEQVKNKKTVQLVDWCPTGFKIGICYEP\n",
      "\n",
      "target          360 PTATPNSQLATVDRAVCMLSNTTSIAEAWKRIDRKFDLMYAKRAFVHWYVGEGMEEGEFT\n",
      "                360 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           360 PTATPNSQLATVDRAVCMLSNTTSIAEAWKRIDRKFDLMYAKRAFVHWYVGEGMEEGEFT\n",
      "\n",
      "target          420 EAREDLAALERDYIEVGADSYAEEEEF 447\n",
      "                420 ||||||||||||||||||||------- 447\n",
      "query           420 EAREDLAALERDYIEVGADS------- 440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2 Perform Alignment\n",
    "# 2.1\n",
    "def perform_global_alignment(uniprot_sequence, pdb_sequence):\n",
    "    # Initialize the aligner\n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'global'  # Perform global alignment\n",
    "    aligner.match_score = 1  # Score for identical characters\n",
    "    aligner.mismatch_score = 0  # Score for non-identical characters\n",
    "    aligner.open_gap_score = 0  # Score to open a gap\n",
    "    aligner.extend_gap_score = 0  # Score to extend a gap# Define two protein sequences to be aligned\n",
    "    # Set sequence\n",
    "    target = uniprot_sequence\n",
    "    query = pdb_sequence\n",
    "    # Perform the alignment\n",
    "    alignments = aligner.align(target, query)\n",
    "    # Get the best alignment (usually the first one)\n",
    "    best_alignment = alignments[0]\n",
    "    \n",
    "    return best_alignment\n",
    "\n",
    "alignment = perform_global_alignment(uniprot_sequence, pdb_sequence)\n",
    "print(f'Alignment: \\n\\n{alignment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned_uniprot\n",
      "MREVISINVGQAGCQIGNACWELYSLEHGIKPDGHLEDGLSKPKGGEEGFSTFFHETGYGKFVPRAIYVDLEPNVIDEVRNGPYKDLFHPEQLISGKEDAANNYARGHYTVGREILGDVLDRIRKLADQCDGLQGFLFTHSLGGGTGSGLGSLLLEELSAEYGKKSKLEFAVYPAPQVSTSVVEPYNTVLTTHTTLEHADCTFMVDNEAIYDMCKRNLDIPRPSFANLNNLIAQVVSSVTASLRFDGSLNVDLNEFQTNLVPYPRIHFPLVSYSPVLSKSKAFHESNSVSEITNACFEPGNQMVKCDPRDGKYMATCLLYRGDVVTRDVQRAVEQVKNKKTVQLVDWCPTGFKIGICYEPPTATPNSQLATVDRAVCMLSNTTSIAEAWKRIDRKFDLMYAKRAFVHWYVGEGMEEGEFTEAREDLAALERDYIEVGADSYAEEEEF\n",
      "aligned_pdb\n",
      "MREVISINVGQAGCQIGNACWELYSLEHGIKPDGHLEDGLSKPKGGEEGFSTFFHETGYGKFVPRAIYVDLEPNVIDEVRNGPYKDLFHPEQLISGKEDAANNYARGHYTVGREILGDVLDRIRKLADQCDGLQGFLFTHSLGGGTGSGLGSLLLEELSAEYGKKSKLEFAVYPAPQVSTSVVEPYNTVLTTHTTLEHADCTFMVDNEAIYDMCKRNLDIPRPSFANLNNLIAQVVSSVTASLRFDGSLNVDLNEFQTNLVPYPRIHFPLVSYSPVLSKSKAFHESNSVSEITNACFEPGNQMVKCDPRDGKYMATCLLYRGDVVTRDVQRAVEQVKNKKTVQLVDWCPTGFKIGICYEPPTATPNSQLATVDRAVCMLSNTTSIAEAWKRIDRKFDLMYAKRAFVHWYVGEGMEEGEFTEAREDLAALERDYIEVGADS-------\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "def extract_aligned_sequences_from_alignment(alignment):\n",
    "    # Convert the alignment object to a string\n",
    "    alignment_str = str(alignment)\n",
    "    \n",
    "    # Split the alignment into lines\n",
    "    lines = alignment_str.strip().split(\"\\n\")\n",
    "    \n",
    "    # Initialize variables to hold the aligned sequences\n",
    "    aligned_uniprot = ''\n",
    "    aligned_pdb = ''\n",
    "\n",
    "    # Process the alignment block by block\n",
    "    for i in range(0, len(lines), 4):   # Each block has 4 lines\n",
    "        # Extract parts of the target and query sequences\n",
    "        # by removes any leading or trailing whitespace with strip()\n",
    "        # and then splits the line into parts based on whitespace with split()\n",
    "        target_line_parts = lines[i].strip().split() \n",
    "        query_line_parts = lines[i+2].strip().split()\n",
    "        \n",
    "        # Check if the line starts with 'target' or 'query' and has at least 3 parts\n",
    "        if target_line_parts[0].startswith('target') and len(target_line_parts) > 2:\n",
    "            aligned_uniprot += target_line_parts[2]  # The sequence part is the third element\n",
    "        if query_line_parts[0].startswith('query') and len(query_line_parts) > 2:\n",
    "            aligned_pdb += query_line_parts[2]  # The sequence part is the third element\n",
    "    \n",
    "    return aligned_uniprot, aligned_pdb\n",
    "\n",
    "aligned_uniprot, aligned_pdb = extract_aligned_sequences_from_alignment(alignment)\n",
    "print(f'aligned_uniprot\\n{aligned_uniprot}')\n",
    "print(f'aligned_pdb\\n{aligned_pdb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  UniProt_Index UniProt_AA\n",
      "0        1              1          M\n",
      "1        2              2          R\n",
      "2        3              3          E\n",
      "3        4              4          V\n",
      "4        5              5          I\n",
      "..     ...            ...        ...\n",
      "442    443            443          E\n",
      "443    444            444          E\n",
      "444    445            445          E\n",
      "445    446            446          E\n",
      "446    447            447          F\n",
      "\n",
      "[447 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Generate dfs and dictionaries from previous data\n",
    "# 3.1\n",
    "def create_df_from_aligned_target(aligned_uniprot):\n",
    "    # Initialize a list to store the data for each row\n",
    "    data_list = []\n",
    "    uniprot_index = 1  # Initialize the UniProt index counter\n",
    "    \n",
    "    # Iterate over each character in the aligned target sequence\n",
    "    for index, aa in enumerate(aligned_uniprot, start=1):\n",
    "        # Check if the character is an amino acid (not a gap '-')\n",
    "        if aa != '-':\n",
    "            # Add the index, UniProt index, and amino acid to the list\n",
    "            data_list.append({'Index': index, 'UniProt_Index': uniprot_index, 'UniProt_AA': aa})\n",
    "            uniprot_index += 1  # Increment the UniProt index counter\n",
    "        else:\n",
    "            # If the character is a gap, add it to the list with an empty UniProt index\n",
    "            data_list.append({'Index': index, 'UniProt_Index': ' ', 'UniProt_AA': aa})\n",
    "    \n",
    "    # Create a DataFrame from the list of data\n",
    "    uniprot_df = pd.DataFrame(data_list)\n",
    "    \n",
    "    return uniprot_df\n",
    "\n",
    "uniprot_df = create_df_from_aligned_target(aligned_uniprot)\n",
    "print(uniprot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3.2 \n",
    "# # For substitution and Addition\n",
    "# # (1)\n",
    "# def create_df_from_aligned_query(data_df, aligned_pdb):\n",
    "#     # Initialize a list to store the index and amino acid data\n",
    "#     aa_data = []\n",
    "#     index = data_df['NUM'].iloc[0]  # Initialize the index counter\n",
    "    \n",
    "#     # Iterate over each character in the aligned query sequence\n",
    "#     for aa in aligned_pdb:\n",
    "#         # Check if the character is an amino acid (not a gap '-')\n",
    "#         if aa != '-':\n",
    "#             # Add the index and amino acid to the list\n",
    "#             aa_data.append({'PDB_Index': index, 'PDB_AA': aa})\n",
    "#             index += 1  # Increment the index counter\n",
    "#         else:\n",
    "#             # If the character is a gap, add it to the list with an empty index\n",
    "#             aa_data.append({'PDB_Index': ' ', 'PDB_AA': aa})\n",
    "    \n",
    "#     # Create a DataFrame from the list of data\n",
    "#     pdb_df = pd.DataFrame(aa_data)\n",
    "    \n",
    "#     return pdb_df\n",
    "\n",
    "# pdb_df = create_df_from_aligned_query(data_df, aligned_pdb)\n",
    "# print(pdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "# def create_alignment_df_and_dict(uniprot_df, pdb_df):\n",
    "#     # Merge the two DataFrames on their index\n",
    "#     alignment_df = pd.merge(uniprot_df, pdb_df, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "#     # Initialize an empty dictionary to store the data\n",
    "#     alignment_dict = {}\n",
    "#     # Iterate over each row in the combined DataFrame\n",
    "#     for index, row in alignment_df.iterrows():\n",
    "#         # Create a key-value pair with the desired columns\n",
    "#         key = (row['Index'], row['UniProt_AA'])\n",
    "#         value = (row['PDB_Index'], row['PDB_AA'])\n",
    "        \n",
    "#         # Add the key-value pair to the dictionary\n",
    "#         alignment_dict[key] = value\n",
    "    \n",
    "#     return alignment_df, alignment_dict\n",
    "\n",
    "# alignment_df, alignment_dict = create_alignment_df_and_dict(uniprot_df, pdb_df)\n",
    "# print(f'alignment_df \\n{alignment_df}')\n",
    "\n",
    "# print(\"Contents of alignment_dict:\")\n",
    "# for key, value in alignment_dict.items():\n",
    "#     print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deletion\n",
      "alignment_df\n",
      "     Index  UniProt_Index UniProt_AA PDB_Index PDB_AA\n",
      "0        1              1          M         1      M\n",
      "1        2              2          R         2      R\n",
      "2        3              3          E         3      E\n",
      "3        4              4          V         4      V\n",
      "4        5              5          I         5      I\n",
      "..     ...            ...        ...       ...    ...\n",
      "442    443            443          E                -\n",
      "443    444            444          E                -\n",
      "444    445            445          E                -\n",
      "445    446            446          E                -\n",
      "446    447            447          F                -\n",
      "\n",
      "[447 rows x 5 columns]\n",
      "\n",
      "alignment_dict\n",
      "(1, 'M') (1, 'M')\n",
      "(2, 'R') (2, 'R')\n",
      "(3, 'E') (3, 'E')\n",
      "(4, 'V') (4, 'V')\n",
      "(5, 'I') (5, 'I')\n",
      "(6, 'S') (6, 'S')\n",
      "(7, 'I') (7, 'I')\n",
      "(8, 'N') (8, 'N')\n",
      "(9, 'V') (9, 'V')\n",
      "(10, 'G') (10, 'G')\n",
      "(11, 'Q') (11, 'Q')\n",
      "(12, 'A') (12, 'A')\n",
      "(13, 'G') (13, 'G')\n",
      "(14, 'C') (14, 'C')\n",
      "(15, 'Q') (15, 'Q')\n",
      "(16, 'I') (16, 'I')\n",
      "(17, 'G') (17, 'G')\n",
      "(18, 'N') (18, 'N')\n",
      "(19, 'A') (19, 'A')\n",
      "(20, 'C') (20, 'C')\n",
      "(21, 'W') (21, 'W')\n",
      "(22, 'E') (22, 'E')\n",
      "(23, 'L') (23, 'L')\n",
      "(24, 'Y') (24, 'Y')\n",
      "(25, 'S') (25, 'S')\n",
      "(26, 'L') (26, 'L')\n",
      "(27, 'E') (27, 'E')\n",
      "(28, 'H') (28, 'H')\n",
      "(29, 'G') (29, 'G')\n",
      "(30, 'I') (30, 'I')\n",
      "(31, 'K') (31, 'K')\n",
      "(32, 'P') (32, 'P')\n",
      "(33, 'D') (33, 'D')\n",
      "(34, 'G') (34, 'G')\n",
      "(35, 'H') (35, 'H')\n",
      "(36, 'L') (36, 'L')\n",
      "(37, 'E') (37, 'E')\n",
      "(38, 'D') (38, 'D')\n",
      "(39, 'G') (39, 'G')\n",
      "(40, 'L') (40, 'L')\n",
      "(41, 'S') (41, 'S')\n",
      "(42, 'K') (42, 'K')\n",
      "(43, 'P') (43, 'P')\n",
      "(44, 'K') (44, 'K')\n",
      "(45, 'G') (45, 'G')\n",
      "(46, 'G') (46, 'G')\n",
      "(47, 'E') (47, 'E')\n",
      "(48, 'E') (48, 'E')\n",
      "(49, 'G') (49, 'G')\n",
      "(50, 'F') (50, 'F')\n",
      "(51, 'S') (51, 'S')\n",
      "(52, 'T') (52, 'T')\n",
      "(53, 'F') (53, 'F')\n",
      "(54, 'F') (54, 'F')\n",
      "(55, 'H') (55, 'H')\n",
      "(56, 'E') (56, 'E')\n",
      "(57, 'T') (57, 'T')\n",
      "(58, 'G') (58, 'G')\n",
      "(59, 'Y') (59, 'Y')\n",
      "(60, 'G') (60, 'G')\n",
      "(61, 'K') (61, 'K')\n",
      "(62, 'F') (62, 'F')\n",
      "(63, 'V') (63, 'V')\n",
      "(64, 'P') (64, 'P')\n",
      "(65, 'R') (65, 'R')\n",
      "(66, 'A') (66, 'A')\n",
      "(67, 'I') (67, 'I')\n",
      "(68, 'Y') (68, 'Y')\n",
      "(69, 'V') (69, 'V')\n",
      "(70, 'D') (70, 'D')\n",
      "(71, 'L') (71, 'L')\n",
      "(72, 'E') (72, 'E')\n",
      "(73, 'P') (73, 'P')\n",
      "(74, 'N') (74, 'N')\n",
      "(75, 'V') (75, 'V')\n",
      "(76, 'I') (76, 'I')\n",
      "(77, 'D') (77, 'D')\n",
      "(78, 'E') (78, 'E')\n",
      "(79, 'V') (79, 'V')\n",
      "(80, 'R') (80, 'R')\n",
      "(81, 'N') (81, 'N')\n",
      "(82, 'G') (82, 'G')\n",
      "(83, 'P') (83, 'P')\n",
      "(84, 'Y') (84, 'Y')\n",
      "(85, 'K') (85, 'K')\n",
      "(86, 'D') (86, 'D')\n",
      "(87, 'L') (87, 'L')\n",
      "(88, 'F') (88, 'F')\n",
      "(89, 'H') (89, 'H')\n",
      "(90, 'P') (90, 'P')\n",
      "(91, 'E') (91, 'E')\n",
      "(92, 'Q') (92, 'Q')\n",
      "(93, 'L') (93, 'L')\n",
      "(94, 'I') (94, 'I')\n",
      "(95, 'S') (95, 'S')\n",
      "(96, 'G') (96, 'G')\n",
      "(97, 'K') (97, 'K')\n",
      "(98, 'E') (98, 'E')\n",
      "(99, 'D') (99, 'D')\n",
      "(100, 'A') (100, 'A')\n",
      "(101, 'A') (101, 'A')\n",
      "(102, 'N') (102, 'N')\n",
      "(103, 'N') (103, 'N')\n",
      "(104, 'Y') (104, 'Y')\n",
      "(105, 'A') (105, 'A')\n",
      "(106, 'R') (106, 'R')\n",
      "(107, 'G') (107, 'G')\n",
      "(108, 'H') (108, 'H')\n",
      "(109, 'Y') (109, 'Y')\n",
      "(110, 'T') (110, 'T')\n",
      "(111, 'V') (111, 'V')\n",
      "(112, 'G') (112, 'G')\n",
      "(113, 'R') (113, 'R')\n",
      "(114, 'E') (114, 'E')\n",
      "(115, 'I') (115, 'I')\n",
      "(116, 'L') (116, 'L')\n",
      "(117, 'G') (117, 'G')\n",
      "(118, 'D') (118, 'D')\n",
      "(119, 'V') (119, 'V')\n",
      "(120, 'L') (120, 'L')\n",
      "(121, 'D') (121, 'D')\n",
      "(122, 'R') (122, 'R')\n",
      "(123, 'I') (123, 'I')\n",
      "(124, 'R') (124, 'R')\n",
      "(125, 'K') (125, 'K')\n",
      "(126, 'L') (126, 'L')\n",
      "(127, 'A') (127, 'A')\n",
      "(128, 'D') (128, 'D')\n",
      "(129, 'Q') (129, 'Q')\n",
      "(130, 'C') (130, 'C')\n",
      "(131, 'D') (131, 'D')\n",
      "(132, 'G') (132, 'G')\n",
      "(133, 'L') (133, 'L')\n",
      "(134, 'Q') (134, 'Q')\n",
      "(135, 'G') (135, 'G')\n",
      "(136, 'F') (136, 'F')\n",
      "(137, 'L') (137, 'L')\n",
      "(138, 'F') (138, 'F')\n",
      "(139, 'T') (139, 'T')\n",
      "(140, 'H') (140, 'H')\n",
      "(141, 'S') (141, 'S')\n",
      "(142, 'L') (142, 'L')\n",
      "(143, 'G') (143, 'G')\n",
      "(144, 'G') (144, 'G')\n",
      "(145, 'G') (145, 'G')\n",
      "(146, 'T') (146, 'T')\n",
      "(147, 'G') (147, 'G')\n",
      "(148, 'S') (148, 'S')\n",
      "(149, 'G') (149, 'G')\n",
      "(150, 'L') (150, 'L')\n",
      "(151, 'G') (151, 'G')\n",
      "(152, 'S') (152, 'S')\n",
      "(153, 'L') (153, 'L')\n",
      "(154, 'L') (154, 'L')\n",
      "(155, 'L') (155, 'L')\n",
      "(156, 'E') (156, 'E')\n",
      "(157, 'E') (157, 'E')\n",
      "(158, 'L') (158, 'L')\n",
      "(159, 'S') (159, 'S')\n",
      "(160, 'A') (160, 'A')\n",
      "(161, 'E') (161, 'E')\n",
      "(162, 'Y') (162, 'Y')\n",
      "(163, 'G') (163, 'G')\n",
      "(164, 'K') (164, 'K')\n",
      "(165, 'K') (165, 'K')\n",
      "(166, 'S') (166, 'S')\n",
      "(167, 'K') (167, 'K')\n",
      "(168, 'L') (168, 'L')\n",
      "(169, 'E') (169, 'E')\n",
      "(170, 'F') (170, 'F')\n",
      "(171, 'A') (171, 'A')\n",
      "(172, 'V') (172, 'V')\n",
      "(173, 'Y') (173, 'Y')\n",
      "(174, 'P') (174, 'P')\n",
      "(175, 'A') (175, 'A')\n",
      "(176, 'P') (176, 'P')\n",
      "(177, 'Q') (177, 'Q')\n",
      "(178, 'V') (178, 'V')\n",
      "(179, 'S') (179, 'S')\n",
      "(180, 'T') (180, 'T')\n",
      "(181, 'S') (181, 'S')\n",
      "(182, 'V') (182, 'V')\n",
      "(183, 'V') (183, 'V')\n",
      "(184, 'E') (184, 'E')\n",
      "(185, 'P') (185, 'P')\n",
      "(186, 'Y') (186, 'Y')\n",
      "(187, 'N') (187, 'N')\n",
      "(188, 'T') (188, 'T')\n",
      "(189, 'V') (189, 'V')\n",
      "(190, 'L') (190, 'L')\n",
      "(191, 'T') (191, 'T')\n",
      "(192, 'T') (192, 'T')\n",
      "(193, 'H') (193, 'H')\n",
      "(194, 'T') (194, 'T')\n",
      "(195, 'T') (195, 'T')\n",
      "(196, 'L') (196, 'L')\n",
      "(197, 'E') (197, 'E')\n",
      "(198, 'H') (198, 'H')\n",
      "(199, 'A') (199, 'A')\n",
      "(200, 'D') (200, 'D')\n",
      "(201, 'C') (201, 'C')\n",
      "(202, 'T') (202, 'T')\n",
      "(203, 'F') (203, 'F')\n",
      "(204, 'M') (204, 'M')\n",
      "(205, 'V') (205, 'V')\n",
      "(206, 'D') (206, 'D')\n",
      "(207, 'N') (207, 'N')\n",
      "(208, 'E') (208, 'E')\n",
      "(209, 'A') (209, 'A')\n",
      "(210, 'I') (210, 'I')\n",
      "(211, 'Y') (211, 'Y')\n",
      "(212, 'D') (212, 'D')\n",
      "(213, 'M') (213, 'M')\n",
      "(214, 'C') (214, 'C')\n",
      "(215, 'K') (215, 'K')\n",
      "(216, 'R') (216, 'R')\n",
      "(217, 'N') (217, 'N')\n",
      "(218, 'L') (218, 'L')\n",
      "(219, 'D') (219, 'D')\n",
      "(220, 'I') (220, 'I')\n",
      "(221, 'P') (221, 'P')\n",
      "(222, 'R') (222, 'R')\n",
      "(223, 'P') (223, 'P')\n",
      "(224, 'S') (224, 'S')\n",
      "(225, 'F') (225, 'F')\n",
      "(226, 'A') (226, 'A')\n",
      "(227, 'N') (227, 'N')\n",
      "(228, 'L') (228, 'L')\n",
      "(229, 'N') (229, 'N')\n",
      "(230, 'N') (230, 'N')\n",
      "(231, 'L') (231, 'L')\n",
      "(232, 'I') (232, 'I')\n",
      "(233, 'A') (233, 'A')\n",
      "(234, 'Q') (234, 'Q')\n",
      "(235, 'V') (235, 'V')\n",
      "(236, 'V') (236, 'V')\n",
      "(237, 'S') (237, 'S')\n",
      "(238, 'S') (238, 'S')\n",
      "(239, 'V') (239, 'V')\n",
      "(240, 'T') (240, 'T')\n",
      "(241, 'A') (241, 'A')\n",
      "(242, 'S') (242, 'S')\n",
      "(243, 'L') (243, 'L')\n",
      "(244, 'R') (244, 'R')\n",
      "(245, 'F') (245, 'F')\n",
      "(246, 'D') (246, 'D')\n",
      "(247, 'G') (247, 'G')\n",
      "(248, 'S') (248, 'S')\n",
      "(249, 'L') (249, 'L')\n",
      "(250, 'N') (250, 'N')\n",
      "(251, 'V') (251, 'V')\n",
      "(252, 'D') (252, 'D')\n",
      "(253, 'L') (253, 'L')\n",
      "(254, 'N') (254, 'N')\n",
      "(255, 'E') (255, 'E')\n",
      "(256, 'F') (256, 'F')\n",
      "(257, 'Q') (257, 'Q')\n",
      "(258, 'T') (258, 'T')\n",
      "(259, 'N') (259, 'N')\n",
      "(260, 'L') (260, 'L')\n",
      "(261, 'V') (261, 'V')\n",
      "(262, 'P') (262, 'P')\n",
      "(263, 'Y') (263, 'Y')\n",
      "(264, 'P') (264, 'P')\n",
      "(265, 'R') (265, 'R')\n",
      "(266, 'I') (266, 'I')\n",
      "(267, 'H') (267, 'H')\n",
      "(268, 'F') (268, 'F')\n",
      "(269, 'P') (269, 'P')\n",
      "(270, 'L') (270, 'L')\n",
      "(271, 'V') (271, 'V')\n",
      "(272, 'S') (272, 'S')\n",
      "(273, 'Y') (273, 'Y')\n",
      "(274, 'S') (274, 'S')\n",
      "(275, 'P') (275, 'P')\n",
      "(276, 'V') (276, 'V')\n",
      "(277, 'L') (277, 'L')\n",
      "(278, 'S') (278, 'S')\n",
      "(279, 'K') (279, 'K')\n",
      "(280, 'S') (280, 'S')\n",
      "(281, 'K') (281, 'K')\n",
      "(282, 'A') (282, 'A')\n",
      "(283, 'F') (283, 'F')\n",
      "(284, 'H') (284, 'H')\n",
      "(285, 'E') (285, 'E')\n",
      "(286, 'S') (286, 'S')\n",
      "(287, 'N') (287, 'N')\n",
      "(288, 'S') (288, 'S')\n",
      "(289, 'V') (289, 'V')\n",
      "(290, 'S') (290, 'S')\n",
      "(291, 'E') (291, 'E')\n",
      "(292, 'I') (292, 'I')\n",
      "(293, 'T') (293, 'T')\n",
      "(294, 'N') (294, 'N')\n",
      "(295, 'A') (295, 'A')\n",
      "(296, 'C') (296, 'C')\n",
      "(297, 'F') (297, 'F')\n",
      "(298, 'E') (298, 'E')\n",
      "(299, 'P') (299, 'P')\n",
      "(300, 'G') (300, 'G')\n",
      "(301, 'N') (301, 'N')\n",
      "(302, 'Q') (302, 'Q')\n",
      "(303, 'M') (303, 'M')\n",
      "(304, 'V') (304, 'V')\n",
      "(305, 'K') (305, 'K')\n",
      "(306, 'C') (306, 'C')\n",
      "(307, 'D') (307, 'D')\n",
      "(308, 'P') (308, 'P')\n",
      "(309, 'R') (309, 'R')\n",
      "(310, 'D') (310, 'D')\n",
      "(311, 'G') (311, 'G')\n",
      "(312, 'K') (312, 'K')\n",
      "(313, 'Y') (313, 'Y')\n",
      "(314, 'M') (314, 'M')\n",
      "(315, 'A') (315, 'A')\n",
      "(316, 'T') (316, 'T')\n",
      "(317, 'C') (317, 'C')\n",
      "(318, 'L') (318, 'L')\n",
      "(319, 'L') (319, 'L')\n",
      "(320, 'Y') (320, 'Y')\n",
      "(321, 'R') (321, 'R')\n",
      "(322, 'G') (322, 'G')\n",
      "(323, 'D') (323, 'D')\n",
      "(324, 'V') (324, 'V')\n",
      "(325, 'V') (325, 'V')\n",
      "(326, 'T') (326, 'T')\n",
      "(327, 'R') (327, 'R')\n",
      "(328, 'D') (328, 'D')\n",
      "(329, 'V') (329, 'V')\n",
      "(330, 'Q') (330, 'Q')\n",
      "(331, 'R') (331, 'R')\n",
      "(332, 'A') (332, 'A')\n",
      "(333, 'V') (333, 'V')\n",
      "(334, 'E') (334, 'E')\n",
      "(335, 'Q') (335, 'Q')\n",
      "(336, 'V') (336, 'V')\n",
      "(337, 'K') (337, 'K')\n",
      "(338, 'N') (338, 'N')\n",
      "(339, 'K') (339, 'K')\n",
      "(340, 'K') (340, 'K')\n",
      "(341, 'T') (341, 'T')\n",
      "(342, 'V') (342, 'V')\n",
      "(343, 'Q') (343, 'Q')\n",
      "(344, 'L') (344, 'L')\n",
      "(345, 'V') (345, 'V')\n",
      "(346, 'D') (346, 'D')\n",
      "(347, 'W') (347, 'W')\n",
      "(348, 'C') (348, 'C')\n",
      "(349, 'P') (349, 'P')\n",
      "(350, 'T') (350, 'T')\n",
      "(351, 'G') (351, 'G')\n",
      "(352, 'F') (352, 'F')\n",
      "(353, 'K') (353, 'K')\n",
      "(354, 'I') (354, 'I')\n",
      "(355, 'G') (355, 'G')\n",
      "(356, 'I') (356, 'I')\n",
      "(357, 'C') (357, 'C')\n",
      "(358, 'Y') (358, 'Y')\n",
      "(359, 'E') (359, 'E')\n",
      "(360, 'P') (360, 'P')\n",
      "(361, 'P') (361, 'P')\n",
      "(362, 'T') (362, 'T')\n",
      "(363, 'A') (363, 'A')\n",
      "(364, 'T') (364, 'T')\n",
      "(365, 'P') (365, 'P')\n",
      "(366, 'N') (366, 'N')\n",
      "(367, 'S') (367, 'S')\n",
      "(368, 'Q') (368, 'Q')\n",
      "(369, 'L') (369, 'L')\n",
      "(370, 'A') (370, 'A')\n",
      "(371, 'T') (371, 'T')\n",
      "(372, 'V') (372, 'V')\n",
      "(373, 'D') (373, 'D')\n",
      "(374, 'R') (374, 'R')\n",
      "(375, 'A') (375, 'A')\n",
      "(376, 'V') (376, 'V')\n",
      "(377, 'C') (377, 'C')\n",
      "(378, 'M') (378, 'M')\n",
      "(379, 'L') (379, 'L')\n",
      "(380, 'S') (380, 'S')\n",
      "(381, 'N') (381, 'N')\n",
      "(382, 'T') (382, 'T')\n",
      "(383, 'T') (383, 'T')\n",
      "(384, 'S') (384, 'S')\n",
      "(385, 'I') (385, 'I')\n",
      "(386, 'A') (386, 'A')\n",
      "(387, 'E') (387, 'E')\n",
      "(388, 'A') (388, 'A')\n",
      "(389, 'W') (389, 'W')\n",
      "(390, 'K') (390, 'K')\n",
      "(391, 'R') (391, 'R')\n",
      "(392, 'I') (392, 'I')\n",
      "(393, 'D') (393, 'D')\n",
      "(394, 'R') (394, 'R')\n",
      "(395, 'K') (395, 'K')\n",
      "(396, 'F') (396, 'F')\n",
      "(397, 'D') (397, 'D')\n",
      "(398, 'L') (398, 'L')\n",
      "(399, 'M') (399, 'M')\n",
      "(400, 'Y') (400, 'Y')\n",
      "(401, 'A') (401, 'A')\n",
      "(402, 'K') (402, 'K')\n",
      "(403, 'R') (403, 'R')\n",
      "(404, 'A') (404, 'A')\n",
      "(405, 'F') (405, 'F')\n",
      "(406, 'V') (406, 'V')\n",
      "(407, 'H') (407, 'H')\n",
      "(408, 'W') (408, 'W')\n",
      "(409, 'Y') (409, 'Y')\n",
      "(410, 'V') (410, 'V')\n",
      "(411, 'G') (411, 'G')\n",
      "(412, 'E') (412, 'E')\n",
      "(413, 'G') (413, 'G')\n",
      "(414, 'M') (414, 'M')\n",
      "(415, 'E') (415, 'E')\n",
      "(416, 'E') (416, 'E')\n",
      "(417, 'G') (417, 'G')\n",
      "(418, 'E') (418, 'E')\n",
      "(419, 'F') (419, 'F')\n",
      "(420, 'T') (420, 'T')\n",
      "(421, 'E') (421, 'E')\n",
      "(422, 'A') (422, 'A')\n",
      "(423, 'R') (423, 'R')\n",
      "(424, 'E') (424, 'E')\n",
      "(425, 'D') (425, 'D')\n",
      "(426, 'L') (426, 'L')\n",
      "(427, 'A') (427, 'A')\n",
      "(428, 'A') (428, 'A')\n",
      "(429, 'L') (429, 'L')\n",
      "(430, 'E') (430, 'E')\n",
      "(431, 'R') (431, 'R')\n",
      "(432, 'D') (432, 'D')\n",
      "(433, 'Y') (433, 'Y')\n",
      "(434, 'I') (434, 'I')\n",
      "(435, 'E') (435, 'E')\n",
      "(436, 'V') (436, 'V')\n",
      "(437, 'G') (437, 'G')\n",
      "(438, 'A') (438, 'A')\n",
      "(439, 'D') (439, 'D')\n",
      "(440, 'S') (440, 'S')\n",
      "(441, 'Y') ('', '-')\n",
      "(442, 'A') ('', '-')\n",
      "(443, 'E') ('', '-')\n",
      "(444, 'E') ('', '-')\n",
      "(445, 'E') ('', '-')\n",
      "(446, 'E') ('', '-')\n",
      "(447, 'F') ('', '-')\n"
     ]
    }
   ],
   "source": [
    "# 3.2\n",
    "# For deletion\n",
    "def create_alignment_df_and_dict(uniprot_df, aligned_pdb):\n",
    "    # Initialize the 'PDB_Index' column with empty strings\n",
    "    uniprot_df['PDB_Index'] = ''\n",
    "    # Add the 'PDB_AA' column to uniprot_df with the characters from aligned_pdb\n",
    "    uniprot_df['PDB_AA'] = list(aligned_pdb)\n",
    "    # Create the alignment DataFrame with the correct column order\n",
    "    alignment_df =uniprot_df\n",
    "    \n",
    "    # Iterate over the DataFrame and update 'PDB_Index' based on the condition\n",
    "    for i, aa in enumerate(uniprot_df['PDB_AA']):\n",
    "        if aa != '-':\n",
    "            uniprot_df.at[i, 'PDB_Index'] = uniprot_df.at[i, 'UniProt_Index']\n",
    "    \n",
    "    alignment_df = alignment_df[['Index', 'UniProt_Index', 'UniProt_AA', 'PDB_Index', 'PDB_AA']]\n",
    "    \n",
    "    # Initialize an empty dictionary to store the data\n",
    "    alignment_dict = {}\n",
    "    # Iterate over each row in the combined DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Create a key-value pair with the desired columns\n",
    "        key = (row['Index'], row['UniProt_AA'])\n",
    "        value = (row['PDB_Index'], row['PDB_AA'])\n",
    "        \n",
    "        # Add the key-value pair to the dictionary\n",
    "        alignment_dict[key] = value\n",
    "    \n",
    "    return alignment_df, alignment_dict\n",
    "\n",
    "# Deletion\n",
    "print('\\nDeletion')\n",
    "alignment_df, alignment_dict = create_alignment_df_and_dict(uniprot_df, aligned_pdb)\n",
    "print('alignment_df')\n",
    "print(alignment_df)\n",
    "\n",
    "print('\\nalignment_dict')\n",
    "for key, value in alignment_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of mapping_dict:\n",
      "(1, 'M') 0.0\n",
      "(2, 'R') 0.0\n",
      "(3, 'E') 0.0\n",
      "(4, 'V') 0.0\n",
      "(5, 'I') 0.0\n",
      "(6, 'S') 0.0\n",
      "(7, 'I') 0.0\n",
      "(8, 'N') 0.0\n",
      "(9, 'V') 0.0\n",
      "(10, 'G') 0.0\n",
      "(11, 'Q') 59.35\n",
      "(12, 'A') 0.0\n",
      "(13, 'G') 0.0\n",
      "(14, 'C') 0.0\n",
      "(15, 'Q') 3.92\n",
      "(16, 'I') 0.0\n",
      "(17, 'G') 0.0\n",
      "(18, 'N') 0.0\n",
      "(19, 'A') 0.0\n",
      "(20, 'C') 0.0\n",
      "(21, 'W') 0.0\n",
      "(22, 'E') 0.0\n",
      "(23, 'L') 0.0\n",
      "(24, 'Y') 0.0\n",
      "(25, 'S') 0.0\n",
      "(26, 'L') 0.0\n",
      "(27, 'E') 0.0\n",
      "(28, 'H') 0.0\n",
      "(29, 'G') 0.0\n",
      "(30, 'I') 0.0\n",
      "(31, 'K') 0.0\n",
      "(32, 'P') 0.0\n",
      "(33, 'D') 0.0\n",
      "(34, 'G') 0.0\n",
      "(35, 'H') 0.0\n",
      "(36, 'L') 0.0\n",
      "(37, 'E') 0.0\n",
      "(38, 'D') 0.0\n",
      "(39, 'G') 0.0\n",
      "(40, 'L') 0.0\n",
      "(41, 'S') 0.0\n",
      "(42, 'K') 0.0\n",
      "(43, 'P') 0.0\n",
      "(44, 'K') 0.0\n",
      "(45, 'G') 0.0\n",
      "(46, 'G') 0.0\n",
      "(47, 'E') 0.0\n",
      "(48, 'E') 0.0\n",
      "(49, 'G') 0.0\n",
      "(50, 'F') 0.0\n",
      "(51, 'S') 0.0\n",
      "(52, 'T') 0.0\n",
      "(53, 'F') 0.0\n",
      "(54, 'F') 0.0\n",
      "(55, 'H') 0.0\n",
      "(56, 'E') 0.0\n",
      "(57, 'T') 0.0\n",
      "(58, 'G') 0.0\n",
      "(59, 'Y') 0.0\n",
      "(60, 'G') 0.0\n",
      "(61, 'K') 0.0\n",
      "(62, 'F') 0.0\n",
      "(63, 'V') 0.0\n",
      "(64, 'P') 0.0\n",
      "(65, 'R') 0.0\n",
      "(66, 'A') 0.0\n",
      "(67, 'I') 0.0\n",
      "(68, 'Y') 0.0\n",
      "(69, 'V') 0.0\n",
      "(70, 'D') 0.0\n",
      "(71, 'L') 0.0\n",
      "(72, 'E') 23.66\n",
      "(73, 'P') 8.19\n",
      "(74, 'N') 80.05\n",
      "(75, 'V') 3.05\n",
      "(76, 'I') 0.0\n",
      "(77, 'D') 19.87\n",
      "(78, 'E') 9.0\n",
      "(79, 'V') 0.0\n",
      "(80, 'R') 0.0\n",
      "(81, 'N') 7.93\n",
      "(82, 'G') 0.0\n",
      "(83, 'P') 0.0\n",
      "(84, 'Y') 0.0\n",
      "(85, 'K') 0.0\n",
      "(86, 'D') 0.0\n",
      "(87, 'L') 0.0\n",
      "(88, 'F') 0.0\n",
      "(89, 'H') 0.0\n",
      "(90, 'P') 0.0\n",
      "(91, 'E') 0.0\n",
      "(92, 'Q') 0.0\n",
      "(93, 'L') 0.0\n",
      "(94, 'I') 0.0\n",
      "(95, 'S') 0.0\n",
      "(96, 'G') 0.0\n",
      "(97, 'K') 68.36\n",
      "(98, 'E') 71.73\n",
      "(99, 'D') 31.2\n",
      "(100, 'A') 0.0\n",
      "(101, 'A') 62.27\n",
      "(102, 'N') 57.98\n",
      "(103, 'N') 1.6\n",
      "(104, 'Y') 0.0\n",
      "(105, 'A') 0.0\n",
      "(106, 'R') 7.32\n",
      "(107, 'G') 0.0\n",
      "(108, 'H') 0.0\n",
      "(109, 'Y') 0.0\n",
      "(110, 'T') 0.0\n",
      "(111, 'V') 0.0\n",
      "(112, 'G') 0.0\n",
      "(113, 'R') 0.0\n",
      "(114, 'E') 0.0\n",
      "(115, 'I') 0.0\n",
      "(116, 'L') 0.0\n",
      "(117, 'G') 0.0\n",
      "(118, 'D') 0.0\n",
      "(119, 'V') 0.0\n",
      "(120, 'L') 0.0\n",
      "(121, 'D') 0.0\n",
      "(122, 'R') 0.0\n",
      "(123, 'I') 0.0\n",
      "(124, 'R') 0.0\n",
      "(125, 'K') 0.0\n",
      "(126, 'L') 0.0\n",
      "(127, 'A') 0.0\n",
      "(128, 'D') 0.0\n",
      "(129, 'Q') 0.0\n",
      "(130, 'C') 0.0\n",
      "(131, 'D') 0.0\n",
      "(132, 'G') 0.0\n",
      "(133, 'L') 0.0\n",
      "(134, 'Q') 0.0\n",
      "(135, 'G') 0.0\n",
      "(136, 'F') 0.0\n",
      "(137, 'L') 0.0\n",
      "(138, 'F') 0.0\n",
      "(139, 'T') 0.0\n",
      "(140, 'H') 0.0\n",
      "(141, 'S') 0.0\n",
      "(142, 'L') 0.0\n",
      "(143, 'G') 0.0\n",
      "(144, 'G') 0.0\n",
      "(145, 'G') 0.0\n",
      "(146, 'T') 0.0\n",
      "(147, 'G') 0.0\n",
      "(148, 'S') 0.0\n",
      "(149, 'G') 0.0\n",
      "(150, 'L') 0.0\n",
      "(151, 'G') 0.0\n",
      "(152, 'S') 0.0\n",
      "(153, 'L') 0.0\n",
      "(154, 'L') 0.0\n",
      "(155, 'L') 0.0\n",
      "(156, 'E') 0.0\n",
      "(157, 'E') 0.0\n",
      "(158, 'L') 0.0\n",
      "(159, 'S') 0.0\n",
      "(160, 'A') 0.0\n",
      "(161, 'E') 0.0\n",
      "(162, 'Y') 0.0\n",
      "(163, 'G') 0.0\n",
      "(164, 'K') 0.0\n",
      "(165, 'K') 0.0\n",
      "(166, 'S') 0.0\n",
      "(167, 'K') 0.0\n",
      "(168, 'L') 0.0\n",
      "(169, 'E') 0.0\n",
      "(170, 'F') 0.0\n",
      "(171, 'A') 0.0\n",
      "(172, 'V') 0.0\n",
      "(173, 'Y') 0.0\n",
      "(174, 'P') 0.0\n",
      "(175, 'A') 0.98\n",
      "(176, 'P') 0.0\n",
      "(177, 'Q') 31.72\n",
      "(178, 'V') 75.54\n",
      "(179, 'S') 49.79\n",
      "(180, 'T') 107.29\n",
      "(181, 'S') 9.06\n",
      "(182, 'V') 106.01\n",
      "(183, 'V') 15.32\n",
      "(184, 'E') 0.42\n",
      "(185, 'P') 1.95\n",
      "(186, 'Y') 0.0\n",
      "(187, 'N') 0.0\n",
      "(188, 'T') 0.0\n",
      "(189, 'V') 0.0\n",
      "(190, 'L') 0.0\n",
      "(191, 'T') 0.0\n",
      "(192, 'T') 0.0\n",
      "(193, 'H') 0.0\n",
      "(194, 'T') 0.0\n",
      "(195, 'T') 0.0\n",
      "(196, 'L') 0.0\n",
      "(197, 'E') 0.0\n",
      "(198, 'H') 0.0\n",
      "(199, 'A') 0.0\n",
      "(200, 'D') 0.0\n",
      "(201, 'C') 0.0\n",
      "(202, 'T') 0.0\n",
      "(203, 'F') 0.0\n",
      "(204, 'M') 0.0\n",
      "(205, 'V') 0.0\n",
      "(206, 'D') 0.0\n",
      "(207, 'N') 0.0\n",
      "(208, 'E') 20.14\n",
      "(209, 'A') 0.0\n",
      "(210, 'I') 0.0\n",
      "(211, 'Y') 42.66\n",
      "(212, 'D') 0.0\n",
      "(213, 'M') 0.0\n",
      "(214, 'C') 0.0\n",
      "(215, 'K') 42.96\n",
      "(216, 'R') 0.0\n",
      "(217, 'N') 0.0\n",
      "(218, 'L') 0.0\n",
      "(219, 'D') 0.0\n",
      "(220, 'I') 0.0\n",
      "(221, 'P') 0.0\n",
      "(222, 'R') 62.12\n",
      "(223, 'P') 35.23\n",
      "(224, 'S') 13.74\n",
      "(225, 'F') 69.38\n",
      "(226, 'A') 0.92\n",
      "(227, 'N') 0.0\n",
      "(228, 'L') 0.0\n",
      "(229, 'N') 0.0\n",
      "(230, 'N') 0.0\n",
      "(231, 'L') 0.0\n",
      "(232, 'I') 0.0\n",
      "(233, 'A') 0.0\n",
      "(234, 'Q') 0.0\n",
      "(235, 'V') 0.0\n",
      "(236, 'V') 0.0\n",
      "(237, 'S') 0.0\n",
      "(238, 'S') 0.0\n",
      "(239, 'V') 0.0\n",
      "(240, 'T') 0.0\n",
      "(241, 'A') 0.0\n",
      "(242, 'S') 0.0\n",
      "(243, 'L') 0.0\n",
      "(244, 'R') 0.0\n",
      "(245, 'F') 0.0\n",
      "(246, 'D') 0.0\n",
      "(247, 'G') 0.0\n",
      "(248, 'S') 0.0\n",
      "(249, 'L') 0.0\n",
      "(250, 'N') 0.0\n",
      "(251, 'V') 0.0\n",
      "(252, 'D') 0.0\n",
      "(253, 'L') 0.0\n",
      "(254, 'N') 0.0\n",
      "(255, 'E') 0.0\n",
      "(256, 'F') 0.0\n",
      "(257, 'Q') 0.0\n",
      "(258, 'T') 0.0\n",
      "(259, 'N') 0.0\n",
      "(260, 'L') 0.0\n",
      "(261, 'V') 0.0\n",
      "(262, 'P') 0.0\n",
      "(263, 'Y') 0.0\n",
      "(264, 'P') 0.0\n",
      "(265, 'R') 0.0\n",
      "(266, 'I') 0.0\n",
      "(267, 'H') 0.0\n",
      "(268, 'F') 0.0\n",
      "(269, 'P') 0.0\n",
      "(270, 'L') 0.0\n",
      "(271, 'V') 0.0\n",
      "(272, 'S') 0.0\n",
      "(273, 'Y') 0.0\n",
      "(274, 'S') 0.0\n",
      "(275, 'P') 0.0\n",
      "(276, 'V') 0.0\n",
      "(277, 'L') 0.0\n",
      "(278, 'S') 0.0\n",
      "(279, 'K') 0.0\n",
      "(280, 'S') 0.0\n",
      "(281, 'K') 0.0\n",
      "(282, 'A') 0.0\n",
      "(283, 'F') 0.0\n",
      "(284, 'H') 0.0\n",
      "(285, 'E') 0.0\n",
      "(286, 'S') 0.0\n",
      "(287, 'N') 0.0\n",
      "(288, 'S') 0.0\n",
      "(289, 'V') 0.0\n",
      "(290, 'S') 0.0\n",
      "(291, 'E') 0.0\n",
      "(292, 'I') 0.0\n",
      "(293, 'T') 0.0\n",
      "(294, 'N') 0.0\n",
      "(295, 'A') 0.0\n",
      "(296, 'C') 0.0\n",
      "(297, 'F') 0.0\n",
      "(298, 'E') 0.0\n",
      "(299, 'P') 0.0\n",
      "(300, 'G') 0.0\n",
      "(301, 'N') 0.0\n",
      "(302, 'Q') 0.0\n",
      "(303, 'M') 0.0\n",
      "(304, 'V') 0.0\n",
      "(305, 'K') 0.0\n",
      "(306, 'C') 0.0\n",
      "(307, 'D') 0.0\n",
      "(308, 'P') 0.0\n",
      "(309, 'R') 0.0\n",
      "(310, 'D') 0.0\n",
      "(311, 'G') 0.0\n",
      "(312, 'K') 0.0\n",
      "(313, 'Y') 0.0\n",
      "(314, 'M') 0.0\n",
      "(315, 'A') 0.0\n",
      "(316, 'T') 0.0\n",
      "(317, 'C') 0.0\n",
      "(318, 'L') 0.0\n",
      "(319, 'L') 0.0\n",
      "(320, 'Y') 0.0\n",
      "(321, 'R') 0.0\n",
      "(322, 'G') 0.0\n",
      "(323, 'D') 0.0\n",
      "(324, 'V') 0.0\n",
      "(325, 'V') 0.0\n",
      "(326, 'T') 0.0\n",
      "(327, 'R') 0.0\n",
      "(328, 'D') 0.0\n",
      "(329, 'V') 0.0\n",
      "(330, 'Q') 0.0\n",
      "(331, 'R') 0.0\n",
      "(332, 'A') 0.0\n",
      "(333, 'V') 0.0\n",
      "(334, 'E') 0.0\n",
      "(335, 'Q') 0.0\n",
      "(336, 'V') 0.0\n",
      "(337, 'K') 0.0\n",
      "(338, 'N') 0.0\n",
      "(339, 'K') 0.0\n",
      "(340, 'K') 0.0\n",
      "(341, 'T') 0.0\n",
      "(342, 'V') 0.0\n",
      "(343, 'Q') 0.0\n",
      "(344, 'L') 0.0\n",
      "(345, 'V') 0.0\n",
      "(346, 'D') 0.0\n",
      "(347, 'W') 0.0\n",
      "(348, 'C') 0.0\n",
      "(349, 'P') 0.0\n",
      "(350, 'T') 0.0\n",
      "(351, 'G') 0.0\n",
      "(352, 'F') 0.0\n",
      "(353, 'K') 0.0\n",
      "(354, 'I') 0.0\n",
      "(355, 'G') 0.0\n",
      "(356, 'I') 0.0\n",
      "(357, 'C') 0.0\n",
      "(358, 'Y') 0.0\n",
      "(359, 'E') 0.0\n",
      "(360, 'P') 0.0\n",
      "(361, 'P') 0.0\n",
      "(362, 'T') 0.0\n",
      "(363, 'A') 0.0\n",
      "(364, 'T') 0.0\n",
      "(365, 'P') 0.0\n",
      "(366, 'N') 0.0\n",
      "(367, 'S') 0.0\n",
      "(368, 'Q') 0.0\n",
      "(369, 'L') 0.0\n",
      "(370, 'A') 0.0\n",
      "(371, 'T') 0.0\n",
      "(372, 'V') 0.0\n",
      "(373, 'D') 0.0\n",
      "(374, 'R') 0.0\n",
      "(375, 'A') 0.0\n",
      "(376, 'V') 0.0\n",
      "(377, 'C') 0.0\n",
      "(378, 'M') 0.0\n",
      "(379, 'L') 0.0\n",
      "(380, 'S') 0.0\n",
      "(381, 'N') 0.0\n",
      "(382, 'T') 0.0\n",
      "(383, 'T') 0.0\n",
      "(384, 'S') 0.0\n",
      "(385, 'I') 0.0\n",
      "(386, 'A') 0.0\n",
      "(387, 'E') 0.0\n",
      "(388, 'A') 0.0\n",
      "(389, 'W') 0.0\n",
      "(390, 'K') 0.0\n",
      "(391, 'R') 0.0\n",
      "(392, 'I') 0.0\n",
      "(393, 'D') 0.0\n",
      "(394, 'R') 0.0\n",
      "(395, 'K') 50.79\n",
      "(396, 'F') 0.0\n",
      "(397, 'D') 0.0\n",
      "(398, 'L') 68.23\n",
      "(399, 'M') 29.91\n",
      "(400, 'Y') 0.0\n",
      "(401, 'A') 0.0\n",
      "(402, 'K') 64.03\n",
      "(403, 'R') 0.0\n",
      "(404, 'A') 48.51\n",
      "(405, 'F') 73.48\n",
      "(406, 'V') 0.0\n",
      "(407, 'H') 46.89\n",
      "(408, 'W') 95.12\n",
      "(409, 'Y') 1.66\n",
      "(410, 'V') 0.0\n",
      "(411, 'G') 0.0\n",
      "(412, 'E') 0.0\n",
      "(413, 'G') 0.0\n",
      "(414, 'M') 0.0\n",
      "(415, 'E') 0.0\n",
      "(416, 'E') 0.0\n",
      "(417, 'G') 0.0\n",
      "(418, 'E') 0.0\n",
      "(419, 'F') 0.0\n",
      "(420, 'T') 0.0\n",
      "(421, 'E') 0.0\n",
      "(422, 'A') 0.0\n",
      "(423, 'R') 0.0\n",
      "(424, 'E') 0.0\n",
      "(425, 'D') 0.0\n",
      "(426, 'L') 0.0\n",
      "(427, 'A') 0.0\n",
      "(428, 'A') 0.0\n",
      "(429, 'L') 0.0\n",
      "(430, 'E') 0.0\n",
      "(431, 'R') 0.0\n",
      "(432, 'D') 0.0\n",
      "(433, 'Y') 0.0\n",
      "(434, 'I') 0.0\n",
      "(435, 'E') 0.0\n",
      "(436, 'V') 0.0\n",
      "(437, 'G') 0.0\n",
      "(438, 'A') 0.0\n",
      "(439, 'D') 0.0\n",
      "(440, 'S') 0.0\n"
     ]
    }
   ],
   "source": [
    "# 3.3\n",
    "def create_aa_rel_dict(data_df):\n",
    "    # Initialize an empty dictionary\n",
    "    aa_rel_dict = {}\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for pdb_index, row in data_df.iterrows():\n",
    "        # Add the key-value pair to the dictionary\n",
    "        aa_rel_dict[(row['NUM'], row['AA'])] = row['ABS']\n",
    "        \n",
    "    return aa_rel_dict\n",
    "\n",
    "aa_rel_dict = create_aa_rel_dict(data_df)\n",
    "# Debugging: Print the contents of aa_rel_dict\n",
    "print(\"Contents of mapping_dict:\")\n",
    "for key, value in aa_rel_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported result in file 5w3f_A_P09733_cal.csv \n",
      "     Index  UniProt_Index UniProt_AA PDB_Index PDB_AA  ABS\n",
      "0        1              1          M         1      M  0.0\n",
      "1        2              2          R         2      R  0.0\n",
      "2        3              3          E         3      E  0.0\n",
      "3        4              4          V         4      V  0.0\n",
      "4        5              5          I         5      I  0.0\n",
      "..     ...            ...        ...       ...    ...  ...\n",
      "442    443            443          E                -     \n",
      "443    444            444          E                -     \n",
      "444    445            445          E                -     \n",
      "445    446            446          E                -     \n",
      "446    447            447          F                -     \n",
      "\n",
      "[447 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.4\n",
    "def update_alignment_df_with_REL_values(uniprot_name, pdb_name, chain_id, alignment_df, alignment_dict, aa_rel_dict):\n",
    "    \n",
    "    def lookup_value(row, alignment_dict, aa_rel_dict):\n",
    "        # Construct the key from the current row's 'Index' and 'UniProt_AA'\n",
    "        key = (row['Index'], row['UniProt_AA'])\n",
    "        # Get the corresponding PDB key from the alignment_dict using the constructed key\n",
    "        pdb_key = alignment_dict.get(key)\n",
    "        # Get the REL value from aa_rel_dict using the PDB key, if it exists\n",
    "        rel_value = aa_rel_dict.get(pdb_key) if pdb_key else None\n",
    "        \n",
    "        return rel_value\n",
    "\n",
    "    # Use the apply() function to apply the lookup_value function to each row of alignment_df\n",
    "    # Pass additional arguments alignment_dict and aa_rel_dict using args parameter\n",
    "    # The result is a new 'Value' column in alignment_df\n",
    "    alignment_df['ABS'] = alignment_df.apply(lookup_value, axis=1, args=(alignment_dict, aa_rel_dict))\n",
    "    # Replace NaN values with an empty string in the 'Value' column\n",
    "    alignment_df['ABS'] = alignment_df['ABS'].fillna('')\n",
    "    \n",
    "    # Write the updated DataFrame to a CSV file\n",
    "    filename = f'{pdb_name}_{chain_id}_{uniprot_name}_cal.csv'\n",
    "    alignment_df.to_csv(filename, index=False)\n",
    "    \n",
    "    return alignment_df\n",
    "\n",
    "alignment_df = update_alignment_df_with_REL_values(uniprot_name, pdb_name, chain_id, alignment_df, alignment_dict, aa_rel_dict)\n",
    "print(f'\\nExported result in file {pdb_name}_{chain_id}_{uniprot_name}_cal.csv ')\n",
    "print(alignment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Calculate the moment(M) of proteins (The truncated protein in the elute)\n",
    "def calculate_moment(r,n,m):\n",
    "    # Initialize the sum\n",
    "    total_sum = 0   \n",
    "    # Calculate the sum of r * (i - m) from i=0 to n\n",
    "    for i in range(n + 1):  # range(n+1) because the upper limit is inclusive\n",
    "        total_sum += r * (i - m)\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PDB model 5w3f, chain A encoded protein, with respect to the UniProt sequence P09733\n",
      "n = 447\n",
      "m = 224.0\n",
      "Absolute Moment(M_abs) = -6813.76\n"
     ]
    }
   ],
   "source": [
    "# Part 4 Calculate the moment(M) of proteins (The truncated protein in the elute)\n",
    "'''\n",
    "- n is the total length of UniProt sequence (n = max(UniProt_Index)).\n",
    "- m is the middle value that can separate the UniProt sequence into equivalent upper and lower two sections.\n",
    "  This is to make sure the REl value for aa counting form both ends has the same weight\n",
    "  (so they can counter each other).\n",
    "- i is the UniProt_Index of each PDB aa.\n",
    "- r is the REL value of each PDB aa, when the REL is not 0.0 and there is a corresponding UniProt aa for the PDB aa.\n",
    "  This is to make sure the calculation is based on the UniProt sequence\n",
    "  (So any addition from the PDB sequence would not affect the calculation).\n",
    "'''\n",
    "\n",
    "# The absolute moment\n",
    "def calculate_absolute_moment(alignment_df):\n",
    "    # Determine the middle position 'm' of the sequence\n",
    "    alignment_df['UniPort_Index'] = pd.to_numeric(alignment_df['UniProt_Index'], errors='coerce')\n",
    "    n = alignment_df['UniPort_Index'].max()\n",
    "    print(f'n = {n}')\n",
    "    m = (n / 2) + 0.5 \n",
    "    print(f'm = {m}')\n",
    "\n",
    "    # Initialize the sum\n",
    "    total_sum = 0\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Check if 'ABS' is numeric, not blank, greater than 0.0, and 'UniProt_AA' is not '-'\n",
    "        if pd.notnull(row['ABS']) and row['ABS'] != '' and row['ABS'] > 0.0 and row['UniProt_AA'] != '-':\n",
    "            r = float(row['ABS'])\n",
    "            i = row['UniPort_Index']\n",
    "            sum = r * (i - m)\n",
    "            # print(i)\n",
    "            # print(f'sum = {r} * ({i} - {m}) = {sum}')\n",
    "            \n",
    "            total_sum += sum\n",
    "    \n",
    "    # Round the total sum to 2 decimal places after the loop\n",
    "    total_sum = round(total_sum, 2)\n",
    "\n",
    "    print(f'Absolute Moment(M_abs) = {total_sum}')\n",
    "    return total_sum\n",
    "\n",
    "print(f'For PDB model {pdb_name}, chain {chain_id} encoded protein, with respect to the UniProt sequence {uniprot_name}')\n",
    "M_abs = calculate_absolute_moment(alignment_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PDB model 5w3f, chain A encoded protein, with respect to the UniPort sequence P09733\n",
      "n = 447\n",
      "m = 224.0\n",
      "sum = 0.03534147546938362 * -0.47651006711409394 = -0.016840568847827093\n",
      "sum = 0.0023342642601513696 * -0.46756152125279643 = -0.0010914121484824077\n",
      "sum = 0.014088952141627909 * -0.3400447427293065 = -0.004790874106325374\n",
      "sum = 0.004876944972101969 * -0.3378076062639821 = -0.001647469106906929\n",
      "sum = 0.047667819904366616 * -0.33557046979865773 = -0.015995912719586114\n",
      "sum = 0.001816200508536142 * -0.3333333333333333 = -0.0006054001695120473\n",
      "sum = 0.01183209970643054 * -0.3288590604026846 = -0.0038910931920476273\n",
      "sum = 0.005359280189123043 * -0.32662192393736017 = -0.0017504584062907477\n",
      "sum = 0.0047221213221939696 * -0.319910514541387 = -0.0015106562619099275\n",
      "sum = 0.04070671041427235 * -0.2841163310961969 = -0.01156544121389841\n",
      "sum = 0.042713463107310654 * -0.28187919463087246 = -0.01204003658058421\n",
      "sum = 0.01857883798895988 * -0.2796420581655481 = -0.0051954244935570135\n",
      "sum = 0.03708026415296577 * -0.2751677852348993 = -0.01020329416289662\n",
      "sum = 0.034525673929483774 * -0.27293064876957496 = -0.009423114584780807\n",
      "sum = 0.0009527609225107632 * -0.27069351230425054 = -0.00025790620050067636\n",
      "sum = 0.004358881220486742 * -0.2639821029082774 = -0.001150666630911489\n",
      "sum = 0.0005835660650378424 * -0.10961968680089486 = -6.397032927707892e-05\n",
      "sum = 0.018888485288775878 * -0.10514541387024609 = -0.0019860376030703944\n",
      "sum = 0.044982225054039406 * -0.1029082774049217 = -0.004629043294151706\n",
      "sum = 0.02964872895738181 * -0.10067114093959731 = -0.002984771371548504\n",
      "sum = 0.06388857461011237 * -0.09843400447427293 = -0.006288808239026721\n",
      "sum = 0.005395008723717196 * -0.09619686800894854 = -0.000518982942102549\n",
      "sum = 0.06312636587210375 * -0.09395973154362416 = -0.005931336390667467\n",
      "sum = 0.009122685833040557 * -0.09172259507829977 = -0.0008367564186905209\n",
      "sum = 0.0002500997421590753 * -0.0894854586129754 = -2.238029012609175e-05\n",
      "sum = 0.0011611773743099925 * -0.087248322147651 = -0.00010131077762436176\n",
      "sum = 0.01199287811210423 * -0.035794183445190156 = -0.0004292752791804646\n",
      "sum = 0.02540298809644322 * -0.029082774049217 = -0.0007387893629838072\n",
      "sum = 0.025581630769413992 * -0.020134228187919462 = -0.000515066391330483\n",
      "sum = 0.036990942816480375 * -0.0044742729306487695 = -0.0001655075741229547\n",
      "sum = 0.020978604562533865 * -0.0022371364653243847 = -4.693200125846502e-05\n",
      "sum = 0.008181834422061178 * 0 = 0.0\n",
      "sum = 0.041314095502372965 * 0.0022371364653243847 = 9.242526958025272e-05\n",
      "sum = 0.0005478375304436888 * 0.0044742729306487695 = 2.4511746328576677e-06\n",
      "sum = 0.030244204533951036 * 0.3825503355704698 = 0.011569930593524893\n",
      "sum = 0.04062929858931836 * 0.38926174496644295 = 0.015815431665640704\n",
      "sum = 0.01781067449518558 * 0.39149888143176736 = 0.0069728591424104615\n",
      "sum = 0.038128301167727606 * 0.3982102908277405 = 0.015183081896768489\n",
      "sum = 0.0288865202193732 * 0.40268456375838924 = 0.011632155793036187\n",
      "sum = 0.0437555453663068 * 0.40492170022371365 = 0.017717569823940783\n",
      "sum = 0.027921849785331052 * 0.40939597315436244 = 0.011431092865135531\n",
      "sum = 0.05664163684326487 * 0.4116331096196868 = 0.023315573107742137\n",
      "sum = 0.0009884894571049168 * 0.41387024608501116 = 0.000409106374864451\n",
      "Relative Moment(M_rel) = -0.01\n"
     ]
    }
   ],
   "source": [
    "# The relative moment\n",
    "def calculate_relative_moment(alignment_df):\n",
    "    # Convert 'UniProt_Index' to numeric and handle errors\n",
    "    alignment_df['UniProt_Index'] = pd.to_numeric(alignment_df['UniProt_Index'], errors='coerce')\n",
    "    n = alignment_df['UniProt_Index'].max()\n",
    "    print(f'n = {n}')\n",
    "    m = (n / 2) + 0.5 \n",
    "    print(f'm = {m}')\n",
    "    \n",
    "    # Initialize values\n",
    "    total_sum = 0\n",
    "    # Handle non-numeric values in 'ABS' column\n",
    "    alignment_df['ABS'] = pd.to_numeric(alignment_df['ABS'], errors='coerce')\n",
    "    # Drop rows with NaN values in 'ABS' column\n",
    "    alignment_df = alignment_df.dropna(subset=['ABS'])\n",
    "    total_r = alignment_df['ABS'].sum()\n",
    "    \n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        # Check if 'ABS' is numeric, not blank, greater than 0.0, and 'UniProt_AA' is not '-'\n",
    "        if pd.notnull(row['ABS']) and row['ABS'] != '' and row['ABS'] > 0.0 and row['UniProt_AA'] != '-':\n",
    "            r = float(row['ABS'])\n",
    "            i = row['UniProt_Index']\n",
    "            # Calculate the relative position with respect to 'm' for for odd residue number\n",
    "            if n % 2 == 1:\n",
    "                if i == m:\n",
    "                    relative_i = 0\n",
    "                else:\n",
    "                    relative_i = (i - m) / n\n",
    "            # Calculate the relative position with respect to 'm' for for odd residue number\n",
    "            if n % 2 == 0:\n",
    "                if i < m:\n",
    "                    relative_i = ((i - m) - 0.5) / n\n",
    "                elif i > m:\n",
    "                    relative_i = ((i - m) + 0.5) / n\n",
    "            \n",
    "            relative_r = r / total_r\n",
    "            \n",
    "            line_sum = relative_r * relative_i\n",
    "            print(f'sum = {relative_r} * {relative_i} = {line_sum}')\n",
    "            \n",
    "            total_sum += line_sum\n",
    "    \n",
    "    # Round the total sum to 2 decimal places after the loop\n",
    "    total_sum = round(total_sum, 2)\n",
    "\n",
    "    print(f'Relative Moment(M_rel) = {total_sum}')\n",
    "    return total_sum\n",
    "\n",
    "print(f'For PDB model {pdb_name}, chain {chain_id} encoded protein, with respect to the UniPort sequence {uniprot_name}')\n",
    "M_rel = calculate_relative_moment(alignment_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
